{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65298a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 975 per-run summary rows to summaries.csv\n",
      "Wrote aggregated top-line summary to aggregated_topline.csv\n",
      "                  problem           model        prompt_type  pass_rate  \\\n",
      "0   DirectedSocialNetwork   Claude35Haiku       directprompt        0.0   \n",
      "1   DirectedSocialNetwork   Claude35Haiku  iterativefeedback        0.0   \n",
      "2   DirectedSocialNetwork   Claude35Haiku   programaugmented        0.0   \n",
      "3   DirectedSocialNetwork  Claude35Sonnet       directprompt      100.0   \n",
      "4   DirectedSocialNetwork  Claude35Sonnet  iterativefeedback      100.0   \n",
      "5   DirectedSocialNetwork  Claude35Sonnet   programaugmented       60.0   \n",
      "6   DirectedSocialNetwork      DeepSeekR1       directprompt       20.0   \n",
      "7   DirectedSocialNetwork      DeepSeekR1  iterativefeedback       40.0   \n",
      "8   DirectedSocialNetwork      DeepSeekR1   programaugmented        0.0   \n",
      "9   DirectedSocialNetwork      DeepSeekV3       directprompt        0.0   \n",
      "10  DirectedSocialNetwork      DeepSeekV3  iterativefeedback        0.0   \n",
      "11  DirectedSocialNetwork      DeepSeekV3   programaugmented        0.0   \n",
      "12  DirectedSocialNetwork           GPT4o       directprompt        0.0   \n",
      "13  DirectedSocialNetwork           GPT4o  iterativefeedback        0.0   \n",
      "14  DirectedSocialNetwork           GPT4o   programaugmented        0.0   \n",
      "15  DirectedSocialNetwork       GPT4omini       directprompt        0.0   \n",
      "16  DirectedSocialNetwork       GPT4omini  iterativefeedback        0.0   \n",
      "17  DirectedSocialNetwork       GPT4omini   programaugmented        0.0   \n",
      "18  DirectedSocialNetwork   Gemini20Flash       directprompt        0.0   \n",
      "19  DirectedSocialNetwork   Gemini20Flash  iterativefeedback       40.0   \n",
      "\n",
      "    avg_error_count  avg_structural_errors  avg_logical_errors  \\\n",
      "0               1.0                    0.0                 0.0   \n",
      "1               1.0                    0.0                 0.0   \n",
      "2               1.0                    1.0                 0.0   \n",
      "3               0.0                    0.0                 0.0   \n",
      "4               0.0                    0.0                 0.0   \n",
      "5               0.4                    0.0                 0.0   \n",
      "6               3.6                    0.8                 2.0   \n",
      "7               1.8                    0.2                 1.0   \n",
      "8               7.0                    1.0                 5.0   \n",
      "9               1.8                    0.4                 0.4   \n",
      "10              1.4                    0.4                 0.0   \n",
      "11              5.8                    0.6                 4.2   \n",
      "12              6.6                    0.6                 5.0   \n",
      "13              1.6                    0.2                 0.4   \n",
      "14              4.8                    0.4                 3.4   \n",
      "15              7.8                    0.4                 6.4   \n",
      "16              5.8                    0.6                 4.2   \n",
      "17              1.8                    0.2                 0.6   \n",
      "18              2.2                    0.0                 1.4   \n",
      "19              0.6                    0.0                 0.0   \n",
      "\n",
      "    avg_attribute_errors  avg_structural_passed  avg_logical_passed  \\\n",
      "0                    1.0                    3.0                 2.0   \n",
      "1                    1.0                    3.0                 2.0   \n",
      "2                    0.0                    2.0                 2.0   \n",
      "3                    0.0                    3.0                 2.0   \n",
      "4                    0.0                    3.0                 2.0   \n",
      "5                    0.4                    3.0                 2.0   \n",
      "6                    0.8                    2.2                 1.4   \n",
      "7                    0.6                    2.8                 1.6   \n",
      "8                    1.0                    2.0                 0.8   \n",
      "9                    1.0                    2.6                 1.6   \n",
      "10                   1.0                    2.6                 2.0   \n",
      "11                   1.0                    2.4                 0.6   \n",
      "12                   1.0                    2.4                 0.6   \n",
      "13                   1.0                    2.8                 1.6   \n",
      "14                   1.0                    2.6                 0.8   \n",
      "15                   1.0                    2.6                 0.8   \n",
      "16                   1.0                    2.4                 0.8   \n",
      "17                   1.0                    2.8                 1.8   \n",
      "18                   0.8                    3.0                 1.2   \n",
      "19                   0.6                    3.0                 2.0   \n",
      "\n",
      "    avg_attribute_passed  run_count  \n",
      "0                    3.0          5  \n",
      "1                    3.0          5  \n",
      "2                    4.0          5  \n",
      "3                    4.0          5  \n",
      "4                    4.0          5  \n",
      "5                    3.6          5  \n",
      "6                    3.2          5  \n",
      "7                    3.4          5  \n",
      "8                    3.0          5  \n",
      "9                    3.0          5  \n",
      "10                   3.0          5  \n",
      "11                   3.0          5  \n",
      "12                   3.0          5  \n",
      "13                   3.0          5  \n",
      "14                   3.0          5  \n",
      "15                   3.0          5  \n",
      "16                   3.0          5  \n",
      "17                   3.0          5  \n",
      "18                   3.2          5  \n",
      "19                   3.4          5  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "###############################################################################\n",
    "# 1. FILENAME PATTERN & PROBLEM MAP\n",
    "###############################################################################\n",
    "\n",
    "FILENAME_REGEX = re.compile(r'^(.*?)_(.*?)_(.*?)_run(\\d+)_output\\.json$')\n",
    "\n",
    "PROBLEM_NAME_MAP = {\n",
    "    \"cities\": \"OptimalNetworkDesign\",\n",
    "    \"directedSocialNetwork\": \"DirectedSocialNetwork\",\n",
    "    \"geneAssociation\": \"GeneDiseaseAssociation\",\n",
    "    \"quantum\": \"QuantumCircuit\",\n",
    "    \"timeDependentDeliveryNetwork\": \"TimeDependentDelivery\"\n",
    "}\n",
    "\n",
    "INPUT_GLOB = \"./**/*.json\"\n",
    "PER_RUN_CSV = \"summaries.csv\"\n",
    "AGGREGATED_CSV = \"aggregated_topline.csv\"\n",
    "\n",
    "###############################################################################\n",
    "# 2. SPLIT-ON-PERIOD HELPER\n",
    "###############################################################################\n",
    "\n",
    "def split_by_period_count(msg: str) -> int:\n",
    "    \"\"\"\n",
    "    Splits a message string on '.' and counts the non-empty segments.\n",
    "    This is how we detect multiple distinct error statements in a single constraint message.\n",
    "    \"\"\"\n",
    "    parts = [p.strip() for p in msg.split('.') if p.strip()]\n",
    "    return len(parts)\n",
    "\n",
    "###############################################################################\n",
    "# 3. GROUP MAPPING\n",
    "###############################################################################\n",
    "# Includes constraints from all problems, including \"cities\" (OptimalNetworkDesign).\n",
    "# We map each known constraint key to one of the three groups.\n",
    "\n",
    "CONSTRAINT_GROUPS = {\n",
    "    # Structural group\n",
    "    \"output_structure\": \"Structural\",\n",
    "    \"connectivity\": \"Structural\",\n",
    "    \"road_capacity\": \"Structural\",\n",
    "    \"redundancy\": \"Structural\",\n",
    "    \"max_edges_constraint\": \"Structural\",\n",
    "    \"valid_no_self_loops\": \"Structural\",\n",
    "    \"valid_edge_structure\": \"Structural\",\n",
    "    \"valid_acyclic\": \"Structural\",\n",
    "    \"bipartite_constraint\": \"Structural\",\n",
    "    \"duplicate_associations\": \"Structural\",\n",
    "    \"valid_dag\": \"Structural\",\n",
    "    \"layered_operations\": \"Structural\",\n",
    "    \"degree_constraints\" : \"Structural\",\n",
    "\n",
    "    # Logical group\n",
    "    \"cost_optimization\": \"Logical\",\n",
    "    \"population_accessibility\": \"Logical\",\n",
    "    \"strategic_road_placement\": \"Logical\",\n",
    "    \"valid_celebrity_outgoing\": \"Logical\",\n",
    "    \"valid_regular_to_expert\": \"Logical\",\n",
    "    \"time_window_compliance\": \"Logical\",\n",
    "    \"storage_capacity_compliance\": \"Logical\",\n",
    "    \"vehicle_capacity_compliance\": \"Logical\",\n",
    "    \"valid_gate_precedences\": \"Logical\",\n",
    "    \"valid_cnot_adjacency\": \"Logical\",\n",
    "    \"valid_swap_constraints\": \"Logical\",\n",
    "\n",
    "    # Attribute group\n",
    "    \"valid_user_attributes\": \"Attribute\",\n",
    "    \"valid_total_users\": \"Attribute\",\n",
    "    \"valid_categories\": \"Attribute\",\n",
    "    \"valid_trust_scores\": \"Attribute\",\n",
    "    \"defined_counts\": \"Attribute\",\n",
    "    \"valid_associations\": \"Attribute\",\n",
    "    \"valid_gate_types\": \"Attribute\",\n",
    "    \"valid_qubits\": \"Attribute\",\n",
    "}\n",
    "\n",
    "###############################################################################\n",
    "# 4. COUNTING ERRORS & PASSED CONSTRAINTS\n",
    "###############################################################################\n",
    "\n",
    "def count_constraints_errors(fullOutput: dict) -> int:\n",
    "    \"\"\"\n",
    "    Count the total number of errors by scanning each constraint (top-level & nested).\n",
    "    If the constraint is \"passed\": false, we split its 'message' on '.' to count sub-errors.\n",
    "    If no message, count it as 1 error.\n",
    "\n",
    "    We do NOT look at fullOutput[\"errors\"].\n",
    "    \"\"\"\n",
    "    total_errors = 0\n",
    "\n",
    "    # Check top-level constraints\n",
    "    for key, val in fullOutput.items():\n",
    "        if key in [\"errors\", \"overall_passed\"]:\n",
    "            continue\n",
    "        if isinstance(val, dict) and \"passed\" in val:\n",
    "            if not val[\"passed\"]:\n",
    "                msg = val.get(\"message\", \"\")\n",
    "                count = split_by_period_count(msg) if msg else 1\n",
    "                total_errors += count\n",
    "        elif isinstance(val, bool):\n",
    "            if val is False:\n",
    "                total_errors += 1\n",
    "\n",
    "    # Check nested constraints under \"constraints\"\n",
    "    nested = fullOutput.get(\"constraints\", {})\n",
    "    if isinstance(nested, dict):\n",
    "        for key, val in nested.items():\n",
    "            if isinstance(val, dict) and \"passed\" in val:\n",
    "                if not val[\"passed\"]:\n",
    "                    msg = val.get(\"message\", \"\")\n",
    "                    count = split_by_period_count(msg) if msg else 1\n",
    "                    total_errors += count\n",
    "            elif isinstance(val, bool):\n",
    "                if val is False:\n",
    "                    total_errors += 1\n",
    "\n",
    "    return total_errors\n",
    "\n",
    "def count_grouped_errors(fullOutput: dict) -> dict:\n",
    "    \"\"\"\n",
    "    For each constraint in fullOutput and fullOutput[\"constraints\"] that fails,\n",
    "    find which group it belongs to (if any), and count sub-errors by splitting on '.'.\n",
    "    If no message, count as 1. Return a dict: { \"Structural\": X, \"Logical\": Y, \"Attribute\": Z }\n",
    "    \"\"\"\n",
    "    groups = {\"Structural\": 0, \"Logical\": 0, \"Attribute\": 0}\n",
    "\n",
    "    # Top-level\n",
    "    for key, val in fullOutput.items():\n",
    "        if key in [\"errors\", \"overall_passed\"]:\n",
    "            continue\n",
    "        group = CONSTRAINT_GROUPS.get(key)\n",
    "        if group:\n",
    "            if isinstance(val, dict) and \"passed\" in val:\n",
    "                if not val[\"passed\"]:\n",
    "                    msg = val.get(\"message\", \"\")\n",
    "                    count = split_by_period_count(msg) if msg else 1\n",
    "                    groups[group] += count\n",
    "            elif isinstance(val, bool):\n",
    "                if val is False:\n",
    "                    groups[group] += 1\n",
    "\n",
    "    # Nested constraints\n",
    "    nested = fullOutput.get(\"constraints\", {})\n",
    "    if isinstance(nested, dict):\n",
    "        for key, val in nested.items():\n",
    "            group = CONSTRAINT_GROUPS.get(key)\n",
    "            if group:\n",
    "                if isinstance(val, dict) and \"passed\" in val:\n",
    "                    if not val[\"passed\"]:\n",
    "                        msg = val.get(\"message\", \"\")\n",
    "                        count = split_by_period_count(msg) if msg else 1\n",
    "                        groups[group] += count\n",
    "                elif isinstance(val, bool):\n",
    "                    if val is False:\n",
    "                        groups[group] += 1\n",
    "    return groups\n",
    "\n",
    "def count_grouped_passed(fullOutput: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Similar to count_grouped_errors, but we count how many constraints in each group are PASSED.\n",
    "    Return a dict: { \"Structural\": X, \"Logical\": Y, \"Attribute\": Z } indicating how many passed.\n",
    "    \"\"\"\n",
    "    passed_counts = {\"Structural\": 0, \"Logical\": 0, \"Attribute\": 0}\n",
    "\n",
    "    # Top-level\n",
    "    for key, val in fullOutput.items():\n",
    "        if key in [\"errors\", \"overall_passed\"]:\n",
    "            continue\n",
    "        group = CONSTRAINT_GROUPS.get(key)\n",
    "        if group:\n",
    "            if isinstance(val, dict) and \"passed\" in val:\n",
    "                if val[\"passed\"]:\n",
    "                    passed_counts[group] += 1\n",
    "            elif isinstance(val, bool):\n",
    "                if val is True:\n",
    "                    passed_counts[group] += 1\n",
    "\n",
    "    # Nested constraints\n",
    "    nested = fullOutput.get(\"constraints\", {})\n",
    "    if isinstance(nested, dict):\n",
    "        for key, val in nested.items():\n",
    "            group = CONSTRAINT_GROUPS.get(key)\n",
    "            if group:\n",
    "                if isinstance(val, dict) and \"passed\" in val:\n",
    "                    if val[\"passed\"]:\n",
    "                        passed_counts[group] += 1\n",
    "                elif isinstance(val, bool):\n",
    "                    if val is True:\n",
    "                        passed_counts[group] += 1\n",
    "\n",
    "    return passed_counts\n",
    "\n",
    "###############################################################################\n",
    "# 5. PER-RUN PARSING\n",
    "###############################################################################\n",
    "\n",
    "def parse_json_file(filepath: str) -> dict | None:\n",
    "    \"\"\"\n",
    "    Parse a single JSON file => produce a run-level summary row with:\n",
    "      - overall_passed\n",
    "      - constraints_passed, constraints_total\n",
    "      - error_count\n",
    "      - structural_errors, logical_errors, attribute_errors\n",
    "      - structural_constraints_passed, logical_constraints_passed, attribute_constraints_passed\n",
    "    We ignore fullOutput[\"errors\"] array for counting errors.\n",
    "    \"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    m = FILENAME_REGEX.match(filename)\n",
    "    if not m:\n",
    "        return None\n",
    "    problem_raw = m.group(1)\n",
    "    model_name = m.group(2)\n",
    "    prompt_type = m.group(3)\n",
    "    run_number = int(m.group(4))\n",
    "    if not (1 <= run_number <= 5):\n",
    "        return None\n",
    "\n",
    "    problem_name = PROBLEM_NAME_MAP.get(problem_raw, problem_raw)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    overall_passed = False\n",
    "    fo = data.get(\"fullOutput\", {})\n",
    "    if isinstance(data.get(\"result\"), bool):\n",
    "        overall_passed = data[\"result\"]\n",
    "    if isinstance(fo.get(\"overall_passed\"), bool):\n",
    "        overall_passed = fo[\"overall_passed\"]\n",
    "\n",
    "    # Count how many constraints are passed/total (for info)\n",
    "    constraints_passed = 0\n",
    "    constraints_total = 0\n",
    "    if isinstance(fo, dict):\n",
    "        # top-level\n",
    "        for key, val in fo.items():\n",
    "            if key in [\"errors\", \"overall_passed\"]:\n",
    "                continue\n",
    "            if isinstance(val, dict) and \"passed\" in val:\n",
    "                constraints_total += 1\n",
    "                if val[\"passed\"]:\n",
    "                    constraints_passed += 1\n",
    "            elif isinstance(val, bool):\n",
    "                constraints_total += 1\n",
    "                if val:\n",
    "                    constraints_passed += 1\n",
    "        # nested constraints\n",
    "        nested = fo.get(\"constraints\", {})\n",
    "        if isinstance(nested, dict):\n",
    "            for key, val in nested.items():\n",
    "                if isinstance(val, dict) and \"passed\" in val:\n",
    "                    constraints_total += 1\n",
    "                    if val[\"passed\"]:\n",
    "                        constraints_passed += 1\n",
    "                elif isinstance(val, bool):\n",
    "                    constraints_total += 1\n",
    "                    if val:\n",
    "                        constraints_passed += 1\n",
    "\n",
    "    # Overall error_count from constraints only\n",
    "    error_count = count_constraints_errors(fo)\n",
    "\n",
    "    # Grouped error counts (failing constraints)\n",
    "    group_errs = count_grouped_errors(fo)\n",
    "\n",
    "    # Grouped pass counts (passing constraints)\n",
    "    group_passed = count_grouped_passed(fo)\n",
    "\n",
    "    return {\n",
    "        \"filename\": filename,\n",
    "        \"problem\": problem_name,\n",
    "        \"model\": model_name,\n",
    "        \"prompt_type\": prompt_type,\n",
    "        \"run_number\": run_number,\n",
    "        \"overall_passed\": overall_passed,\n",
    "        \"constraints_passed\": constraints_passed,\n",
    "        \"constraints_total\": constraints_total,\n",
    "        \"error_count\": error_count,\n",
    "\n",
    "        # failing constraints\n",
    "        \"structural_errors\": group_errs[\"Structural\"],\n",
    "        \"logical_errors\": group_errs[\"Logical\"],\n",
    "        \"attribute_errors\": group_errs[\"Attribute\"],\n",
    "\n",
    "        # passing constraints\n",
    "        \"structural_constraints_passed\": group_passed[\"Structural\"],\n",
    "        \"logical_constraints_passed\": group_passed[\"Logical\"],\n",
    "        \"attribute_constraints_passed\": group_passed[\"Attribute\"]\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 6. BUILD PER-RUN SUMMARY\n",
    "###############################################################################\n",
    "\n",
    "def build_summary_csv(input_glob: str, output_csv: str):\n",
    "    rows = []\n",
    "    for filepath in glob.glob(input_glob, recursive=True):\n",
    "        if filepath.endswith(\".json\"):\n",
    "            row = parse_json_file(filepath)\n",
    "            if row is not None:\n",
    "                rows.append(row)\n",
    "    # remove duplicates\n",
    "    seen = set()\n",
    "    unique_rows = []\n",
    "    for r in rows:\n",
    "        combo = (r[\"problem\"], r[\"model\"], r[\"prompt_type\"], r[\"run_number\"])\n",
    "        if combo not in seen:\n",
    "            seen.add(combo)\n",
    "            unique_rows.append(r)\n",
    "    unique_rows.sort(key=lambda r: (r[\"problem\"], r[\"model\"], r[\"prompt_type\"], r[\"run_number\"]))\n",
    "\n",
    "    fieldnames = [\n",
    "        \"filename\", \"problem\", \"model\", \"prompt_type\", \"run_number\",\n",
    "        \"overall_passed\", \"constraints_passed\", \"constraints_total\", \"error_count\",\n",
    "        \"structural_errors\", \"logical_errors\", \"attribute_errors\",\n",
    "        \"structural_constraints_passed\", \"logical_constraints_passed\", \"attribute_constraints_passed\"\n",
    "    ]\n",
    "    with open(output_csv, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(unique_rows)\n",
    "    print(f\"Wrote {len(unique_rows)} per-run summary rows to {output_csv}\")\n",
    "\n",
    "###############################################################################\n",
    "# 7. AGGREGATE INTO TOP-LINE\n",
    "###############################################################################\n",
    "\n",
    "def aggregate_grouped_summary(input_csv: str, output_csv: str):\n",
    "    df = pd.read_csv(input_csv)\n",
    "    # group by problem, model, prompt_type\n",
    "    group_cols = [\"problem\", \"model\", \"prompt_type\"]\n",
    "    # keep only combos that have exactly 5 runs\n",
    "    run_counts = df.groupby(group_cols)[\"run_number\"].nunique().reset_index().rename(columns={\"run_number\": \"run_count\"})\n",
    "    valid_groups = run_counts[run_counts[\"run_count\"] == 5][group_cols]\n",
    "    df_valid = pd.merge(df, valid_groups, on=group_cols, how=\"inner\")\n",
    "\n",
    "    agg = df_valid.groupby(group_cols, dropna=False).agg(\n",
    "        pass_rate = (\"overall_passed\", \"mean\"),\n",
    "        avg_error_count = (\"error_count\", \"mean\"),\n",
    "        avg_structural_errors = (\"structural_errors\", \"mean\"),\n",
    "        avg_logical_errors = (\"logical_errors\", \"mean\"),\n",
    "        avg_attribute_errors = (\"attribute_errors\", \"mean\"),\n",
    "\n",
    "        avg_structural_passed = (\"structural_constraints_passed\", \"mean\"),\n",
    "        avg_logical_passed = (\"logical_constraints_passed\", \"mean\"),\n",
    "        avg_attribute_passed = (\"attribute_constraints_passed\", \"mean\"),\n",
    "\n",
    "        run_count = (\"run_number\", \"count\")\n",
    "    ).reset_index()\n",
    "\n",
    "    # convert pass_rate to percentage and round\n",
    "    agg[\"pass_rate\"] = (agg[\"pass_rate\"] * 100).round(1)\n",
    "    agg[\"avg_error_count\"] = agg[\"avg_error_count\"].round(2)\n",
    "    agg[\"avg_structural_errors\"] = agg[\"avg_structural_errors\"].round(2)\n",
    "    agg[\"avg_logical_errors\"] = agg[\"avg_logical_errors\"].round(2)\n",
    "    agg[\"avg_attribute_errors\"] = agg[\"avg_attribute_errors\"].round(2)\n",
    "\n",
    "    agg[\"avg_structural_passed\"] = agg[\"avg_structural_passed\"].round(2)\n",
    "    agg[\"avg_logical_passed\"] = agg[\"avg_logical_passed\"].round(2)\n",
    "    agg[\"avg_attribute_passed\"] = agg[\"avg_attribute_passed\"].round(2)\n",
    "\n",
    "    agg.to_csv(output_csv, index=False)\n",
    "    print(f\"Wrote aggregated top-line summary to {output_csv}\")\n",
    "    print(agg.head(20))\n",
    "\n",
    "###############################################################################\n",
    "# 8. MAIN\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_summary_csv(INPUT_GLOB, PER_RUN_CSV)\n",
    "    aggregate_grouped_summary(PER_RUN_CSV, AGGREGATED_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77ff765",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
