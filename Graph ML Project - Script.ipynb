{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20d72e7",
   "metadata": {},
   "source": [
    "### For the program augmented prompt, add \"Here is the script that I will use to verify your output: \"INSERT SCRIPT\" to the end of the direct prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f600d",
   "metadata": {},
   "source": [
    "# Time-Dependent Delivery Network\n",
    "\n",
    "Design a time-dependent delivery network based on the specifications below.\n",
    "\n",
    "## Problem Description:\n",
    "Create a delivery network that schedules deliveries across multiple locations using a fleet of vehicles. The network must account for vehicle capacities, location storage capacities, delivery time windows, dynamic travel times, and vehicle speeds to ensure efficient and timely deliveries.\n",
    "\n",
    "## Constraints:\n",
    "1. **Locations:**\n",
    "   - **Total Locations:** 15, labeled from `L0` to `L14`.\n",
    "   - **Attributes:**\n",
    "     - **Storage Capacity:** Each location has a storage capacity specified in kilograms (kg). Example: `L0` has a capacity of 500 kg.\n",
    "     - **Time Window:** Each location has a delivery time window represented as a list of two integers `[start_hour, end_hour]` in 24-hour format. Example: `L3` has a time window of `[9, 11]` corresponding to 09:00-11:00.\n",
    "\n",
    "2. **Vehicles:**\n",
    "   - **Total Vehicles:** 7, labeled from `V1` to `V7`.\n",
    "   - **Attributes:**\n",
    "     - **Capacity:** Each vehicle has a specific capacity in kilograms (kg). Example: `V1` has a capacity of 100 kg.\n",
    "     - **Speed:** Each vehicle has a defined speed in kilometers per hour (km/h). Example: `V1` travels at 60 km/h.\n",
    "\n",
    "3. **Edges (Routes):**\n",
    "   - **Definition:** Represents travel paths between two distinct locations.\n",
    "   - **Attributes:**\n",
    "     - **From:** The starting location ID (e.g., `L0`).\n",
    "     - **To:** The destination location ID (e.g., `L1`).\n",
    "     - **Base Travel Time:** The fundamental travel time for the route in minutes.\n",
    "     - **Hourly Adjustments:** A dictionary where keys are time ranges in the format `\"HH-HH\"` (24-hour format) and values are additional travel time in minutes applicable during those hours. Example: `{\"8-10\": 15}` adds 15 minutes to the base travel time between 08:00-10:00.\n",
    "     - **Maximum Weight Limit:** The maximum weight a vehicle can carry on that route in kilograms (kg).\n",
    "\n",
    "4. **Operational Constraints:**\n",
    "   - **Storage Capacity Compliance:** The sum of incoming goods to any location must not exceed its storage capacity.\n",
    "   - **Vehicle Capacity Compliance:** No vehicle should exceed its capacity on any edge it traverses.\n",
    "   - **Time Window Compliance:** Departures and arrivals must respect the time windows of locations. Specifically:\n",
    "     - **Departure Time:** Must be within the `from` location's time window.\n",
    "     - **Arrival Time:** Must be within the `to` location's time window.\n",
    "     - **Loading Time:** Assume a fixed loading time of 10 minutes at each location, which must be accounted for when scheduling departures.\n",
    "\n",
    "## Required Output Format:\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "locations = [\n",
    "    {\"id\": \"L0\", \"capacity\": int, \"time_window\": [int, int]},\n",
    "    {\"id\": \"L1\", \"capacity\": int, \"time_window\": [int, int]},\n",
    "    # ... all locations (L2-L14)\n",
    "]\n",
    "\n",
    "vehicles = [\n",
    "    {\"id\": \"V1\", \"capacity\": int, \"speed\": int},\n",
    "    {\"id\": \"V2\", \"capacity\": int, \"speed\": int},\n",
    "    # ... all vehicles (V3-V7)\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    {\"from\": \"L0\", \"to\": \"L1\", \"base_time\": int, \"hourly_adjust\": {\"HH-HH\": int}, \"max_weight\": int},\n",
    "    {\"from\": \"L1\", \"to\": \"L2\", \"base_time\": int, \"hourly_adjust\": {\"HH-HH\": int}, \"max_weight\": int},\n",
    "    # ... more edges\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c234d47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(False, {'output_structure': {'passed': True, 'message': ''}, 'storage_capacity_compliance': {'passed': False, 'message': \"Total incoming 'max_weight' to location 'L1' is 400 kg, exceeding its storage capacity of 350 kg. Total incoming 'max_weight' to location 'L2' is 400 kg, exceeding its storage capacity of 350 kg. Total incoming 'max_weight' to location 'L5' is 400 kg, exceeding its storage capacity of 350 kg. Total incoming 'max_weight' to location 'L7' is 400 kg, exceeding its storage capacity of 380 kg.\"}, 'vehicle_capacity_compliance': {'passed': True, 'message': ''}, 'time_window_compliance': {'passed': False, 'message': \"Edge from 'L10' to 'L3' with total travel time 55 minutes does not fit within the time windows of 'L10' [10-15] and 'L3' [9-11].\"}, 'overall_passed': False, 'errors': ['Storage Capacity Compliance Check Failed.', 'Time Window Compliance Check Failed.']})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def verify_time_dependent_delivery_network(locations, vehicles, edges):\n",
    "    verification_results = {\n",
    "        \"output_structure\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"storage_capacity_compliance\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"vehicle_capacity_compliance\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"time_window_compliance\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"overall_passed\": False,\n",
    "        \"errors\": []\n",
    "    }\n",
    "    def add_error(message):\n",
    "        verification_results[\"errors\"].append(message)\n",
    "\n",
    "    if not isinstance(locations, list):\n",
    "        add_error(\"'locations' should be a list.\")\n",
    "    elif len(locations) != 15:\n",
    "        add_error(f\"Number of locations is {len(locations)}; expected 15.\")\n",
    "    else:\n",
    "        location_ids = set()\n",
    "        location_valid = True\n",
    "        for loc in locations:\n",
    "            if not isinstance(loc, dict):\n",
    "                add_error(\"Each location should be a dictionary.\")\n",
    "                location_valid = False\n",
    "                continue\n",
    "            required_loc_keys = {\"id\", \"capacity\", \"time_window\"}\n",
    "            if not required_loc_keys.issubset(loc.keys()):\n",
    "                add_error(f\"Location {loc.get('id', 'Unknown')} is missing required keys: {required_loc_keys - set(loc.keys())}.\")\n",
    "                location_valid = False\n",
    "                continue\n",
    "            if not re.fullmatch(r\"L\\d+\", loc[\"id\"]):\n",
    "                add_error(f\"Location ID '{loc['id']}' is invalid. Expected format 'L0' to 'L14'.\")\n",
    "                location_valid = False\n",
    "            location_ids.add(loc[\"id\"])\n",
    "            if not isinstance(loc[\"capacity\"], int) or loc[\"capacity\"] <= 0:\n",
    "                add_error(f\"Location '{loc['id']}' has invalid 'capacity'. Must be a positive integer.\")\n",
    "                location_valid = False\n",
    "            if (not isinstance(loc[\"time_window\"], list) or\n",
    "                len(loc[\"time_window\"]) != 2 or\n",
    "                not all(isinstance(t, int) for t in loc[\"time_window\"])):\n",
    "                add_error(f\"Location '{loc['id']}' has invalid 'time_window'. Must be a list of two integers.\")\n",
    "                location_valid = False\n",
    "            else:\n",
    "                start, end = loc[\"time_window\"]\n",
    "                if not (0 <= start < end <= 24):\n",
    "                    add_error(f\"Location '{loc['id']}' has invalid 'time_window' values: {loc['time_window']}. Must satisfy 0 <= start < end <= 24.\")\n",
    "                    location_valid = False\n",
    "        if location_valid:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = True\n",
    "        else:\n",
    "            verification_results[\"output_structure\"][\"message\"] = \"Errors found in 'locations' structure.\"\n",
    "    \n",
    "    if not isinstance(vehicles, list):\n",
    "        add_error(\"'vehicles' should be a list.\")\n",
    "    elif len(vehicles) != 7:\n",
    "        add_error(f\"Number of vehicles is {len(vehicles)}; expected 7.\")\n",
    "    else:\n",
    "        vehicle_ids = set()\n",
    "        vehicle_valid = True\n",
    "        vehicle_capacities = []\n",
    "        for veh in vehicles:\n",
    "            if not isinstance(veh, dict):\n",
    "                add_error(\"Each vehicle should be a dictionary.\")\n",
    "                vehicle_valid = False\n",
    "                continue\n",
    "            required_veh_keys = {\"id\", \"capacity\", \"speed\"}\n",
    "            if not required_veh_keys.issubset(veh.keys()):\n",
    "                add_error(f\"Vehicle {veh.get('id', 'Unknown')} is missing required keys: {required_veh_keys - set(veh.keys())}.\")\n",
    "                vehicle_valid = False\n",
    "                continue\n",
    "            if not re.fullmatch(r\"V\\d+\", veh[\"id\"]):\n",
    "                add_error(f\"Vehicle ID '{veh['id']}' is invalid. Expected format 'V1' to 'V7'.\")\n",
    "                vehicle_valid = False\n",
    "            vehicle_ids.add(veh[\"id\"])\n",
    "            if not isinstance(veh[\"capacity\"], int) or veh[\"capacity\"] <= 0:\n",
    "                add_error(f\"Vehicle '{veh['id']}' has invalid 'capacity'. Must be a positive integer.\")\n",
    "                vehicle_valid = False\n",
    "            else:\n",
    "                vehicle_capacities.append(veh[\"capacity\"])\n",
    "            if not isinstance(veh[\"speed\"], int) or veh[\"speed\"] <= 0:\n",
    "                add_error(f\"Vehicle '{veh['id']}' has invalid 'speed'. Must be a positive integer.\")\n",
    "                vehicle_valid = False\n",
    "        if vehicle_valid:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = verification_results[\"output_structure\"][\"passed\"] and True\n",
    "        else:\n",
    "            verification_results[\"output_structure\"][\"message\"] += \" Errors found in 'vehicles' structure.\"\n",
    "    \n",
    "    if not isinstance(edges, list):\n",
    "        add_error(\"'edges' should be a list.\")\n",
    "    elif len(edges) == 0:\n",
    "        add_error(\"No edges defined in the network.\")\n",
    "    else:\n",
    "        edge_pairs = set()\n",
    "        incoming_weights = defaultdict(int)\n",
    "        edge_valid = True\n",
    "        for edge in edges:\n",
    "            if not isinstance(edge, dict):\n",
    "                add_error(\"Each edge should be a dictionary.\")\n",
    "                edge_valid = False\n",
    "                continue\n",
    "            required_edge_keys = {\"from\", \"to\", \"base_time\", \"hourly_adjust\", \"max_weight\"}\n",
    "            if not required_edge_keys.issubset(edge.keys()):\n",
    "                add_error(f\"Edge from '{edge.get('from', 'Unknown')}' to '{edge.get('to', 'Unknown')}' is missing required keys: {required_edge_keys - set(edge.keys())}.\")\n",
    "                edge_valid = False\n",
    "                continue\n",
    "            from_id = edge[\"from\"]\n",
    "            to_id = edge[\"to\"]\n",
    "            if from_id not in location_ids:\n",
    "                add_error(f\"Edge 'from' location '{from_id}' is not defined among locations.\")\n",
    "                edge_valid = False\n",
    "            if to_id not in location_ids:\n",
    "                add_error(f\"Edge 'to' location '{to_id}' is not defined among locations.\")\n",
    "                edge_valid = False\n",
    "            pair = (from_id, to_id)\n",
    "            if pair in edge_pairs:\n",
    "                add_error(f\"Duplicate edge detected from '{from_id}' to '{to_id}'.\")\n",
    "                edge_valid = False\n",
    "            else:\n",
    "                edge_pairs.add(pair)\n",
    "            if not isinstance(edge[\"base_time\"], int) or edge[\"base_time\"] <= 0:\n",
    "                add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid 'base_time'. Must be a positive integer.\")\n",
    "                edge_valid = False\n",
    "            if not isinstance(edge[\"hourly_adjust\"], dict):\n",
    "                add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid 'hourly_adjust'. Must be a dictionary.\")\n",
    "                edge_valid = False\n",
    "            else:\n",
    "                for time_range, adjustment in edge[\"hourly_adjust\"].items():\n",
    "                    if not re.fullmatch(r\"\\d{1,2}-\\d{1,2}\", time_range):\n",
    "                        add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid time range '{time_range}' in 'hourly_adjust'. Expected format 'HH-HH'.\")\n",
    "                        edge_valid = False\n",
    "                        continue\n",
    "                    start, end = map(int, time_range.split('-'))\n",
    "                    if not (0 <= start < end <= 24):\n",
    "                        add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid time range values '{time_range}'. Must satisfy 0 <= start < end <= 24.\")\n",
    "                        edge_valid = False\n",
    "                    if not isinstance(adjustment, int) or adjustment < 0:\n",
    "                        add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid adjustment value '{adjustment}' for time range '{time_range}'. Must be a non-negative integer.\")\n",
    "                        edge_valid = False\n",
    "            if not isinstance(edge[\"max_weight\"], int) or edge[\"max_weight\"] <= 0:\n",
    "                add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid 'max_weight'. Must be a positive integer.\")\n",
    "                edge_valid = False\n",
    "            else:\n",
    "                incoming_weights[to_id] += edge[\"max_weight\"]\n",
    "        if edge_valid:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = verification_results[\"output_structure\"][\"passed\"] and True\n",
    "        else:\n",
    "            verification_results[\"output_structure\"][\"message\"] += \" Errors found in 'edges' structure.\"\n",
    "    \n",
    "\n",
    "    storage_compliance_passed = True\n",
    "    storage_errors = []\n",
    "    loc_capacity_map = {loc[\"id\"]: loc[\"capacity\"] for loc in locations}\n",
    "    for loc_id, total_incoming in incoming_weights.items():\n",
    "        capacity = loc_capacity_map.get(loc_id, 0)\n",
    "        if total_incoming > capacity:\n",
    "            storage_compliance_passed = False\n",
    "            storage_errors.append(f\"Total incoming 'max_weight' to location '{loc_id}' is {total_incoming} kg, exceeding its storage capacity of {capacity} kg.\")\n",
    "    if storage_compliance_passed:\n",
    "        verification_results[\"storage_capacity_compliance\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"storage_capacity_compliance\"][\"message\"] = \" \".join(storage_errors)\n",
    "        add_error(\"Storage Capacity Compliance Check Failed.\")\n",
    "    \n",
    "    vehicle_capacity_passed = True\n",
    "    vehicle_errors = []\n",
    "    if not vehicle_capacities:\n",
    "        vehicle_capacity_passed = False\n",
    "        vehicle_errors.append(\"No valid vehicle capacities found.\")\n",
    "    else:\n",
    "        max_vehicle_capacity = max(vehicle_capacities)\n",
    "        for edge in edges:\n",
    "            if edge[\"max_weight\"] < max_vehicle_capacity:\n",
    "                vehicle_capacity_passed = False\n",
    "                vehicle_errors.append(f\"Edge from '{edge['from']}' to '{edge['to']}' has 'max_weight' {edge['max_weight']} kg, which is less than the maximum vehicle capacity of {max_vehicle_capacity} kg.\")\n",
    "    if vehicle_capacity_passed:\n",
    "        verification_results[\"vehicle_capacity_compliance\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"vehicle_capacity_compliance\"][\"message\"] = \" \".join(vehicle_errors)\n",
    "        add_error(\"Vehicle Capacity Compliance Check Failed.\")\n",
    "    \n",
    "    time_window_passed = True\n",
    "    time_window_errors = []\n",
    "    loc_time_map = {loc[\"id\"]: loc[\"time_window\"] for loc in locations}\n",
    "    for edge in edges:\n",
    "        from_id = edge[\"from\"]\n",
    "        to_id = edge[\"to\"]\n",
    "        base_time = edge[\"base_time\"]  \n",
    "        hourly_adjust = edge[\"hourly_adjust\"] \n",
    "        max_adjust = max(hourly_adjust.values()) if hourly_adjust else 0\n",
    "        total_travel_time = base_time + max_adjust  # in minutes\n",
    "        total_travel_hours = (total_travel_time + 59) // 60 \n",
    "        from_tw_start, from_tw_end = loc_time_map[from_id]\n",
    "        to_tw_start, to_tw_end = loc_time_map[to_id]\n",
    "        feasible = False\n",
    "        for dep_hour in range(from_tw_start, from_tw_end):\n",
    "            dep_time = dep_hour + 0.17 \n",
    "            arr_time = dep_time + (total_travel_time / 60)\n",
    "            if to_tw_start <= arr_time <= to_tw_end:\n",
    "                feasible = True\n",
    "                break\n",
    "        if not feasible:\n",
    "            time_window_passed = False\n",
    "            time_window_errors.append(f\"Edge from '{from_id}' to '{to_id}' with total travel time {total_travel_time} minutes does not fit within the time windows of '{from_id}' [{from_tw_start}-{from_tw_end}] and '{to_id}' [{to_tw_start}-{to_tw_end}].\")\n",
    "    if time_window_passed:\n",
    "        verification_results[\"time_window_compliance\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"time_window_compliance\"][\"message\"] = \" \".join(time_window_errors)\n",
    "        add_error(\"Time Window Compliance Check Failed.\")\n",
    "    \n",
    "    overall_passed = all([\n",
    "        verification_results[\"output_structure\"][\"passed\"],\n",
    "        verification_results[\"storage_capacity_compliance\"][\"passed\"],\n",
    "        verification_results[\"vehicle_capacity_compliance\"][\"passed\"],\n",
    "        verification_results[\"time_window_compliance\"][\"passed\"]\n",
    "    ])\n",
    "    verification_results[\"overall_passed\"] = overall_passed\n",
    "    \n",
    "    return overall_passed, verification_results\n",
    "\n",
    "locations = [  \n",
    "    {\"id\": \"L0\", \"capacity\": 500, \"time_window\": [8, 18]},  \n",
    "    {\"id\": \"L1\", \"capacity\": 350, \"time_window\": [9, 15]},  \n",
    "    {\"id\": \"L2\", \"capacity\": 350, \"time_window\": [10, 16]},  \n",
    "    {\"id\": \"L3\", \"capacity\": 400, \"time_window\": [9, 11]},  \n",
    "    {\"id\": \"L4\", \"capacity\": 400, \"time_window\": [10, 14]},  \n",
    "    {\"id\": \"L5\", \"capacity\": 350, \"time_window\": [8, 12]},  \n",
    "    {\"id\": \"L6\", \"capacity\": 450, \"time_window\": [11, 17]},  \n",
    "    {\"id\": \"L7\", \"capacity\": 380, \"time_window\": [8, 14]},  \n",
    "    {\"id\": \"L8\", \"capacity\": 320, \"time_window\": [12, 18]},  \n",
    "    {\"id\": \"L9\", \"capacity\": 280, \"time_window\": [9, 13]},  \n",
    "    {\"id\": \"L10\", \"capacity\": 420, \"time_window\": [10, 15]},  \n",
    "    {\"id\": \"L11\", \"capacity\": 370, \"time_window\": [11, 16]},  \n",
    "    {\"id\": \"L12\", \"capacity\": 290, \"time_window\": [8, 13]},  \n",
    "    {\"id\": \"L13\", \"capacity\": 330, \"time_window\": [9, 17]},  \n",
    "    {\"id\": \"L14\", \"capacity\": 310, \"time_window\": [10, 18]}  \n",
    "]  \n",
    "\n",
    "vehicles = [  \n",
    "    {\"id\": \"V1\", \"capacity\": 100, \"speed\": 60},  \n",
    "    {\"id\": \"V2\", \"capacity\": 150, \"speed\": 55},  \n",
    "    {\"id\": \"V3\", \"capacity\": 120, \"speed\": 65},  \n",
    "    {\"id\": \"V4\", \"capacity\": 180, \"speed\": 50},  \n",
    "    {\"id\": \"V5\", \"capacity\": 130, \"speed\": 58},  \n",
    "    {\"id\": \"V6\", \"capacity\": 200, \"speed\": 45},  \n",
    "    {\"id\": \"V7\", \"capacity\": 160, \"speed\": 52}  \n",
    "]  \n",
    "\n",
    "edges = [  \n",
    "    {\"from\": \"L0\", \"to\": \"L1\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L0\", \"to\": \"L2\", \"base_time\": 45, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 25}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L0\", \"to\": \"L3\", \"base_time\": 40, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L0\", \"to\": \"L4\", \"base_time\": 35, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 15}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L1\", \"to\": \"L5\", \"base_time\": 25, \"hourly_adjust\": {\"8-10\": 10, \"16-18\": 15}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L1\", \"to\": \"L6\", \"base_time\": 40, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L2\", \"to\": \"L7\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L2\", \"to\": \"L8\", \"base_time\": 35, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 25}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L3\", \"to\": \"L9\", \"base_time\": 25, \"hourly_adjust\": {\"8-10\": 10, \"16-18\": 15}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L3\", \"to\": \"L10\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L4\", \"to\": \"L11\", \"base_time\": 40, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 25}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L4\", \"to\": \"L12\", \"base_time\": 35, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L5\", \"to\": \"L13\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 10, \"16-18\": 15}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L6\", \"to\": \"L14\", \"base_time\": 25, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L7\", \"to\": \"L0\", \"base_time\": 50, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 25}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L8\", \"to\": \"L1\", \"base_time\": 45, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L9\", \"to\": \"L2\", \"base_time\": 40, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 25}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L10\", \"to\": \"L3\", \"base_time\": 35, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L11\", \"to\": \"L4\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 10, \"16-18\": 15}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L12\", \"to\": \"L5\", \"base_time\": 40, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L13\", \"to\": \"L6\", \"base_time\": 35, \"hourly_adjust\": {\"8-10\": 20, \"16-18\": 25}, \"max_weight\": 200},  \n",
    "    {\"from\": \"L14\", \"to\": \"L7\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 15, \"16-18\": 20}, \"max_weight\": 200}  \n",
    "]  \n",
    "verification_output = verify_time_dependent_delivery_network(locations, vehicles, edges)\n",
    "print(verification_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b68dcb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. GPT4omini\n",
      "2. Claude35Haiku\n",
      "3. Gemini20Flash\n",
      "4. DeepSeekV3\n",
      "5. Llama32\n",
      "6. GPT4o\n",
      "7. Claude35Sonnet\n",
      "8. Gemini20Pro\n",
      "9. Llama31405B\n",
      "10. DeepSeekR1\n",
      "11. o3mini\n",
      "12. o1\n",
      "13. Llama318B\n",
      "14. GrokV3\n",
      "15. Claude37Sonnet\n",
      "Select a model by number: 15\n",
      "\n",
      "Available Prompt Types:\n",
      "1. directprompt\n",
      "2. iterativefeedback\n",
      "3. programaugmented\n",
      "Select a prompt type by number: 3\n",
      "\n",
      "Enter the run number (1-5): 5\n",
      "Save is succesful! results/timeDependentDeliveryNetwork_Claude37Sonnet_programaugmented_run5_output.json\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama32\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini20Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\", \"Llama318B\", \"GrokV3\",\"Claude37Sonnet\"]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"timeDependentDeliveryNetwork\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"locations\": locations,\n",
    "    \"vehicles\": vehicles,\n",
    "    \"edges\": edges,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d05c9",
   "metadata": {},
   "source": [
    "### # Directed Social Network with Influence Relationships\n",
    "\n",
    "Design a directed social network based on the specifications below.\n",
    "\n",
    "## Problem Description:\n",
    "Create a social network graph representing influence relationships among users. Each user has specific attributes, and influence connections must adhere to defined constraints to maintain the integrity and intended structure of the network.\n",
    "\n",
    "## Constraints:\n",
    "1. **Users:**\n",
    "   - Total of 20 users labeled from U0 to U19.\n",
    "   - Each user has a \"trust_score\" ranging from 0 to 100.\n",
    "   - Each user belongs to a \"category\" based on their trust score:\n",
    "     - \"celebrity\" (trust_score ≥ 80)\n",
    "     - \"expert\" (70 ≤ trust_score < 80)\n",
    "     - \"regular\" (trust_score < 50)\n",
    "\n",
    "2. **Edges (Influence Relationships):**\n",
    "   - Directed edges where Ux → Uy indicates that Ux influences Uy.\n",
    "   - **No self-loops:** A user cannot influence themselves.\n",
    "   - **Category Constraints:**\n",
    "     - **Celebrities:** Must have at least 5 outgoing edges.\n",
    "     - **Regular Users:** Cannot influence experts.\n",
    "   - **Graph Structure:**\n",
    "     - The graph must be acyclic (no cycles in influence relationships).\n",
    "\n",
    "### Required Output Format:\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "\n",
    "users = [\n",
    "    {\"id\": \"U0\", \"trust_score\": int, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U1\", \"trust_score\": int, \"category\": \"regular\"},\n",
    "    {\"id\": \"U2\", \"trust_score\": int, \"category\": \"expert\"},\n",
    "    # ... all users (U3-U19)\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    {\"from\": \"U0\", \"to\": \"U1\"},\n",
    "    {\"from: \"U0\", \"to\": \"U2\"},\n",
    "    {\"from\": \"U2\", \"to\": \"U3\"},\n",
    "    # ... more edges\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "687fbd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Output: (True, {'valid_no_self_loops': {'passed': True, 'message': ''}, 'valid_celebrity_outgoing': {'passed': True, 'message': ''}, 'valid_regular_to_expert': {'passed': True, 'message': ''}, 'valid_acyclic': {'passed': True, 'message': ''}, 'valid_user_attributes': {'passed': True, 'message': ''}, 'valid_edge_structure': {'passed': True, 'message': ''}, 'valid_total_users': {'passed': True, 'message': ''}, 'valid_categories': {'passed': True, 'message': ''}, 'valid_trust_scores': {'passed': True, 'message': ''}})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict  \n",
    "def verify_social_network(users, edges):\n",
    "    # Initialize each constraint as a dict with passed and message.\n",
    "    results = {\n",
    "        \"valid_no_self_loops\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_celebrity_outgoing\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_regular_to_expert\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_acyclic\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_user_attributes\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_edge_structure\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_total_users\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_categories\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_trust_scores\": {\"passed\": True, \"message\": \"\"}\n",
    "    }\n",
    "    errors = []\n",
    "\n",
    "    # Check users list and count\n",
    "    if not isinstance(users, list):\n",
    "        results[\"valid_total_users\"] = {\"passed\": False, \"message\": \"'users' should be a list.\"}\n",
    "        errors.append(\"'users' should be a list.\")\n",
    "    elif len(users) != 20:\n",
    "        results[\"valid_total_users\"] = {\"passed\": False, \"message\": f\"Number of users is {len(users)}; expected 20.\"}\n",
    "        errors.append(f\"Number of users is {len(users)}; expected 20.\")\n",
    "\n",
    "    expected_user_ids = {f\"U{i}\" for i in range(20)}\n",
    "    actual_user_ids = set()\n",
    "    user_map = {}\n",
    "    for user in users:\n",
    "        if not isinstance(user, dict):\n",
    "            results[\"valid_user_attributes\"] = {\"passed\": False, \"message\": \"Each user should be a dictionary.\"}\n",
    "            errors.append(\"Each user should be a dictionary.\")\n",
    "            continue\n",
    "        required_keys = {\"id\", \"trust_score\", \"category\"}\n",
    "        if not required_keys.issubset(user.keys()):\n",
    "            missing = required_keys - set(user.keys())\n",
    "            msg = f\"User {user.get('id', 'Unknown')} is missing keys: {missing}.\"\n",
    "            results[\"valid_user_attributes\"][\"passed\"] = False\n",
    "            results[\"valid_user_attributes\"][\"message\"] += msg + \" \"\n",
    "            errors.append(msg)\n",
    "            continue\n",
    "        user_id = user[\"id\"]\n",
    "        if user_id not in expected_user_ids:\n",
    "            msg = f\"User ID '{user_id}' is invalid. Expected IDs from U0 to U19.\"\n",
    "            results[\"valid_user_attributes\"][\"passed\"] = False\n",
    "            results[\"valid_user_attributes\"][\"message\"] += msg + \" \"\n",
    "            errors.append(msg)\n",
    "        actual_user_ids.add(user_id)\n",
    "        user_map[user_id] = user\n",
    "        trust_score = user[\"trust_score\"]\n",
    "        if not isinstance(trust_score, int) or not (0 <= trust_score <= 100):\n",
    "            msg = f\"User '{user_id}' has invalid 'trust_score': {trust_score}.\"\n",
    "            results[\"valid_trust_scores\"][\"passed\"] = False\n",
    "            results[\"valid_trust_scores\"][\"message\"] += msg + \" \"\n",
    "            errors.append(msg)\n",
    "        category = user[\"category\"]\n",
    "        if trust_score >= 80:\n",
    "            if category != \"celebrity\":\n",
    "                msg = f\"User '{user_id}' has trust_score {trust_score} but category '{category}'; should be 'celebrity'.\"\n",
    "                results[\"valid_categories\"][\"passed\"] = False\n",
    "                results[\"valid_categories\"][\"message\"] += msg + \" \"\n",
    "                errors.append(msg)\n",
    "        elif 70 <= trust_score < 80:\n",
    "            if category != \"expert\":\n",
    "                msg = f\"User '{user_id}' has trust_score {trust_score} but category '{category}'; should be 'expert'.\"\n",
    "                results[\"valid_categories\"][\"passed\"] = False\n",
    "                results[\"valid_categories\"][\"message\"] += msg + \" \"\n",
    "                errors.append(msg)\n",
    "        elif trust_score < 50:\n",
    "            if category != \"regular\":\n",
    "                msg = f\"User '{user_id}' has trust_score {trust_score} but category '{category}'; should be 'regular'.\"\n",
    "                results[\"valid_categories\"][\"passed\"] = False\n",
    "                results[\"valid_categories\"][\"message\"] += msg + \" \"\n",
    "                errors.append(msg)\n",
    "        else:\n",
    "            msg = f\"User '{user_id}' has trust_score {trust_score} which is between 50 and 70; no valid category defined.\"\n",
    "            results[\"valid_categories\"][\"passed\"] = False\n",
    "            results[\"valid_categories\"][\"message\"] += msg + \" \"\n",
    "            errors.append(msg)\n",
    "    missing_users = expected_user_ids - actual_user_ids\n",
    "    if missing_users:\n",
    "        msg = f\"Missing user IDs: {missing_users}.\"\n",
    "        results[\"valid_total_users\"][\"passed\"] = False\n",
    "        results[\"valid_total_users\"][\"message\"] += msg + \" \"\n",
    "        errors.append(msg)\n",
    "    \n",
    "    # Check edges\n",
    "    if not isinstance(edges, list):\n",
    "        results[\"valid_edge_structure\"] = {\"passed\": False, \"message\": \"'edges' should be a list.\"}\n",
    "        errors.append(\"'edges' should be a list.\")\n",
    "    else:\n",
    "        adj = defaultdict(list)\n",
    "        for edge in edges:\n",
    "            if not isinstance(edge, dict):\n",
    "                results[\"valid_edge_structure\"] = {\"passed\": False, \"message\": \"Each edge should be a dictionary.\"}\n",
    "                errors.append(\"Each edge should be a dictionary.\")\n",
    "                continue\n",
    "            required_edge_keys = {\"from\", \"to\"}\n",
    "            if not required_edge_keys.issubset(edge.keys()):\n",
    "                missing = required_edge_keys - set(edge.keys())\n",
    "                msg = f\"Edge is missing keys: {missing}.\"\n",
    "                results[\"valid_edge_structure\"][\"passed\"] = False\n",
    "                results[\"valid_edge_structure\"][\"message\"] += msg + \" \"\n",
    "                errors.append(msg)\n",
    "                continue\n",
    "            from_id = edge[\"from\"]\n",
    "            to_id = edge[\"to\"]\n",
    "            if from_id not in expected_user_ids:\n",
    "                msg = f\"Edge 'from' user '{from_id}' is not valid.\"\n",
    "                results[\"valid_edge_structure\"][\"passed\"] = False\n",
    "                results[\"valid_edge_structure\"][\"message\"] += msg + \" \"\n",
    "                errors.append(msg)\n",
    "            if to_id not in expected_user_ids:\n",
    "                msg = f\"Edge 'to' user '{to_id}' is not valid.\"\n",
    "                results[\"valid_edge_structure\"][\"passed\"] = False\n",
    "                results[\"valid_edge_structure\"][\"message\"] += msg + \" \"\n",
    "                errors.append(msg)\n",
    "            adj[from_id].append(to_id)\n",
    "    \n",
    "    # Self-loop check\n",
    "    no_self_loops_errors = []\n",
    "    for edge in edges:\n",
    "        if edge[\"from\"] == edge[\"to\"]:\n",
    "            msg = f\"Self-loop detected: {edge['from']} → {edge['to']}.\"\n",
    "            no_self_loops_errors.append(msg)\n",
    "    if no_self_loops_errors:\n",
    "        results[\"valid_no_self_loops\"][\"passed\"] = False\n",
    "        results[\"valid_no_self_loops\"][\"message\"] = \" \".join(no_self_loops_errors)\n",
    "        errors.extend(no_self_loops_errors)\n",
    "    \n",
    "    # Celebrity outgoing check: each celebrity must have at least 5 outgoing edges.\n",
    "    celebrity_errors = []\n",
    "    for user in users:\n",
    "        if user[\"category\"] == \"celebrity\":\n",
    "            uid = user[\"id\"]\n",
    "            outgoing = len(adj[uid])\n",
    "            if outgoing < 5:\n",
    "                celebrity_errors.append(f\"Celebrity '{uid}' has {outgoing} outgoing edges; expected at least 5.\")\n",
    "    if celebrity_errors:\n",
    "        results[\"valid_celebrity_outgoing\"][\"passed\"] = False\n",
    "        results[\"valid_celebrity_outgoing\"][\"message\"] = \" \".join(celebrity_errors)\n",
    "        errors.extend(celebrity_errors)\n",
    "    \n",
    "    # Regular-to-expert check: a regular user should not influence an expert.\n",
    "    reg_to_expert_errors = []\n",
    "    for edge in edges:\n",
    "        from_user = user_map.get(edge[\"from\"])\n",
    "        to_user = user_map.get(edge[\"to\"])\n",
    "        if from_user and to_user:\n",
    "            if from_user[\"category\"] == \"regular\" and to_user[\"trust_score\"] >= 70:\n",
    "                reg_to_expert_errors.append(f\"Regular user '{from_user['id']}' is influencing expert '{to_user['id']}'.\")\n",
    "    if reg_to_expert_errors:\n",
    "        results[\"valid_regular_to_expert\"][\"passed\"] = False\n",
    "        results[\"valid_regular_to_expert\"][\"message\"] = \" \".join(reg_to_expert_errors)\n",
    "        errors.extend(reg_to_expert_errors)\n",
    "    \n",
    "    # Acyclic check using DFS\n",
    "    visited = set()\n",
    "    rec_stack = set()\n",
    "    def dfs(u):\n",
    "        visited.add(u)\n",
    "        rec_stack.add(u)\n",
    "        for v in adj[u]:\n",
    "            if v not in visited:\n",
    "                if dfs(v):\n",
    "                    return True\n",
    "            elif v in rec_stack:\n",
    "                return True\n",
    "        rec_stack.remove(u)\n",
    "        return False\n",
    "    cycle_detected = False\n",
    "    for uid in expected_user_ids:\n",
    "        if uid not in visited:\n",
    "            if dfs(uid):\n",
    "                cycle_detected = True\n",
    "                break\n",
    "    if cycle_detected:\n",
    "        msg = \"Cycle detected in the network; the graph must be acyclic.\"\n",
    "        results[\"valid_acyclic\"][\"passed\"] = False\n",
    "        results[\"valid_acyclic\"][\"message\"] = msg\n",
    "        errors.append(msg)\n",
    "    \n",
    "    overall_passed = all(results[k][\"passed\"] for k in results if k != \"errors\")\n",
    "    return overall_passed, results\n",
    "\n",
    "\n",
    "users = [\n",
    "    {\"id\": \"U0\", \"trust_score\": 85, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U1\", \"trust_score\": 90, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U2\", \"trust_score\": 75, \"category\": \"expert\"},\n",
    "    {\"id\": \"U3\", \"trust_score\": 72, \"category\": \"expert\"},\n",
    "    {\"id\": \"U4\", \"trust_score\": 45, \"category\": \"regular\"},\n",
    "    {\"id\": \"U5\", \"trust_score\": 40, \"category\": \"regular\"},\n",
    "    {\"id\": \"U6\", \"trust_score\": 82, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U7\", \"trust_score\": 78, \"category\": \"expert\"},\n",
    "    {\"id\": \"U8\", \"trust_score\": 30, \"category\": \"regular\"},\n",
    "    {\"id\": \"U9\", \"trust_score\": 35, \"category\": \"regular\"},\n",
    "    {\"id\": \"U10\", \"trust_score\": 88, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U11\", \"trust_score\": 70, \"category\": \"expert\"},\n",
    "    {\"id\": \"U12\", \"trust_score\": 25, \"category\": \"regular\"},\n",
    "    {\"id\": \"U13\", \"trust_score\": 20, \"category\": \"regular\"},\n",
    "    {\"id\": \"U14\", \"trust_score\": 95, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U15\", \"trust_score\": 73, \"category\": \"expert\"},\n",
    "    {\"id\": \"U16\", \"trust_score\": 48, \"category\": \"regular\"},\n",
    "    {\"id\": \"U17\", \"trust_score\": 15, \"category\": \"regular\"},\n",
    "    {\"id\": \"U18\", \"trust_score\": 77, \"category\": \"expert\"},\n",
    "    {\"id\": \"U19\", \"trust_score\": 42, \"category\": \"regular\"}\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    {\"from\": \"U0\", \"to\": \"U2\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U3\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U4\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U5\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U7\"},\n",
    "    {\"from\": \"U1\", \"to\": \"U2\"},\n",
    "    {\"from\": \"U1\", \"to\": \"U3\"},\n",
    "    {\"from\": \"U1\", \"to\": \"U8\"},\n",
    "    {\"from\": \"U1\", \"to\": \"U9\"},\n",
    "    {\"from\": \"U1\", \"to\": \"U11\"},\n",
    "    {\"from\": \"U2\", \"to\": \"U4\"},\n",
    "    {\"from\": \"U2\", \"to\": \"U5\"},\n",
    "    {\"from\": \"U3\", \"to\": \"U8\"},\n",
    "    {\"from\": \"U6\", \"to\": \"U7\"},\n",
    "    {\"from\": \"U6\", \"to\": \"U9\"},\n",
    "    {\"from\": \"U6\", \"to\": \"U11\"},\n",
    "    {\"from\": \"U6\", \"to\": \"U12\"},\n",
    "    {\"from\": \"U6\", \"to\": \"U13\"},\n",
    "    {\"from\": \"U7\", \"to\": \"U16\"},\n",
    "    {\"from\": \"U10\", \"to\": \"U11\"},\n",
    "    {\"from\": \"U10\", \"to\": \"U12\"},\n",
    "    {\"from\": \"U10\", \"to\": \"U13\"},\n",
    "    {\"from\": \"U10\", \"to\": \"U15\"},\n",
    "    {\"from\": \"U10\", \"to\": \"U16\"},\n",
    "    {\"from\": \"U11\", \"to\": \"U17\"},\n",
    "    {\"from\": \"U14\", \"to\": \"U15\"},\n",
    "    {\"from\": \"U14\", \"to\": \"U16\"},\n",
    "    {\"from\": \"U14\", \"to\": \"U17\"},\n",
    "    {\"from\": \"U14\", \"to\": \"U18\"},\n",
    "    {\"from\": \"U14\", \"to\": \"U19\"},\n",
    "    {\"from\": \"U15\", \"to\": \"U19\"},\n",
    "    {\"from\": \"U18\", \"to\": \"U12\"}\n",
    "]\n",
    "\n",
    "verification_output = verify_social_network(users, edges)\n",
    "print(\"Verification Output:\", verification_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "65364642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. GPT4omini\n",
      "2. Claude35Haiku\n",
      "3. Gemini20Flash\n",
      "4. DeepSeekV3\n",
      "5. Llama32\n",
      "6. GPT4o\n",
      "7. Claude35Sonnet\n",
      "8. Gemini20Pro\n",
      "9. Llama31405B\n",
      "10. DeepSeekR1\n",
      "11. o3mini\n",
      "12. o1\n",
      "13. Llama318B\n",
      "14. GrokV3\n",
      "15. Claude37Sonnet\n",
      "Select a model by number: 14\n",
      "\n",
      "Available Prompt Types:\n",
      "1. directprompt\n",
      "2. iterativefeedback\n",
      "3. programaugmented\n",
      "Select a prompt type by number: 3\n",
      "\n",
      "Enter the run number (1-5): 5\n",
      "Save is succesful! results/directedSocialNetwork_GrokV3_programaugmented_run5_output.json\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama32\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini20Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\", \"Llama318B\", \"GrokV3\",\"Claude37Sonnet\"]\n",
    "\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"directedSocialNetwork\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"users\":users,\n",
    "    \"edges\":edges,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a40de4",
   "metadata": {},
   "source": [
    "# Quantum Circuit Design  \n",
    "\n",
    "## Problem Description:\n",
    "Design a quantum circuit consisting of multiple qubits and quantum gates. The circuit must adhere to specific constraints to ensure proper gate operations, circuit efficiency, and overall functionality. The design should incorporate structural elements like depth and a Directed Acyclic Graph (DAG) while simplifying some of the gate-related rules to enhance accessibility.\n",
    "\n",
    "## Constraints:\n",
    "1. **Qubits:**\n",
    "   - **Total Qubits:** 10, labeled from `Q0` to `Q9`.\n",
    "   - **Initialization:** All qubits must start in the |0⟩ state.\n",
    "\n",
    "2. **Gates:**\n",
    "   - **Types of Gates to Include:**\n",
    "     - **Single-Qubit Gates:** Hadamard (H), Pauli-X (X), Pauli-Z (Z)\n",
    "     - **Multi-Qubit Gates:** Controlled NOT (CNOT), SWAP\n",
    "     - **Measurement:** Measure (Measure)\n",
    "   - **Gate Operations:**\n",
    "     - Each gate operates on specific qubits at designated times.\n",
    "     - **CNOT Gates:** Must operate on qubits that are not adjacent (e.g., Q0 and Q2 are valid; Q0 and Q1 are invalid).\n",
    "     - **SWAP Gates:** Must operate between pairs of qubits that have identical gate sequences up to that point.\n",
    "     - **Measurements:** Each qubit can be measured only once and must be the last operation on that qubit.\n",
    "   - **Gate Restrictions:**\n",
    "     - **Gate Frequency:** No single-qubit gate can be applied more than twice consecutively on the same qubit.\n",
    "\n",
    "3. **Circuit Structure:**\n",
    "   - The circuit must be a Directed Acyclic Graph (DAG); no repeated times for the same qubit.\n",
    "   - **Layered Operations:** Gates at the same time step must operate on disjoint sets of qubits (i.e., no two gates at the same time can act on the same qubit).\n",
    "   - **Depth Constraint:** The total number of time steps (layers) must not exceed 30.\n",
    "\n",
    "4. **Operational Constraints:**\n",
    "   - **Circuit Reversibility:** Measurements must be the final operations on their respective qubits to maintain circuit reversibility.\n",
    "   - **Gate Optimization:** The circuit should minimize the total number of gates while satisfying all other constraints.\n",
    "   - **Final State:** After all operations, all qubits must either be measured or returned to the |0⟩ state.\n",
    "\n",
    "## Required Output Format:\n",
    "\n",
    "Provide the circuit details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "circuit = [\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q0\"], \"time\": 1},\n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q0\", \"Q2\"], \"time\": 2},\n",
    "    {\"gate\": \"X\", \"qubits\": [\"Q2\"], \"time\": 3},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q0\"], \"time\": 4},\n",
    "    # ... more gates\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3d8270de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Output: (True, {'valid_output_structure': {'passed': True, 'message': ''}, 'valid_gate_types': {'passed': True, 'message': ''}, 'valid_qubits': {'passed': True, 'message': ''}, 'valid_dag': {'passed': True, 'message': ''}, 'valid_gate_precedences': {'passed': True, 'message': ''}, 'valid_cnot_adjacency': {'passed': True, 'message': ''}, 'valid_swap_constraints': {'passed': True, 'message': ''}, 'valid_measurements': {'passed': True, 'message': ''}, 'valid_gate_restrictions': {'passed': True, 'message': ''}, 'layered_operations': {'passed': True, 'message': ''}, 'depth_constraint': {'passed': True, 'message': ''}, 'gate_optimization': {'passed': True, 'message': ''}, 'final_state_compliance': {'passed': True, 'message': ''}, 'overall_passed': True})\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def verify_quantum_circuit(circuit):\n",
    "    results = {\n",
    "        \"valid_output_structure\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_gate_types\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_qubits\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_dag\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_gate_precedences\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_cnot_adjacency\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_swap_constraints\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_measurements\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"valid_gate_restrictions\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"layered_operations\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"depth_constraint\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"gate_optimization\": {\"passed\": True, \"message\": \"\"},\n",
    "        \"final_state_compliance\": {\"passed\": True, \"message\": \"\"}\n",
    "    }\n",
    "    errors = []\n",
    "    valid_qubits = {f\"Q{i}\" for i in range(10)}\n",
    "    single_qubit_gates = {\"H\", \"X\", \"Z\"}\n",
    "    multi_qubit_gates = {\"CNOT\", \"SWAP\"}\n",
    "    measurement_gate = \"Measure\"\n",
    "    allowed_gates = single_qubit_gates.union(multi_qubit_gates).union({measurement_gate})\n",
    "    \n",
    "    qubit_operations = defaultdict(list)\n",
    "    gate_sequences = defaultdict(list)\n",
    "    time_layers = defaultdict(set)\n",
    "    max_time_step = 0\n",
    "\n",
    "    def add_error(key, message):\n",
    "        results[key][\"passed\"] = False\n",
    "        if results[key][\"message\"]:\n",
    "            results[key][\"message\"] += \" \" + message\n",
    "        else:\n",
    "            results[key][\"message\"] = message\n",
    "        errors.append(message)\n",
    "\n",
    "    if not isinstance(circuit, list):\n",
    "        add_error(\"valid_output_structure\", \"'circuit' should be a list.\")\n",
    "        return False, results\n",
    "\n",
    "    for idx, gate_op in enumerate(circuit):\n",
    "        if not isinstance(gate_op, dict):\n",
    "            add_error(\"valid_output_structure\", f\"Gate operation at index {idx} is not a dictionary.\")\n",
    "            continue\n",
    "        required_keys = {\"gate\", \"qubits\", \"time\"}\n",
    "        if not required_keys.issubset(gate_op.keys()):\n",
    "            missing = required_keys - set(gate_op.keys())\n",
    "            add_error(\"valid_output_structure\", f\"Gate operation at index {idx} is missing keys: {missing}.\")\n",
    "            continue\n",
    "        gate = gate_op[\"gate\"]\n",
    "        qubits = gate_op[\"qubits\"]\n",
    "        time = gate_op[\"time\"]\n",
    "        if gate not in allowed_gates:\n",
    "            add_error(\"valid_gate_types\", f\"Invalid gate type '{gate}' at index {idx}. Allowed: {allowed_gates}.\")\n",
    "        if not isinstance(qubits, list) or not all(isinstance(q, str) for q in qubits):\n",
    "            add_error(\"valid_output_structure\", f\"'qubits' for gate at index {idx} must be a list of strings.\")\n",
    "            continue\n",
    "        for q in qubits:\n",
    "            if q not in valid_qubits:\n",
    "                add_error(\"valid_qubits\", f\"Invalid qubit ID '{q}' at index {idx}. Expected Q0 to Q9.\")\n",
    "        if not isinstance(time, int) or time < 0:\n",
    "            add_error(\"valid_output_structure\", f\"Invalid 'time' value '{time}' at index {idx}. Must be a non-negative integer.\")\n",
    "            continue\n",
    "        if time > max_time_step:\n",
    "            max_time_step = time\n",
    "        for q in qubits:\n",
    "            qubit_operations[q].append((time, gate))\n",
    "            gate_sequences[q].append(gate)\n",
    "        for q in qubits:\n",
    "            if q in time_layers[time]:\n",
    "                add_error(\"layered_operations\", f\"Multiple gates operate on qubit '{q}' at time {time}.\")\n",
    "            time_layers[time].add(q)\n",
    "        if gate == \"CNOT\":\n",
    "            if len(qubits) != 2:\n",
    "                add_error(\"valid_output_structure\", f\"CNOT gate at index {idx} must operate on exactly two qubits.\")\n",
    "        elif gate == \"SWAP\":\n",
    "            if len(qubits) != 2:\n",
    "                add_error(\"valid_output_structure\", f\"SWAP gate at index {idx} must operate on exactly two qubits.\")\n",
    "        elif gate in single_qubit_gates and gate != \"Measure\":\n",
    "            if len(qubits) != 1:\n",
    "                add_error(\"valid_output_structure\", f\"{gate} gate at index {idx} must operate on exactly one qubit.\")\n",
    "        elif gate == \"Measure\":\n",
    "            if len(qubits) != 1:\n",
    "                add_error(\"valid_output_structure\", f\"Measure gate at index {idx} must operate on exactly one qubit.\")\n",
    "\n",
    "    for q, ops in qubit_operations.items():\n",
    "        times = [t for (t, _) in ops]\n",
    "        if len(times) != len(set(times)):\n",
    "            add_error(\"valid_dag\", f\"Qubit '{q}' has overlapping operations at the same time.\")\n",
    "\n",
    "    for q, gates in gate_sequences.items():\n",
    "        previous = None\n",
    "        count = 0\n",
    "        for idx, g in enumerate(gates):\n",
    "            if g in single_qubit_gates:\n",
    "                if g == previous:\n",
    "                    count += 1\n",
    "                    if count > 2:\n",
    "                        add_error(\"valid_gate_restrictions\", f\"Qubit '{q}' has more than two consecutive '{g}' gates at positions {idx-1} and {idx}.\")\n",
    "                else:\n",
    "                    count = 1\n",
    "            else:\n",
    "                count = 0\n",
    "            previous = g\n",
    "\n",
    "    for idx, gate_op in enumerate(circuit):\n",
    "        if gate_op[\"gate\"] == \"CNOT\":\n",
    "            q1, q2 = gate_op[\"qubits\"]\n",
    "            if abs(int(q1[1:]) - int(q2[1:])) < 2:\n",
    "                add_error(\"valid_cnot_adjacency\", f\"CNOT gate at index {idx} operates on adjacent qubits '{q1}' and '{q2}'.\")\n",
    "    for idx, gate_op in enumerate(circuit):\n",
    "        if gate_op[\"gate\"] == \"SWAP\":\n",
    "            q1, q2 = gate_op[\"qubits\"]\n",
    "            # For SWAP, check that prior gate sequences (excluding current SWAP) are identical.\n",
    "            seq1 = gate_sequences[q1][:gate_sequences[q1].index(\"SWAP\")]\n",
    "            seq2 = gate_sequences[q2][:gate_sequences[q2].index(\"SWAP\")]\n",
    "            if seq1 != seq2:\n",
    "                add_error(\"valid_swap_constraints\", f\"SWAP gate at index {idx} operates on qubits '{q1}' and '{q2}' with differing prior gate sequences.\")\n",
    "    measurement_counts = defaultdict(int)\n",
    "    for gate_op in circuit:\n",
    "        if gate_op[\"gate\"] == \"Measure\":\n",
    "            measurement_counts[gate_op[\"qubits\"][0]] += 1\n",
    "    for q, count in measurement_counts.items():\n",
    "        if count > 1:\n",
    "            add_error(\"valid_measurements\", f\"Qubit '{q}' is measured {count} times; only one measurement allowed.\")\n",
    "    if max_time_step > 30:\n",
    "        add_error(\"depth_constraint\", f\"Circuit depth is {max_time_step} time steps; maximum allowed is 30.\")\n",
    "    for q, gates in gate_sequences.items():\n",
    "        for i in range(1, len(gates)):\n",
    "            if gates[i] == gates[i-1] and gates[i] in single_qubit_gates:\n",
    "                add_error(\"gate_optimization\", f\"Redundant consecutive '{gates[i]}' gates on qubit '{q}' at positions {i-1} and {i}.\")\n",
    "    for q, gates in gate_sequences.items():\n",
    "        if gates and gates[-1] != \"Measure\":\n",
    "            add_error(\"final_state_compliance\", f\"Qubit '{q}' does not end with a Measurement (or resetting gate).\")\n",
    "    \n",
    "    overall_passed = all(results[key][\"passed\"] for key in results)\n",
    "    results[\"overall_passed\"] = overall_passed\n",
    "    return overall_passed, results\n",
    "\n",
    "\n",
    "\n",
    "circuit = [\n",
    "    # Layer 1 - Initial Hadamard gates to create superposition\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q0\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q2\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q4\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q6\"], \"time\": 1},\n",
    "\n",
    "    # Layer 2 - First set of CNOT gates (non-adjacent qubits)\n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q0\", \"Q2\"], \"time\": 2},\n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q4\", \"Q6\"], \"time\": 2},\n",
    "    {\"gate\": \"X\", \"qubits\": [\"Q8\"], \"time\": 2},\n",
    "\n",
    "    # Layer 3 - Pauli gates\n",
    "    {\"gate\": \"Z\", \"qubits\": [\"Q1\"], \"time\": 3},\n",
    "    {\"gate\": \"X\", \"qubits\": [\"Q3\"], \"time\": 3},\n",
    "    {\"gate\": \"Z\", \"qubits\": [\"Q5\"], \"time\": 3},\n",
    "\n",
    "    # Layer 4 - SWAP gates (Q1 and Q3 have identical sequences up to this point: [Z] and [X])\n",
    "    {\"gate\": \"SWAP\", \"qubits\": [\"Q2\", \"Q4\"], \"time\": 4},\n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q6\", \"Q8\"], \"time\": 4},\n",
    "\n",
    "    # Layer 5 - Second set of single-qubit gates\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q7\"], \"time\": 5},\n",
    "    {\"gate\": \"X\", \"qubits\": [\"Q9\"], \"time\": 5},\n",
    "\n",
    "    # Layers 6-15 - Measurements for all qubits\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q0\"], \"time\": 6},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q1\"], \"time\": 7},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q2\"], \"time\": 8},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q3\"], \"time\": 9},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q4\"], \"time\": 10},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q5\"], \"time\": 11},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q6\"], \"time\": 12},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q7\"], \"time\": 13},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q8\"], \"time\": 14},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q9\"], \"time\": 15}\n",
    "]\n",
    "\n",
    "# Execute verification\n",
    "verification_output = verify_quantum_circuit(circuit)\n",
    "print(\"Verification Output:\", verification_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "47ef6d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. GPT4omini\n",
      "2. Claude35Haiku\n",
      "3. Gemini20Flash\n",
      "4. DeepSeekV3\n",
      "5. Llama32\n",
      "6. GPT4o\n",
      "7. Claude35Sonnet\n",
      "8. Gemini20Pro\n",
      "9. Llama31405B\n",
      "10. DeepSeekR1\n",
      "11. o3mini\n",
      "12. o1\n",
      "13. Llama318B\n",
      "14. GrokV3\n",
      "15. Claude37Sonnet\n",
      "Select a model by number: 14\n",
      "\n",
      "Available Prompt Types:\n",
      "1. directprompt\n",
      "2. iterativefeedback\n",
      "3. programaugmented\n",
      "Select a prompt type by number: 3\n",
      "\n",
      "Enter the run number (1-5): 5\n",
      "Save is succesful! results/quantum_GrokV3_programaugmented_run5_output.json\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama32\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini20Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\", \"Llama318B\", \"GrokV3\",\"Claude37Sonnet\"]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"quantum\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\" Asks the user for model, prompt type, run number, and problem type \"\"\"\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"circuit\": circuit,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74198f1f",
   "metadata": {},
   "source": [
    "# Gene-Disease Association Network\n",
    "\n",
    "Design a gene-disease association network based on the specifications below.\n",
    "\n",
    "## Problem Description:\n",
    "Create a bipartite network that models the associations between genes and diseases. This network will represent which genes are associated with which diseases, capturing the strength of each association. The network should adhere to defined constraints to ensure biological relevance and structural integrity.\n",
    "\n",
    "## Constraints:\n",
    "1. **Nodes:**\n",
    "   - **Genes:**\n",
    "     - Total of 20 genes labeled from G0 to G19.\n",
    "     - Each gene has a \"name\" and a \"function\".\n",
    "   - **Diseases:**\n",
    "     - Total of 20 diseases labeled from D0 to D19.\n",
    "     - Each disease has a \"name\" and a \"severity_level\" (e.g., \"Low\", \"Medium\", \"High\").\n",
    "   \n",
    "2. **Edges (Associations):**\n",
    "   - Represents the association between a gene and a disease.\n",
    "   - **Bipartite Constraint:** Associations can only exist between genes and diseases, not within the same set.\n",
    "   - **Association Strength:** Each association has a \"strength\" value ranging from 0.0 to 1.0, indicating the confidence of the association.\n",
    "   \n",
    "3. **Degree Constraints:**\n",
    "   - **Genes:**\n",
    "     - Each gene must be associated with at least 2 and at most 5 diseases.\n",
    "   - **Diseases:**\n",
    "     - Each disease must be associated with at least 3 and at most 10 genes.\n",
    "   \n",
    "4. **Structural Constraints:**\n",
    "   - The network must be bipartite; no edges should connect nodes within the same set (i.e., no gene-gene or disease-disease associations).\n",
    "   - There should be no duplicate edges (i.e., each gene-disease pair is unique).\n",
    "\n",
    "## Required Output Format:\n",
    "\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "genes = [\n",
    "    {\"id\": \"G0\", \"name\": \"BRCA1\", \"function\": \"DNA repair\"},\n",
    "    {\"id\": \"G1\", \"name\": \"TP53\", \"function\": \"Tumor suppression\"},\n",
    "    # ... all genes (G2-G19)\n",
    "]\n",
    "\n",
    "diseases = [\n",
    "    {\"id\": \"D0\", \"name\": \"Breast Cancer\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D1\", \"name\": \"Lung Cancer\", \"severity_level\": \"High\"},\n",
    "    # ... all diseases (D2-D19)\n",
    "]\n",
    "\n",
    "associations = [\n",
    "    {\"from\": \"G0\", \"to\": \"D0\", \"strength\": 0.85},\n",
    "    {\"from\": \"G0\", \"to\": \"D2\", \"strength\": 0.60},\n",
    "    {\"from\": \"G1\", \"to\": \"D0\", \"strength\": 0.90},\n",
    "    # ... more associations\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7e348cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gene-Disease Association Network is valid: (True, {'constraints': {'defined_counts': {'passed': True, 'message': ''}, 'valid_associations': {'passed': True, 'message': ''}, 'degree_constraints': {'passed': True, 'message': ''}, 'duplicate_associations': {'passed': True, 'message': ''}, 'bipartite_constraint': {'passed': True, 'message': ''}}, 'overall_passed': True, 'errors': []})\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def verify_gene_disease_association_network(genes, diseases, associations):\n",
    "    # Prepare the verification result container\n",
    "    verification_results = {\n",
    "        \"defined_counts\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"valid_associations\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"degree_constraints\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"duplicate_associations\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"bipartite_constraint\": {\"passed\": False, \"message\": \"\"}\n",
    "    }\n",
    "    error_messages = []\n",
    "\n",
    "    # Check counts of nodes\n",
    "    if len(genes) == 20 and len(diseases) == 20:\n",
    "        verification_results[\"defined_counts\"][\"passed\"] = True\n",
    "    else:\n",
    "        missing = []\n",
    "        if len(genes) != 20:\n",
    "            missing.append(f\"genes count is {len(genes)}; expected 20.\")\n",
    "        if len(diseases) != 20:\n",
    "            missing.append(f\"diseases count is {len(diseases)}; expected 20.\")\n",
    "        verification_results[\"defined_counts\"][\"message\"] = \" \".join(missing)\n",
    "        error_messages.append(\"Defined Counts Check Failed.\")\n",
    "\n",
    "    # Build maps for easy lookup\n",
    "    gene_map = {gene[\"id\"]: gene for gene in genes}\n",
    "    disease_map = {disease[\"id\"]: disease for disease in diseases}\n",
    "\n",
    "    # Check associations:\n",
    "    invalid_associations = []\n",
    "    bipartite_errors = []\n",
    "    for assoc in associations:\n",
    "        from_id = assoc.get(\"from\")\n",
    "        to_id = assoc.get(\"to\")\n",
    "        strength = assoc.get(\"strength\")\n",
    "\n",
    "        # Must be from a gene and to a disease.\n",
    "        if from_id not in gene_map:\n",
    "            invalid_associations.append(f\"Association from undefined gene '{from_id}' to '{to_id}'.\")\n",
    "        if to_id not in disease_map:\n",
    "            invalid_associations.append(f\"Association from '{from_id}' to undefined disease '{to_id}'.\")\n",
    "\n",
    "        # Bipartite check: if both endpoints are genes or both are diseases.\n",
    "        if from_id in gene_map and to_id in gene_map:\n",
    "            bipartite_errors.append(f\"Association between gene '{from_id}' and gene '{to_id}' violates bipartite constraint.\")\n",
    "        if from_id in disease_map and to_id in disease_map:\n",
    "            bipartite_errors.append(f\"Association between disease '{from_id}' and disease '{to_id}' violates bipartite constraint.\")\n",
    "\n",
    "        # Check association strength\n",
    "        if not isinstance(strength, (int, float)) or not (0.0 <= strength <= 1.0):\n",
    "            invalid_associations.append(\n",
    "                f\"Association strength {strength} for '{from_id}' -> '{to_id}' is out of bounds (0.0 - 1.0).\"\n",
    "            )\n",
    "    \n",
    "    if not invalid_associations:\n",
    "        verification_results[\"valid_associations\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"valid_associations\"][\"message\"] = \" \".join(invalid_associations)\n",
    "        error_messages.append(\"Valid Associations Check Failed.\")\n",
    "\n",
    "    if not bipartite_errors:\n",
    "        verification_results[\"bipartite_constraint\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"bipartite_constraint\"][\"message\"] = \" \".join(bipartite_errors)\n",
    "        error_messages.append(\"Bipartite Constraint Check Failed.\")\n",
    "\n",
    "    # Degree constraints\n",
    "    gene_degrees = defaultdict(int)\n",
    "    disease_degrees = defaultdict(int)\n",
    "    for assoc in associations:\n",
    "        gene_id = assoc.get(\"from\")\n",
    "        disease_id = assoc.get(\"to\")\n",
    "        gene_degrees[gene_id] += 1\n",
    "        disease_degrees[disease_id] += 1\n",
    "\n",
    "    degree_errors = []\n",
    "    for gene in genes:\n",
    "        gene_id = gene[\"id\"]\n",
    "        degree = gene_degrees.get(gene_id, 0)\n",
    "        if degree < 2 or degree > 5:\n",
    "            degree_errors.append(f\"Gene '{gene_id}' has {degree} associations; expected between 2 and 5.\")\n",
    "\n",
    "    for disease in diseases:\n",
    "        disease_id = disease[\"id\"]\n",
    "        degree = disease_degrees.get(disease_id, 0)\n",
    "        if degree < 3 or degree > 10:\n",
    "            degree_errors.append(f\"Disease '{disease_id}' has {degree} associations; expected between 3 and 10.\")\n",
    "\n",
    "    if not degree_errors:\n",
    "        verification_results[\"degree_constraints\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"degree_constraints\"][\"message\"] = \" \".join(degree_errors)\n",
    "        error_messages.append(\"Degree Constraints Check Failed.\")\n",
    "\n",
    "    # Duplicate associations check\n",
    "    seen_pairs = set()\n",
    "    duplicate_errors = []\n",
    "    for assoc in associations:\n",
    "        pair = (assoc.get(\"from\"), assoc.get(\"to\"))\n",
    "        if pair in seen_pairs:\n",
    "            duplicate_errors.append(f\"Duplicate association found between '{pair[0]}' and '{pair[1]}'.\")\n",
    "        else:\n",
    "            seen_pairs.add(pair)\n",
    "    \n",
    "    if not duplicate_errors:\n",
    "        verification_results[\"duplicate_associations\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"duplicate_associations\"][\"message\"] = \" \".join(duplicate_errors)\n",
    "        error_messages.append(\"Duplicate Associations Check Failed.\")\n",
    "\n",
    "    final_results = {\n",
    "        \"constraints\": verification_results,\n",
    "        \"overall_passed\": not error_messages,\n",
    "        \"errors\": error_messages\n",
    "    }\n",
    "    return (not error_messages, final_results)\n",
    "\n",
    "genes = [  \n",
    "    {\"id\": \"G0\", \"name\": \"BRCA1\", \"function\": \"DNA repair and tumor suppression\"},  \n",
    "    {\"id\": \"G1\", \"name\": \"TP53\", \"function\": \"Tumor suppression and cell cycle regulation\"},  \n",
    "    {\"id\": \"G2\", \"name\": \"EGFR\", \"function\": \"Cell growth and division signaling\"},  \n",
    "    {\"id\": \"G3\", \"name\": \"KRAS\", \"function\": \"GTPase signaling in cell growth\"},  \n",
    "    {\"id\": \"G4\", \"name\": \"PTEN\", \"function\": \"Tumor suppression and cell cycle regulation\"},  \n",
    "    {\"id\": \"G5\", \"name\": \"APP\", \"function\": \"Neural growth and repair\"},  \n",
    "    {\"id\": \"G6\", \"name\": \"CFTR\", \"function\": \"Chloride channel regulation\"},  \n",
    "    {\"id\": \"G7\", \"name\": \"HBB\", \"function\": \"Oxygen transport in blood\"},  \n",
    "    {\"id\": \"G8\", \"name\": \"APOE\", \"function\": \"Lipid metabolism and transport\"},  \n",
    "    {\"id\": \"G9\", \"name\": \"TNF\", \"function\": \"Inflammatory response regulation\"},  \n",
    "    {\"id\": \"G10\", \"name\": \"IL6\", \"function\": \"Immune response signaling\"},  \n",
    "    {\"id\": \"G11\", \"name\": \"ACE2\", \"function\": \"Blood pressure regulation\"},  \n",
    "    {\"id\": \"G12\", \"name\": \"MTHFR\", \"function\": \"Folate metabolism\"},  \n",
    "    {\"id\": \"G13\", \"name\": \"COMT\", \"function\": \"Neurotransmitter metabolism\"},  \n",
    "    {\"id\": \"G14\", \"name\": \"HTT\", \"function\": \"Neural development\"},  \n",
    "    {\"id\": \"G15\", \"name\": \"SOD1\", \"function\": \"Antioxidant defense\"},  \n",
    "    {\"id\": \"G16\", \"name\": \"DMD\", \"function\": \"Muscle cell structure and function\"},  \n",
    "    {\"id\": \"G17\", \"name\": \"FMR1\", \"function\": \"RNA binding and neural development\"},  \n",
    "    {\"id\": \"G18\", \"name\": \"LDLR\", \"function\": \"Cholesterol metabolism\"},  \n",
    "    {\"id\": \"G19\", \"name\": \"NF1\", \"function\": \"Cell growth regulation\"}  \n",
    "]  \n",
    "\n",
    "diseases = [  \n",
    "    {\"id\": \"D0\", \"name\": \"Breast Cancer\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D1\", \"name\": \"Lung Cancer\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D2\", \"name\": \"Alzheimer's Disease\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D3\", \"name\": \"Cystic Fibrosis\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D4\", \"name\": \"Huntington's Disease\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D5\", \"name\": \"Type 2 Diabetes\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D6\", \"name\": \"Coronary Heart Disease\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D7\", \"name\": \"Asthma\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D8\", \"name\": \"Parkinson's Disease\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D9\", \"name\": \"Multiple Sclerosis\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D10\", \"name\": \"Rheumatoid Arthritis\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D11\", \"name\": \"Sickle Cell Anemia\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D12\", \"name\": \"Hypertension\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D13\", \"name\": \"Depression\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D14\", \"name\": \"Schizophrenia\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D15\", \"name\": \"Osteoporosis\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D16\", \"name\": \"Muscular Dystrophy\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D17\", \"name\": \"Celiac Disease\", \"severity_level\": \"Medium\"},  \n",
    "    {\"id\": \"D18\", \"name\": \"Fragile X Syndrome\", \"severity_level\": \"High\"},  \n",
    "    {\"id\": \"D19\", \"name\": \"Hypercholesterolemia\", \"severity_level\": \"Low\"}  \n",
    "]  \n",
    "\n",
    "associations = [  \n",
    "    # BRCA1 associations (G0)  \n",
    "    {\"from\": \"G0\", \"to\": \"D0\", \"strength\": 0.95},  \n",
    "    {\"from\": \"G0\", \"to\": \"D1\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G0\", \"to\": \"D6\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G0\", \"to\": \"D3\", \"strength\": 0.25},  \n",
    "    {\"from\": \"G0\", \"to\": \"D18\", \"strength\": 0.30},  \n",
    "    \n",
    "    # TP53 associations (G1)  \n",
    "    {\"from\": \"G1\", \"to\": \"D0\", \"strength\": 0.85},  \n",
    "    {\"from\": \"G1\", \"to\": \"D1\", \"strength\": 0.90},  \n",
    "    {\"from\": \"G1\", \"to\": \"D8\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G1\", \"to\": \"D14\", \"strength\": 0.30},  \n",
    "    {\"from\": \"G1\", \"to\": \"D16\", \"strength\": 0.40},  \n",
    "    \n",
    "    # EGFR associations (G2)  \n",
    "    {\"from\": \"G2\", \"to\": \"D1\", \"strength\": 0.90},  \n",
    "    {\"from\": \"G2\", \"to\": \"D0\", \"strength\": 0.65},  \n",
    "    {\"from\": \"G2\", \"to\": \"D7\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G2\", \"to\": \"D10\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G2\", \"to\": \"D12\", \"strength\": 0.25},  \n",
    "    \n",
    "    # KRAS associations (G3)  \n",
    "    {\"from\": \"G3\", \"to\": \"D1\", \"strength\": 0.85},  \n",
    "    {\"from\": \"G3\", \"to\": \"D6\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G3\", \"to\": \"D5\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G3\", \"to\": \"D11\", \"strength\": 0.30},  \n",
    "    {\"from\": \"G3\", \"to\": \"D18\", \"strength\": 0.35},  \n",
    "    \n",
    "    # PTEN associations (G4)  \n",
    "    {\"from\": \"G4\", \"to\": \"D0\", \"strength\": 0.80},  \n",
    "    {\"from\": \"G4\", \"to\": \"D9\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G4\", \"to\": \"D13\", \"strength\": 0.30},  \n",
    "    {\"from\": \"G4\", \"to\": \"D14\", \"strength\": 0.55},  \n",
    "    {\"from\": \"G4\", \"to\": \"D17\", \"strength\": 0.30},  \n",
    "    \n",
    "    # APP associations (G5)  \n",
    "    {\"from\": \"G5\", \"to\": \"D2\", \"strength\": 0.95},  \n",
    "    {\"from\": \"G5\", \"to\": \"D8\", \"strength\": 0.50},  \n",
    "    {\"from\": \"G5\", \"to\": \"D13\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G5\", \"to\": \"D4\", \"strength\": 0.55},  \n",
    "    \n",
    "    # CFTR associations (G6)  \n",
    "    {\"from\": \"G6\", \"to\": \"D3\", \"strength\": 0.98},  \n",
    "    {\"from\": \"G6\", \"to\": \"D7\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G6\", \"to\": \"D17\", \"strength\": 0.25},  \n",
    "    \n",
    "    # HBB associations (G7)  \n",
    "    {\"from\": \"G7\", \"to\": \"D11\", \"strength\": 0.95},  \n",
    "    {\"from\": \"G7\", \"to\": \"D6\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G7\", \"to\": \"D12\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G7\", \"to\": \"D16\", \"strength\": 0.35},  \n",
    "    \n",
    "    # APOE associations (G8)  \n",
    "    {\"from\": \"G8\", \"to\": \"D2\", \"strength\": 0.85},  \n",
    "    {\"from\": \"G8\", \"to\": \"D6\", \"strength\": 0.75},  \n",
    "    {\"from\": \"G8\", \"to\": \"D19\", \"strength\": 0.80},  \n",
    "    {\"from\": \"G8\", \"to\": \"D5\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G8\", \"to\": \"D18\", \"strength\": 0.40},  \n",
    "    \n",
    "    # TNF associations (G9)  \n",
    "    {\"from\": \"G9\", \"to\": \"D10\", \"strength\": 0.85},  \n",
    "    {\"from\": \"G9\", \"to\": \"D7\", \"strength\": 0.65},  \n",
    "    {\"from\": \"G9\", \"to\": \"D9\", \"strength\": 0.70},  \n",
    "    {\"from\": \"G9\", \"to\": \"D17\", \"strength\": 0.50},  \n",
    "    {\"from\": \"G9\", \"to\": \"D15\", \"strength\": 0.35},  \n",
    "    \n",
    "    # IL6 associations (G10)  \n",
    "    {\"from\": \"G10\", \"to\": \"D10\", \"strength\": 0.80},  \n",
    "    {\"from\": \"G10\", \"to\": \"D9\", \"strength\": 0.65},  \n",
    "    {\"from\": \"G10\", \"to\": \"D5\", \"strength\": 0.55},  \n",
    "    {\"from\": \"G10\", \"to\": \"D12\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G10\", \"to\": \"D11\", \"strength\": 0.25},  \n",
    "    \n",
    "    # ACE2 associations (G11)  \n",
    "    {\"from\": \"G11\", \"to\": \"D12\", \"strength\": 0.80},  \n",
    "    {\"from\": \"G11\", \"to\": \"D5\", \"strength\": 0.50},  \n",
    "    {\"from\": \"G11\", \"to\": \"D6\", \"strength\": 0.65},  \n",
    "    {\"from\": \"G11\", \"to\": \"D3\", \"strength\": 0.20},  \n",
    "    \n",
    "    # MTHFR associations (G12)  \n",
    "    {\"from\": \"G12\", \"to\": \"D6\", \"strength\": 0.60},  \n",
    "    {\"from\": \"G12\", \"to\": \"D13\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G12\", \"to\": \"D15\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G12\", \"to\": \"D19\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G12\", \"to\": \"D17\", \"strength\": 0.40},  \n",
    "    \n",
    "    # COMT associations (G13)  \n",
    "    {\"from\": \"G13\", \"to\": \"D13\", \"strength\": 0.70},  \n",
    "    {\"from\": \"G13\", \"to\": \"D14\", \"strength\": 0.65},  \n",
    "    {\"from\": \"G13\", \"to\": \"D8\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G13\", \"to\": \"D4\", \"strength\": 0.40},  \n",
    "    \n",
    "    # HTT associations (G14)  \n",
    "    {\"from\": \"G14\", \"to\": \"D4\", \"strength\": 0.98},  \n",
    "    {\"from\": \"G14\", \"to\": \"D8\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G14\", \"to\": \"D13\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G14\", \"to\": \"D17\", \"strength\": 0.35},  \n",
    "    \n",
    "    # SOD1 associations (G15)  \n",
    "    {\"from\": \"G15\", \"to\": \"D8\", \"strength\": 0.65},  \n",
    "    {\"from\": \"G15\", \"to\": \"D9\", \"strength\": 0.55},  \n",
    "    {\"from\": \"G15\", \"to\": \"D15\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G15\", \"to\": \"D2\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G15\", \"to\": \"D3\", \"strength\": 0.30},  \n",
    "    \n",
    "    # DMD associations (G16)  \n",
    "    {\"from\": \"G16\", \"to\": \"D16\", \"strength\": 0.95},  \n",
    "    {\"from\": \"G16\", \"to\": \"D6\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G16\", \"to\": \"D15\", \"strength\": 0.30},  \n",
    "    \n",
    "    # FMR1 associations (G17)  \n",
    "    {\"from\": \"G17\", \"to\": \"D18\", \"strength\": 0.95},  \n",
    "    {\"from\": \"G17\", \"to\": \"D13\", \"strength\": 0.50},  \n",
    "    {\"from\": \"G17\", \"to\": \"D14\", \"strength\": 0.45},  \n",
    "    \n",
    "    # LDLR associations (G18)  \n",
    "    {\"from\": \"G18\", \"to\": \"D19\", \"strength\": 0.95},  \n",
    "    {\"from\": \"G18\", \"to\": \"D6\", \"strength\": 0.75},  \n",
    "    {\"from\": \"G18\", \"to\": \"D5\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G18\", \"to\": \"D11\", \"strength\": 0.35},  \n",
    "    \n",
    "    # NF1 associations (G19)  \n",
    "    {\"from\": \"G19\", \"to\": \"D0\", \"strength\": 0.50},  \n",
    "    {\"from\": \"G19\", \"to\": \"D1\", \"strength\": 0.45},  \n",
    "    {\"from\": \"G19\", \"to\": \"D9\", \"strength\": 0.35},  \n",
    "    {\"from\": \"G19\", \"to\": \"D16\", \"strength\": 0.40},  \n",
    "    {\"from\": \"G19\", \"to\": \"D4\", \"strength\": 0.35}  \n",
    "]  \n",
    "\n",
    "\n",
    "# Verfication script would confirm all constraints are satisfied\n",
    "verification_output = verify_gene_disease_association_network(genes, diseases, associations)\n",
    "\n",
    "print(\"Gene-Disease Association Network is valid:\", verification_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6959fed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. GPT4omini\n",
      "2. Claude35Haiku\n",
      "3. Gemini20Flash\n",
      "4. DeepSeekV3\n",
      "5. Llama32\n",
      "6. GPT4o\n",
      "7. Claude35Sonnet\n",
      "8. Gemini20Pro\n",
      "9. Llama31405B\n",
      "10. DeepSeekR1\n",
      "11. o3mini\n",
      "12. o1\n",
      "13. Llama318B\n",
      "14. GrokV3\n",
      "15. Claude37Sonnet\n",
      "Select a model by number: 15\n",
      "\n",
      "Available Prompt Types:\n",
      "1. directprompt\n",
      "2. iterativefeedback\n",
      "3. programaugmented\n",
      "Select a prompt type by number: 2\n",
      "\n",
      "Enter the run number (1-5): 5\n",
      "Save is succesful! results/geneAssociation_Claude37Sonnet_iterativefeedback_run5_output.json\n"
     ]
    }
   ],
   "source": [
    "# import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama32\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini20Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\", \"Llama318B\", \"GrokV3\",\"Claude37Sonnet\"]\n",
    "\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"geneAssociation\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\" Asks the user for model, prompt type, run number, and problem type \"\"\"\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "verification_json = {\n",
    "    \"genes\": genes,\n",
    "    \"diseases\": diseases,\n",
    "    \"associations\": associations,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45e101",
   "metadata": {},
   "source": [
    "## Optimal Network Design Challenge\n",
    "\n",
    "### Problem Description\n",
    "\n",
    "Design an optimal transportation network represented as a **directed graph** where nodes represent cities and edges represent one-way roads. The network must satisfy the following constraints to ensure efficiency, connectivity, robustness, and cost-effectiveness:\n",
    "\n",
    "#### 1. Nodes (Cities):\n",
    "- **Total:** 8, labeled from `C0` to `C7`.\n",
    "- **Attributes:**\n",
    "  - **Population:** Number of inhabitants in each city.\n",
    "    - `C0`: 1,000\n",
    "    - `C1`: 500\n",
    "    - `C2`: 750\n",
    "    - `C3`: 600\n",
    "    - `C4`: 900\n",
    "    - `C5`: 400\n",
    "    - `C6`: 800\n",
    "    - `C7`: 650\n",
    "\n",
    "#### 2. Edges (Roads):\n",
    "- **Definition:** Represents a one-way road from one city to another.\n",
    "- **Attributes:**\n",
    "  - **Distance:** Length of the road in kilometers (km). *(Each road must be ≤ 300 km.)*\n",
    "  - **Construction Cost:** Cost to build the road in thousand dollars ($K).\n",
    "\n",
    "#### 3. Constraints:\n",
    "1. **Connectivity:**\n",
    "   - The network must be **strongly connected**, meaning there is a directed path from any city to every other city.\n",
    "\n",
    "2. **Road Capacity:**\n",
    "   - No single road should be longer than **300 km**.\n",
    "\n",
    "3. **Cost Optimization:**\n",
    "   - The **total construction cost** of all roads should not exceed **$10,000K**.\n",
    "\n",
    "4. **Population Accessibility:**\n",
    "   - Each city must have **at least two incoming roads** to ensure redundancy and accessibility.\n",
    "\n",
    "5. **Strategic Road Placement:**\n",
    "   - Cities `C0` and `C7` are major hubs and **must have at least three outgoing roads** each to distribute traffic efficiently.\n",
    "\n",
    "6. **Avoiding Redundancy:**\n",
    "   - **No two cities** should have more than **one direct road** connecting them in the same direction.\n",
    "\n",
    "7. **Minimizing Total Distance:**\n",
    "   - The **sum of all road distances** should be minimized to ensure efficient transportation.\n",
    "\n",
    "8. **2-Edge Robustness:**\n",
    "   - The network must remain strongly connected if **any single road is removed** (i.e. there must be two edge‑disjoint paths between every ordered pair of cities).\n",
    "\n",
    "9. **Edge-Disjoint Paths Guarantee:**\n",
    "   - For every pair of distinct cities, there must exist **at least two completely independent (edge‑disjoint) paths** connecting them.\n",
    "\n",
    "10. **Balanced Outgoing Degree:**\n",
    "    - Except for the designated hubs (`C0` and `C7`), the difference between the maximum and minimum number of outgoing roads among all cities must not exceed **2**. This prevents “overloaded” junctions.\n",
    "\n",
    "11. **Path Efficiency Constraint:**\n",
    "    - For every pair of cities, the shortest route (by total distance) should be less than **500 km** to ensure quick intercity transit.\n",
    "\n",
    "12. **Cost–Distance Consistency:**\n",
    "    - For every road, the construction cost (in $K) must be **between 1.0 and 1.5 times its distance (in km)**.  \n",
    "      *Example:* A road that is 90 km long must have a cost between **90K** and **135K**.\n",
    "     \n",
    "13. **Maximum Edge-Hop Constraint:**\n",
    "    - For every pair of cities, you need to be able to get to every other city in at most 3 edges.\n",
    "\n",
    "### Required Output Format\n",
    "\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "cities = [\n",
    "    {\"id\": \"C0\", \"population\": 1000},\n",
    "    {\"id\": \"C1\", \"population\": 500},\n",
    "    # ... all cities (C2-C7)\n",
    "]\n",
    "\n",
    "roads = [\n",
    "    {\"from\": \"C0\", \"to\": \"C1\", \"distance\": float, \"cost\": float},\n",
    "    {\"from\": \"C1\", \"to\": \"C2\", \"distance\": float, \"cost\": float},\n",
    "    # ... all roads\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "973d81c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Output: (True, {'output_structure': {'passed': True, 'message': ''}, 'connectivity': {'passed': True, 'message': ''}, 'road_capacity': {'passed': True, 'message': ''}, 'cost_optimization': {'passed': True, 'message': ''}, 'population_accessibility': {'passed': True, 'message': ''}, 'strategic_road_placement': {'passed': True, 'message': ''}, 'redundancy': {'passed': True, 'message': ''}, 'max_edges_constraint': {'passed': True, 'message': ''}, 'overall_passed': True, 'errors': []})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def verify_optimal_network_design(cities, roads):\n",
    "    verification_results = {\n",
    "        \"output_structure\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"connectivity\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"road_capacity\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"cost_optimization\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"population_accessibility\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"strategic_road_placement\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"redundancy\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"max_edges_constraint\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"overall_passed\": False,\n",
    "        \"errors\": []\n",
    "    }\n",
    "\n",
    "    def add_constraint_message(constraint_key, msg):\n",
    "        \"\"\"\n",
    "        Mark the given constraint as failed and append `msg` to its 'message' string,\n",
    "        as well as appending `msg` to the top-level 'errors' array.\n",
    "        \"\"\"\n",
    "        verification_results[constraint_key][\"passed\"] = False\n",
    "        if verification_results[constraint_key][\"message\"]:\n",
    "            verification_results[constraint_key][\"message\"] += \" \" + msg\n",
    "        else:\n",
    "            verification_results[constraint_key][\"message\"] = msg\n",
    "        verification_results[\"errors\"].append(msg)\n",
    "\n",
    "    # 1. Check 'cities' structure\n",
    "    if not isinstance(cities, list):\n",
    "        verification_results[\"output_structure\"][\"message\"] = \"'cities' should be a list.\"\n",
    "        return False, verification_results\n",
    "    city_ids = set()\n",
    "    city_population = {}\n",
    "    for city in cities:\n",
    "        if not isinstance(city, dict):\n",
    "            add_constraint_message(\"output_structure\", \"Each city should be a dictionary.\")\n",
    "            continue\n",
    "        if \"id\" not in city or \"population\" not in city:\n",
    "            cid = city.get(\"id\", \"Unknown\")\n",
    "            add_constraint_message(\"output_structure\", f\"City {cid} is missing 'id' or 'population'.\")\n",
    "            continue\n",
    "        cid = city[\"id\"]\n",
    "        pop = city[\"population\"]\n",
    "        if cid in city_ids:\n",
    "            add_constraint_message(\"output_structure\", f\"Duplicate city ID detected: {cid}.\")\n",
    "            continue\n",
    "        city_ids.add(cid)\n",
    "        city_population[cid] = pop\n",
    "\n",
    "    # 2. Check 'roads' structure\n",
    "    if not isinstance(roads, list):\n",
    "        verification_results[\"output_structure\"][\"message\"] += \" 'roads' should be a list.\"\n",
    "        return False, verification_results\n",
    "    adjacency = defaultdict(list)\n",
    "    road_set = set()\n",
    "    total_cost = 0.0\n",
    "    road_unique = True\n",
    "    road_capacity_passed = True\n",
    "    road_capacity_msgs = []\n",
    "    for road in roads:\n",
    "        if not isinstance(road, dict):\n",
    "            add_constraint_message(\"output_structure\", \"Each road should be a dictionary.\")\n",
    "            continue\n",
    "        required_keys = {\"from\", \"to\", \"distance\", \"cost\"}\n",
    "        if not required_keys.issubset(road.keys()):\n",
    "            missing = required_keys - set(road.keys())\n",
    "            msg = f\"Road from {road.get('from', 'Unknown')} to {road.get('to', 'Unknown')} missing {missing}.\"\n",
    "            add_constraint_message(\"output_structure\", msg)\n",
    "            continue\n",
    "        from_city = road[\"from\"]\n",
    "        to_city = road[\"to\"]\n",
    "        dist = road[\"distance\"]\n",
    "        cost_val = road[\"cost\"]\n",
    "        if from_city not in city_ids:\n",
    "            add_constraint_message(\"output_structure\", f\"Road 'from' city '{from_city}' is not defined.\")\n",
    "        if to_city not in city_ids:\n",
    "            add_constraint_message(\"output_structure\", f\"Road 'to' city '{to_city}' is not defined.\")\n",
    "        if not isinstance(dist, (int, float)) or dist > 300:\n",
    "            msg = f\"Road from '{from_city}' to '{to_city}' has invalid distance {dist} km (must be <= 300).\"\n",
    "            add_constraint_message(\"road_capacity\", msg)\n",
    "            road_capacity_passed = False\n",
    "            road_capacity_msgs.append(msg)\n",
    "        if not isinstance(cost_val, (int, float)) or cost_val <= 0:\n",
    "            add_constraint_message(\"output_structure\", f\"Road from '{from_city}' to '{to_city}' has invalid cost {cost_val}K (must be positive).\")\n",
    "        road_key = (from_city, to_city)\n",
    "        if road_key in road_set:\n",
    "            add_constraint_message(\"output_structure\", f\"Duplicate road from '{from_city}' to '{to_city}'.\")\n",
    "            road_unique = False\n",
    "        else:\n",
    "            road_set.add(road_key)\n",
    "        adjacency[from_city].append(to_city)\n",
    "        total_cost += cost_val\n",
    "\n",
    "    # Mark output_structure passed if still no error\n",
    "    if not verification_results[\"output_structure\"][\"message\"]:\n",
    "        verification_results[\"output_structure\"][\"passed\"] = True\n",
    "\n",
    "    # 3. Road Capacity\n",
    "    if road_capacity_passed:\n",
    "        verification_results[\"road_capacity\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"road_capacity\"][\"passed\"] = False\n",
    "        verification_results[\"road_capacity\"][\"message\"] = \"; \".join(road_capacity_msgs)\n",
    "\n",
    "    # 4. Cost Optimization\n",
    "    if total_cost <= 10000:\n",
    "        verification_results[\"cost_optimization\"][\"passed\"] = True\n",
    "    else:\n",
    "        msg = f\"Total construction cost is {total_cost}K, exceeding 10000K limit.\"\n",
    "        add_constraint_message(\"cost_optimization\", msg)\n",
    "\n",
    "    # 5. Connectivity (strongly connected)\n",
    "    def kosaraju_scc(adj, nodes):\n",
    "        visited = set()\n",
    "        stack = []\n",
    "        def dfs(u):\n",
    "            visited.add(u)\n",
    "            for v in adj[u]:\n",
    "                if v not in visited:\n",
    "                    dfs(v)\n",
    "            stack.append(u)\n",
    "        for u in nodes:\n",
    "            if u not in visited:\n",
    "                dfs(u)\n",
    "        # transpose\n",
    "        transposed = defaultdict(list)\n",
    "        for u in adj:\n",
    "            for v in adj[u]:\n",
    "                transposed[v].append(u)\n",
    "        visited.clear()\n",
    "        sccs = []\n",
    "        def dfs_t(u, comp):\n",
    "            visited.add(u)\n",
    "            comp.append(u)\n",
    "            for w in transposed[u]:\n",
    "                if w not in visited:\n",
    "                    dfs_t(w, comp)\n",
    "        while stack:\n",
    "            node = stack.pop()\n",
    "            if node not in visited:\n",
    "                comp = []\n",
    "                dfs_t(node, comp)\n",
    "                sccs.append(comp)\n",
    "        return sccs\n",
    "\n",
    "    scc = kosaraju_scc(adjacency, city_ids)\n",
    "    if len(scc) == 1:\n",
    "        verification_results[\"connectivity\"][\"passed\"] = True\n",
    "    else:\n",
    "        msg = \"The network is not strongly connected.\"\n",
    "        add_constraint_message(\"connectivity\", msg)\n",
    "\n",
    "    # 6. Population Accessibility (each city needs >=2 incoming roads)\n",
    "    incoming = defaultdict(int)\n",
    "    for road in roads:\n",
    "        incoming[road[\"to\"]] += 1\n",
    "    pop_access_ok = True\n",
    "    pop_access_msgs = []\n",
    "    for cid in city_ids:\n",
    "        if incoming[cid] < 2:\n",
    "            pop_access_ok = False\n",
    "            pop_access_msgs.append(f\"City '{cid}' has only {incoming[cid]} incoming roads; needs >=2.\")\n",
    "    if pop_access_ok:\n",
    "        verification_results[\"population_accessibility\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"population_accessibility\"][\"passed\"] = False\n",
    "        verification_results[\"population_accessibility\"][\"message\"] = \" \".join(pop_access_msgs)\n",
    "        verification_results[\"errors\"].extend(pop_access_msgs)\n",
    "\n",
    "    # 7. Strategic road placement: C0 and C7 need >=3 outgoing roads\n",
    "    strategic_ok = True\n",
    "    strategic_msgs = []\n",
    "    for hub in [\"C0\", \"C7\"]:\n",
    "        out_count = len(adjacency[hub])\n",
    "        if out_count < 3:\n",
    "            strategic_ok = False\n",
    "            strategic_msgs.append(f\"Critical city '{hub}' has only {out_count} outgoing roads; needs >=3.\")\n",
    "    if strategic_ok:\n",
    "        verification_results[\"strategic_road_placement\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"strategic_road_placement\"][\"passed\"] = False\n",
    "        verification_results[\"strategic_road_placement\"][\"message\"] = \" \".join(strategic_msgs)\n",
    "        verification_results[\"errors\"].extend(strategic_msgs)\n",
    "\n",
    "    # 8. Redundancy\n",
    "    # (We define redundancy as passing connectivity + population_accessibility)\n",
    "    if verification_results[\"connectivity\"][\"passed\"] and verification_results[\"population_accessibility\"][\"passed\"]:\n",
    "        verification_results[\"redundancy\"][\"passed\"] = True\n",
    "    else:\n",
    "        msg = \"Insufficient redundancy due to failing connectivity or population accessibility.\"\n",
    "        verification_results[\"redundancy\"][\"passed\"] = False\n",
    "        verification_results[\"redundancy\"][\"message\"] = msg\n",
    "        verification_results[\"errors\"].append(msg)\n",
    "\n",
    "    # 9. Output structure is \"passed\" if road_unique was never set false\n",
    "    if verification_results[\"output_structure\"][\"passed\"]:\n",
    "        # If road_unique is false, mark output_structure as false\n",
    "        if not road_unique:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = False\n",
    "            if not verification_results[\"output_structure\"][\"message\"]:\n",
    "                verification_results[\"output_structure\"][\"message\"] = \"Duplicate roads found.\"\n",
    "\n",
    "    # 10. Max edges constraint: BFS up to 3 edges\n",
    "    max_edges_ok = True\n",
    "    max_edges_msgs = []\n",
    "    from collections import deque\n",
    "    for start in city_ids:\n",
    "        visited = {start: 0}\n",
    "        queue = deque([start])\n",
    "        while queue:\n",
    "            curr = queue.popleft()\n",
    "            for nxt in adjacency[curr]:\n",
    "                if nxt not in visited:\n",
    "                    visited[nxt] = visited[curr] + 1\n",
    "                    if visited[nxt] <= 3:\n",
    "                        queue.append(nxt)\n",
    "        for cid in city_ids:\n",
    "            if cid != start:\n",
    "                if cid not in visited or visited[cid] > 3:\n",
    "                    max_edges_ok = False\n",
    "                    max_edges_msgs.append(f\"City '{cid}' not reachable from '{start}' in <=3 edges.\")\n",
    "    if max_edges_ok:\n",
    "        verification_results[\"max_edges_constraint\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"max_edges_constraint\"][\"passed\"] = False\n",
    "        verification_results[\"max_edges_constraint\"][\"message\"] = \" \".join(max_edges_msgs)\n",
    "        verification_results[\"errors\"].extend(max_edges_msgs)\n",
    "\n",
    "    # Overall\n",
    "    overall = all([\n",
    "        verification_results[\"output_structure\"][\"passed\"],\n",
    "        verification_results[\"connectivity\"][\"passed\"],\n",
    "        verification_results[\"road_capacity\"][\"passed\"],\n",
    "        verification_results[\"cost_optimization\"][\"passed\"],\n",
    "        verification_results[\"population_accessibility\"][\"passed\"],\n",
    "        verification_results[\"strategic_road_placement\"][\"passed\"],\n",
    "        verification_results[\"redundancy\"][\"passed\"],\n",
    "        verification_results[\"max_edges_constraint\"][\"passed\"]\n",
    "    ])\n",
    "    verification_results[\"overall_passed\"] = overall\n",
    "    return overall, verification_results\n",
    "\n",
    "cities = [  \n",
    "    {\"id\": \"C0\", \"population\": 1000},  \n",
    "    {\"id\": \"C1\", \"population\": 500},  \n",
    "    {\"id\": \"C2\", \"population\": 750},  \n",
    "    {\"id\": \"C3\", \"population\": 600},  \n",
    "    {\"id\": \"C4\", \"population\": 900},  \n",
    "    {\"id\": \"C5\", \"population\": 400},  \n",
    "    {\"id\": \"C6\", \"population\": 800},  \n",
    "    {\"id\": \"C7\", \"population\": 650}  \n",
    "]  \n",
    "\n",
    "roads = [  \n",
    "    {\"from\": \"C0\", \"to\": \"C1\", \"distance\": 80.0, \"cost\": 100.0},  \n",
    "    {\"from\": \"C1\", \"to\": \"C2\", \"distance\": 100.0, \"cost\": 125.0},  \n",
    "    {\"from\": \"C2\", \"to\": \"C3\", \"distance\": 90.0, \"cost\": 120.0},  \n",
    "    {\"from\": \"C3\", \"to\": \"C4\", \"distance\": 100.0, \"cost\": 125.0},  \n",
    "    {\"from\": \"C4\", \"to\": \"C5\", \"distance\": 80.0, \"cost\": 100.0},  \n",
    "    {\"from\": \"C5\", \"to\": \"C6\", \"distance\": 90.0, \"cost\": 120.0},  \n",
    "    {\"from\": \"C6\", \"to\": \"C7\", \"distance\": 100.0, \"cost\": 125.0},  \n",
    "    {\"from\": \"C7\", \"to\": \"C0\", \"distance\": 150.0, \"cost\": 200.0},  \n",
    "    {\"from\": \"C0\", \"to\": \"C3\", \"distance\": 150.0, \"cost\": 200.0},  \n",
    "    {\"from\": \"C0\", \"to\": \"C5\", \"distance\": 160.0, \"cost\": 220.0},  \n",
    "    {\"from\": \"C7\", \"to\": \"C2\", \"distance\": 150.0, \"cost\": 200.0},  \n",
    "    {\"from\": \"C7\", \"to\": \"C4\", \"distance\": 160.0, \"cost\": 220.0},  \n",
    "    {\"from\": \"C2\", \"to\": \"C0\", \"distance\": 130.0, \"cost\": 180.0},  \n",
    "    {\"from\": \"C4\", \"to\": \"C1\", \"distance\": 130.0, \"cost\": 180.0},  \n",
    "    {\"from\": \"C6\", \"to\": \"C4\", \"distance\": 120.0, \"cost\": 160.0},  \n",
    "    {\"from\": \"C3\", \"to\": \"C7\", \"distance\": 140.0, \"cost\": 190.0},  \n",
    "    {\"from\": \"C5\", \"to\": \"C7\", \"distance\": 140.0, \"cost\": 190.0},  \n",
    "    {\"from\": \"C1\", \"to\": \"C6\", \"distance\": 150.0, \"cost\": 200.0},  \n",
    "    {\"from\": \"C6\", \"to\": \"C0\", \"distance\": 160.0, \"cost\": 220.0},  \n",
    "    {\"from\": \"C1\", \"to\": \"C7\", \"distance\": 170.0, \"cost\": 230.0}  \n",
    "]  \n",
    "\n",
    "verification_output = verify_optimal_network_design(cities, roads)\n",
    "print(\"Verification Output:\", verification_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "fb276ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. GPT4omini\n",
      "2. Claude35Haiku\n",
      "3. Gemini20Flash\n",
      "4. DeepSeekV3\n",
      "5. Llama32\n",
      "6. GPT4o\n",
      "7. Claude35Sonnet\n",
      "8. Gemini20Pro\n",
      "9. Llama31405B\n",
      "10. DeepSeekR1\n",
      "11. o3mini\n",
      "12. o1\n",
      "13. Llama318B\n",
      "14. GrokV3\n",
      "15. Claude37Sonnet\n",
      "Select a model by number: 15\n",
      "\n",
      "Available Prompt Types:\n",
      "1. directprompt\n",
      "2. iterativefeedback\n",
      "3. programaugmented\n",
      "Select a prompt type by number: 2\n",
      "\n",
      "Enter the run number (1-5): 5\n",
      "Save is succesful! results/cities_Claude37Sonnet_iterativefeedback_run5_output.json\n"
     ]
    }
   ],
   "source": [
    "# import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama32\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini20Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\", \"Llama318B\", \"GrokV3\",\"Claude37Sonnet\"]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"cities\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\" Asks the user for model, prompt type, run number, and problem type \"\"\"\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"cities\":cities,\n",
    "    \"roads\":roads,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a09b0ba",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
