{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c20d72e7",
   "metadata": {},
   "source": [
    "### For the program augmented prompt, add \"Here is the script that I will use to verify your output: \"INSERT SCRIPT\" to the end of the direct prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f600d",
   "metadata": {},
   "source": [
    "# Time-Dependent Delivery Network\n",
    "\n",
    "Design a time-dependent delivery network based on the specifications below.\n",
    "\n",
    "## Problem Description:\n",
    "Create a delivery network that schedules deliveries across multiple locations using a fleet of vehicles. The network must account for vehicle capacities, location storage capacities, delivery time windows, dynamic travel times, and vehicle speeds to ensure efficient and timely deliveries.\n",
    "\n",
    "## Constraints:\n",
    "1. **Locations:**\n",
    "   - **Total Locations:** 15, labeled from `L0` to `L14`.\n",
    "   - **Attributes:**\n",
    "     - **Storage Capacity:** Each location has a storage capacity specified in kilograms (kg). Example: `L0` has a capacity of 500 kg.\n",
    "     - **Time Window:** Each location has a delivery time window represented as a list of two integers `[start_hour, end_hour]` in 24-hour format. Example: `L3` has a time window of `[9, 11]` corresponding to 09:00-11:00.\n",
    "\n",
    "2. **Vehicles:**\n",
    "   - **Total Vehicles:** 7, labeled from `V1` to `V7`.\n",
    "   - **Attributes:**\n",
    "     - **Capacity:** Each vehicle has a specific capacity in kilograms (kg). Example: `V1` has a capacity of 100 kg.\n",
    "     - **Speed:** Each vehicle has a defined speed in kilometers per hour (km/h). Example: `V1` travels at 60 km/h.\n",
    "\n",
    "3. **Edges (Routes):**\n",
    "   - **Definition:** Represents travel paths between two distinct locations.\n",
    "   - **Attributes:**\n",
    "     - **From:** The starting location ID (e.g., `L0`).\n",
    "     - **To:** The destination location ID (e.g., `L1`).\n",
    "     - **Base Travel Time:** The fundamental travel time for the route in minutes.\n",
    "     - **Hourly Adjustments:** A dictionary where keys are time ranges in the format `\"HH-HH\"` (24-hour format) and values are additional travel time in minutes applicable during those hours. Example: `{\"8-10\": 15}` adds 15 minutes to the base travel time between 08:00-10:00.\n",
    "     - **Maximum Weight Limit:** The maximum weight a vehicle can carry on that route in kilograms (kg).\n",
    "\n",
    "4. **Operational Constraints:**\n",
    "   - **Storage Capacity Compliance:** The sum of incoming goods to any location must not exceed its storage capacity.\n",
    "   - **Vehicle Capacity Compliance:** No vehicle should exceed its capacity on any edge it traverses.\n",
    "   - **Time Window Compliance:** Departures and arrivals must respect the time windows of locations. Specifically:\n",
    "     - **Departure Time:** Must be within the `from` location's time window.\n",
    "     - **Arrival Time:** Must be within the `to` location's time window.\n",
    "     - **Loading Time:** Assume a fixed loading time of 10 minutes at each location, which must be accounted for when scheduling departures.\n",
    "\n",
    "## Required Output Format:\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "locations = [\n",
    "    {\"id\": \"L0\", \"capacity\": int, \"time_window\": [int, int]},\n",
    "    {\"id\": \"L1\", \"capacity\": int, \"time_window\": [int, int]},\n",
    "    # ... all locations (L2-L14)\n",
    "]\n",
    "\n",
    "vehicles = [\n",
    "    {\"id\": \"V1\", \"capacity\": int, \"speed\": int},\n",
    "    {\"id\": \"V2\", \"capacity\": int, \"speed\": int},\n",
    "    # ... all vehicles (V3-V7)\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    {\"from\": \"L0\", \"to\": \"L1\", \"base_time\": int, \"hourly_adjust\": {\"HH-HH\": int}, \"max_weight\": int},\n",
    "    {\"from\": \"L1\", \"to\": \"L2\", \"base_time\": int, \"hourly_adjust\": {\"HH-HH\": int}, \"max_weight\": int},\n",
    "    # ... more edges\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c234d47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Output: {'output_structure': {'passed': True, 'message': ''}, 'storage_capacity_compliance': {'passed': True, 'message': ''}, 'vehicle_capacity_compliance': {'passed': False, 'message': \"Edge from 'L0' to 'L1' has 'max_weight' 200 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L0' to 'L3' has 'max_weight' 250 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L1' to 'L4' has 'max_weight' 180 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L1' to 'L5' has 'max_weight' 150 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L2' to 'L6' has 'max_weight' 220 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L3' to 'L8' has 'max_weight' 200 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L3' to 'L9' has 'max_weight' 150 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L4' to 'L10' has 'max_weight' 180 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L4' to 'L11' has 'max_weight' 250 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L5' to 'L13' has 'max_weight' 200 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L6' to 'L14' has 'max_weight' 180 kg, which is less than the maximum vehicle capacity of 300 kg. Edge from 'L1' to 'L0' has 'max_weight' 200 kg, which is less than the maximum vehicle capacity of 300 kg.\"}, 'time_window_compliance': {'passed': False, 'message': \"Edge from 'L1' to 'L5' with total travel time 45 minutes does not fit within the time windows of 'L1' [8-10] and 'L5' [11-13]. Edge from 'L2' to 'L7' with total travel time 50 minutes does not fit within the time windows of 'L2' [9-12] and 'L7' [14-17]. Edge from 'L3' to 'L8' with total travel time 45 minutes does not fit within the time windows of 'L3' [9-11] and 'L8' [12-18].\"}, 'overall_passed': False, 'errors': ['Vehicle Capacity Compliance Check Failed.', 'Time Window Compliance Check Failed.']}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "def verify_time_dependent_delivery_network(locations, vehicles, edges):\n",
    "    verification_results = {\n",
    "        \"output_structure\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"storage_capacity_compliance\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"vehicle_capacity_compliance\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"time_window_compliance\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"overall_passed\": False,\n",
    "        \"errors\": []\n",
    "    }\n",
    "    def add_error(message):\n",
    "        verification_results[\"errors\"].append(message)\n",
    "\n",
    "    if not isinstance(locations, list):\n",
    "        add_error(\"'locations' should be a list.\")\n",
    "    elif len(locations) != 15:\n",
    "        add_error(f\"Number of locations is {len(locations)}; expected 15.\")\n",
    "    else:\n",
    "        location_ids = set()\n",
    "        location_valid = True\n",
    "        for loc in locations:\n",
    "            if not isinstance(loc, dict):\n",
    "                add_error(\"Each location should be a dictionary.\")\n",
    "                location_valid = False\n",
    "                continue\n",
    "            required_loc_keys = {\"id\", \"capacity\", \"time_window\"}\n",
    "            if not required_loc_keys.issubset(loc.keys()):\n",
    "                add_error(f\"Location {loc.get('id', 'Unknown')} is missing required keys: {required_loc_keys - set(loc.keys())}.\")\n",
    "                location_valid = False\n",
    "                continue\n",
    "            if not re.fullmatch(r\"L\\d+\", loc[\"id\"]):\n",
    "                add_error(f\"Location ID '{loc['id']}' is invalid. Expected format 'L0' to 'L14'.\")\n",
    "                location_valid = False\n",
    "            location_ids.add(loc[\"id\"])\n",
    "            if not isinstance(loc[\"capacity\"], int) or loc[\"capacity\"] <= 0:\n",
    "                add_error(f\"Location '{loc['id']}' has invalid 'capacity'. Must be a positive integer.\")\n",
    "                location_valid = False\n",
    "            if (not isinstance(loc[\"time_window\"], list) or\n",
    "                len(loc[\"time_window\"]) != 2 or\n",
    "                not all(isinstance(t, int) for t in loc[\"time_window\"])):\n",
    "                add_error(f\"Location '{loc['id']}' has invalid 'time_window'. Must be a list of two integers.\")\n",
    "                location_valid = False\n",
    "            else:\n",
    "                start, end = loc[\"time_window\"]\n",
    "                if not (0 <= start < end <= 24):\n",
    "                    add_error(f\"Location '{loc['id']}' has invalid 'time_window' values: {loc['time_window']}. Must satisfy 0 <= start < end <= 24.\")\n",
    "                    location_valid = False\n",
    "        if location_valid:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = True\n",
    "        else:\n",
    "            verification_results[\"output_structure\"][\"message\"] = \"Errors found in 'locations' structure.\"\n",
    "    \n",
    "    if not isinstance(vehicles, list):\n",
    "        add_error(\"'vehicles' should be a list.\")\n",
    "    elif len(vehicles) != 7:\n",
    "        add_error(f\"Number of vehicles is {len(vehicles)}; expected 7.\")\n",
    "    else:\n",
    "        vehicle_ids = set()\n",
    "        vehicle_valid = True\n",
    "        vehicle_capacities = []\n",
    "        for veh in vehicles:\n",
    "            if not isinstance(veh, dict):\n",
    "                add_error(\"Each vehicle should be a dictionary.\")\n",
    "                vehicle_valid = False\n",
    "                continue\n",
    "            required_veh_keys = {\"id\", \"capacity\", \"speed\"}\n",
    "            if not required_veh_keys.issubset(veh.keys()):\n",
    "                add_error(f\"Vehicle {veh.get('id', 'Unknown')} is missing required keys: {required_veh_keys - set(veh.keys())}.\")\n",
    "                vehicle_valid = False\n",
    "                continue\n",
    "            if not re.fullmatch(r\"V\\d+\", veh[\"id\"]):\n",
    "                add_error(f\"Vehicle ID '{veh['id']}' is invalid. Expected format 'V1' to 'V7'.\")\n",
    "                vehicle_valid = False\n",
    "            vehicle_ids.add(veh[\"id\"])\n",
    "            if not isinstance(veh[\"capacity\"], int) or veh[\"capacity\"] <= 0:\n",
    "                add_error(f\"Vehicle '{veh['id']}' has invalid 'capacity'. Must be a positive integer.\")\n",
    "                vehicle_valid = False\n",
    "            else:\n",
    "                vehicle_capacities.append(veh[\"capacity\"])\n",
    "            if not isinstance(veh[\"speed\"], int) or veh[\"speed\"] <= 0:\n",
    "                add_error(f\"Vehicle '{veh['id']}' has invalid 'speed'. Must be a positive integer.\")\n",
    "                vehicle_valid = False\n",
    "        if vehicle_valid:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = verification_results[\"output_structure\"][\"passed\"] and True\n",
    "        else:\n",
    "            verification_results[\"output_structure\"][\"message\"] += \" Errors found in 'vehicles' structure.\"\n",
    "    \n",
    "    if not isinstance(edges, list):\n",
    "        add_error(\"'edges' should be a list.\")\n",
    "    elif len(edges) == 0:\n",
    "        add_error(\"No edges defined in the network.\")\n",
    "    else:\n",
    "        edge_pairs = set()\n",
    "        incoming_weights = defaultdict(int)\n",
    "        edge_valid = True\n",
    "        for edge in edges:\n",
    "            if not isinstance(edge, dict):\n",
    "                add_error(\"Each edge should be a dictionary.\")\n",
    "                edge_valid = False\n",
    "                continue\n",
    "            required_edge_keys = {\"from\", \"to\", \"base_time\", \"hourly_adjust\", \"max_weight\"}\n",
    "            if not required_edge_keys.issubset(edge.keys()):\n",
    "                add_error(f\"Edge from '{edge.get('from', 'Unknown')}' to '{edge.get('to', 'Unknown')}' is missing required keys: {required_edge_keys - set(edge.keys())}.\")\n",
    "                edge_valid = False\n",
    "                continue\n",
    "            from_id = edge[\"from\"]\n",
    "            to_id = edge[\"to\"]\n",
    "            if from_id not in location_ids:\n",
    "                add_error(f\"Edge 'from' location '{from_id}' is not defined among locations.\")\n",
    "                edge_valid = False\n",
    "            if to_id not in location_ids:\n",
    "                add_error(f\"Edge 'to' location '{to_id}' is not defined among locations.\")\n",
    "                edge_valid = False\n",
    "            pair = (from_id, to_id)\n",
    "            if pair in edge_pairs:\n",
    "                add_error(f\"Duplicate edge detected from '{from_id}' to '{to_id}'.\")\n",
    "                edge_valid = False\n",
    "            else:\n",
    "                edge_pairs.add(pair)\n",
    "            if not isinstance(edge[\"base_time\"], int) or edge[\"base_time\"] <= 0:\n",
    "                add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid 'base_time'. Must be a positive integer.\")\n",
    "                edge_valid = False\n",
    "            if not isinstance(edge[\"hourly_adjust\"], dict):\n",
    "                add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid 'hourly_adjust'. Must be a dictionary.\")\n",
    "                edge_valid = False\n",
    "            else:\n",
    "                for time_range, adjustment in edge[\"hourly_adjust\"].items():\n",
    "                    if not re.fullmatch(r\"\\d{1,2}-\\d{1,2}\", time_range):\n",
    "                        add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid time range '{time_range}' in 'hourly_adjust'. Expected format 'HH-HH'.\")\n",
    "                        edge_valid = False\n",
    "                        continue\n",
    "                    start, end = map(int, time_range.split('-'))\n",
    "                    if not (0 <= start < end <= 24):\n",
    "                        add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid time range values '{time_range}'. Must satisfy 0 <= start < end <= 24.\")\n",
    "                        edge_valid = False\n",
    "                    if not isinstance(adjustment, int) or adjustment < 0:\n",
    "                        add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid adjustment value '{adjustment}' for time range '{time_range}'. Must be a non-negative integer.\")\n",
    "                        edge_valid = False\n",
    "            if not isinstance(edge[\"max_weight\"], int) or edge[\"max_weight\"] <= 0:\n",
    "                add_error(f\"Edge from '{from_id}' to '{to_id}' has invalid 'max_weight'. Must be a positive integer.\")\n",
    "                edge_valid = False\n",
    "            else:\n",
    "                incoming_weights[to_id] += edge[\"max_weight\"]\n",
    "        if edge_valid:\n",
    "            verification_results[\"output_structure\"][\"passed\"] = verification_results[\"output_structure\"][\"passed\"] and True\n",
    "        else:\n",
    "            verification_results[\"output_structure\"][\"message\"] += \" Errors found in 'edges' structure.\"\n",
    "    \n",
    "\n",
    "    storage_compliance_passed = True\n",
    "    storage_errors = []\n",
    "    loc_capacity_map = {loc[\"id\"]: loc[\"capacity\"] for loc in locations}\n",
    "    for loc_id, total_incoming in incoming_weights.items():\n",
    "        capacity = loc_capacity_map.get(loc_id, 0)\n",
    "        if total_incoming > capacity:\n",
    "            storage_compliance_passed = False\n",
    "            storage_errors.append(f\"Total incoming 'max_weight' to location '{loc_id}' is {total_incoming} kg, exceeding its storage capacity of {capacity} kg.\")\n",
    "    if storage_compliance_passed:\n",
    "        verification_results[\"storage_capacity_compliance\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"storage_capacity_compliance\"][\"message\"] = \" \".join(storage_errors)\n",
    "        add_error(\"Storage Capacity Compliance Check Failed.\")\n",
    "    \n",
    "    vehicle_capacity_passed = True\n",
    "    vehicle_errors = []\n",
    "    if not vehicle_capacities:\n",
    "        vehicle_capacity_passed = False\n",
    "        vehicle_errors.append(\"No valid vehicle capacities found.\")\n",
    "    else:\n",
    "        max_vehicle_capacity = max(vehicle_capacities)\n",
    "        for edge in edges:\n",
    "            if edge[\"max_weight\"] < max_vehicle_capacity:\n",
    "                vehicle_capacity_passed = False\n",
    "                vehicle_errors.append(f\"Edge from '{edge['from']}' to '{edge['to']}' has 'max_weight' {edge['max_weight']} kg, which is less than the maximum vehicle capacity of {max_vehicle_capacity} kg.\")\n",
    "    if vehicle_capacity_passed:\n",
    "        verification_results[\"vehicle_capacity_compliance\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"vehicle_capacity_compliance\"][\"message\"] = \" \".join(vehicle_errors)\n",
    "        add_error(\"Vehicle Capacity Compliance Check Failed.\")\n",
    "    \n",
    "    time_window_passed = True\n",
    "    time_window_errors = []\n",
    "    loc_time_map = {loc[\"id\"]: loc[\"time_window\"] for loc in locations}\n",
    "    for edge in edges:\n",
    "        from_id = edge[\"from\"]\n",
    "        to_id = edge[\"to\"]\n",
    "        base_time = edge[\"base_time\"]  \n",
    "        hourly_adjust = edge[\"hourly_adjust\"] \n",
    "        max_adjust = max(hourly_adjust.values()) if hourly_adjust else 0\n",
    "        total_travel_time = base_time + max_adjust  # in minutes\n",
    "        total_travel_hours = (total_travel_time + 59) // 60 \n",
    "        from_tw_start, from_tw_end = loc_time_map[from_id]\n",
    "        to_tw_start, to_tw_end = loc_time_map[to_id]\n",
    "        feasible = False\n",
    "        for dep_hour in range(from_tw_start, from_tw_end):\n",
    "            dep_time = dep_hour + 0.17 \n",
    "            arr_time = dep_time + (total_travel_time / 60)\n",
    "            if to_tw_start <= arr_time <= to_tw_end:\n",
    "                feasible = True\n",
    "                break\n",
    "        if not feasible:\n",
    "            time_window_passed = False\n",
    "            time_window_errors.append(f\"Edge from '{from_id}' to '{to_id}' with total travel time {total_travel_time} minutes does not fit within the time windows of '{from_id}' [{from_tw_start}-{from_tw_end}] and '{to_id}' [{to_tw_start}-{to_tw_end}].\")\n",
    "    if time_window_passed:\n",
    "        verification_results[\"time_window_compliance\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"time_window_compliance\"][\"message\"] = \" \".join(time_window_errors)\n",
    "        add_error(\"Time Window Compliance Check Failed.\")\n",
    "    \n",
    "    overall_passed = all([\n",
    "        verification_results[\"output_structure\"][\"passed\"],\n",
    "        verification_results[\"storage_capacity_compliance\"][\"passed\"],\n",
    "        verification_results[\"vehicle_capacity_compliance\"][\"passed\"],\n",
    "        verification_results[\"time_window_compliance\"][\"passed\"]\n",
    "    ])\n",
    "    verification_results[\"overall_passed\"] = overall_passed\n",
    "    \n",
    "    return overall_passed, verification_results\n",
    "\n",
    "#PASTE HERE!\n",
    "\n",
    "locations = [\n",
    "    {\"id\": \"L0\", \"capacity\": 500, \"time_window\": [6, 18]},\n",
    "    {\"id\": \"L1\", \"capacity\": 300, \"time_window\": [8, 10]},\n",
    "    {\"id\": \"L2\", \"capacity\": 450, \"time_window\": [9, 12]},\n",
    "    {\"id\": \"L3\", \"capacity\": 600, \"time_window\": [9, 11]},\n",
    "    {\"id\": \"L4\", \"capacity\": 800, \"time_window\": [7, 15]},\n",
    "    {\"id\": \"L5\", \"capacity\": 350, \"time_window\": [11, 13]},\n",
    "    {\"id\": \"L6\", \"capacity\": 700, \"time_window\": [8, 16]},\n",
    "    {\"id\": \"L7\", \"capacity\": 400, \"time_window\": [14, 17]},\n",
    "    {\"id\": \"L8\", \"capacity\": 550, \"time_window\": [12, 18]},\n",
    "    {\"id\": \"L9\", \"capacity\": 900, \"time_window\": [5, 20]},\n",
    "    {\"id\": \"L10\", \"capacity\": 200, \"time_window\": [9, 11]},\n",
    "    {\"id\": \"L11\", \"capacity\": 750, \"time_window\": [10, 15]},\n",
    "    {\"id\": \"L12\", \"capacity\": 1000, \"time_window\": [6, 20]},\n",
    "    {\"id\": \"L13\", \"capacity\": 480, \"time_window\": [7, 12]},\n",
    "    {\"id\": \"L14\", \"capacity\": 650, \"time_window\": [13, 16]}\n",
    "]\n",
    "\n",
    "vehicles = [\n",
    "    {\"id\": \"V1\", \"capacity\": 100, \"speed\": 60},\n",
    "    {\"id\": \"V2\", \"capacity\": 150, \"speed\": 55},\n",
    "    {\"id\": \"V3\", \"capacity\": 200, \"speed\": 70},\n",
    "    {\"id\": \"V4\", \"capacity\": 250, \"speed\": 65},\n",
    "    {\"id\": \"V5\", \"capacity\": 300, \"speed\": 75},\n",
    "    {\"id\": \"V6\", \"capacity\": 180, \"speed\": 80},\n",
    "    {\"id\": \"V7\", \"capacity\": 220, \"speed\": 50}\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    {\"from\": \"L0\", \"to\": \"L1\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 15}, \"max_weight\": 200},\n",
    "    {\"from\": \"L0\", \"to\": \"L2\", \"base_time\": 45, \"hourly_adjust\": {\"12-14\": 10}, \"max_weight\": 300},\n",
    "    {\"from\": \"L0\", \"to\": \"L3\", \"base_time\": 20, \"hourly_adjust\": {\"9-11\": 5}, \"max_weight\": 250},\n",
    "    {\"from\": \"L1\", \"to\": \"L4\", \"base_time\": 25, \"hourly_adjust\": {\"15-17\": 20}, \"max_weight\": 180},\n",
    "    {\"from\": \"L1\", \"to\": \"L5\", \"base_time\": 35, \"hourly_adjust\": {\"7-9\": 10}, \"max_weight\": 150},\n",
    "    {\"from\": \"L2\", \"to\": \"L6\", \"base_time\": 40, \"hourly_adjust\": {\"10-12\": 5}, \"max_weight\": 220},\n",
    "    {\"from\": \"L2\", \"to\": \"L7\", \"base_time\": 50, \"hourly_adjust\": {}, \"max_weight\": 300},\n",
    "    {\"from\": \"L3\", \"to\": \"L8\", \"base_time\": 30, \"hourly_adjust\": {\"14-16\": 15}, \"max_weight\": 200},\n",
    "    {\"from\": \"L3\", \"to\": \"L9\", \"base_time\": 60, \"hourly_adjust\": {\"17-19\": 30}, \"max_weight\": 150},\n",
    "    {\"from\": \"L4\", \"to\": \"L10\", \"base_time\": 25, \"hourly_adjust\": {\"8-10\": 10}, \"max_weight\": 180},\n",
    "    {\"from\": \"L4\", \"to\": \"L11\", \"base_time\": 35, \"hourly_adjust\": {}, \"max_weight\": 250},\n",
    "    {\"from\": \"L5\", \"to\": \"L12\", \"base_time\": 20, \"hourly_adjust\": {\"12-14\": 15}, \"max_weight\": 300},\n",
    "    {\"from\": \"L5\", \"to\": \"L13\", \"base_time\": 40, \"hourly_adjust\": {\"10-12\": 5}, \"max_weight\": 200},\n",
    "    {\"from\": \"L6\", \"to\": \"L14\", \"base_time\": 30, \"hourly_adjust\": {\"9-11\": 10}, \"max_weight\": 180},\n",
    "    {\"from\": \"L1\", \"to\": \"L0\", \"base_time\": 30, \"hourly_adjust\": {\"8-10\": 15}, \"max_weight\": 200},\n",
    "    {\"from\": \"L2\", \"to\": \"L0\", \"base_time\": 45, \"hourly_adjust\": {\"12-14\": 10}, \"max_weight\": 300}\n",
    "]\n",
    "\n",
    "# Execute verification\n",
    "verification_output = verify_time_dependent_delivery_network(locations, vehicles, edges)\n",
    "print(\"Verification Output:\", verification_output[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68dcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama3370B\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini15Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\"\n",
    "]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"timeDependentDeliveryNetwork\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"locations\": locations,\n",
    "    \"vehicles\": vehicles,\n",
    "    \"edges\": edges,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5d05c9",
   "metadata": {},
   "source": [
    "\n",
    "# Directed Social Network with Influence Relationships\n",
    "\n",
    "Design a directed social network based on the specifications below.\n",
    "\n",
    "## Problem Description:\n",
    "Create a social network graph representing influence relationships among users. Each user has specific attributes, and influence connections must adhere to defined constraints to maintain the integrity and intended structure of the network.\n",
    "\n",
    "## Constraints:\n",
    "1. **Users:**\n",
    "   - Total of 20 users labeled from U0 to U19.\n",
    "   - Each user has a \"trust_score\" ranging from 0 to 100.\n",
    "   - Each user belongs to a \"category\" based on their trust score:\n",
    "     - \"celebrity\" (trust_score ≥ 80)\n",
    "     - \"expert\" (70 ≤ trust_score < 80)\n",
    "     - \"regular\" (trust_score < 50)\n",
    "\n",
    "2. **Edges (Influence Relationships):**\n",
    "   - Directed edges where Ux → Uy indicates that Ux influences Uy.\n",
    "   - **No self-loops:** A user cannot influence themselves.\n",
    "   - **Category Constraints:**\n",
    "     - **Celebrities:** Must have at least 5 outgoing edges.\n",
    "     - **Regular Users:** Cannot influence experts.\n",
    "   - **Graph Structure:**\n",
    "     - The graph must be acyclic (no cycles in influence relationships).\n",
    "\n",
    "### Required Output Format:\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "\n",
    "users = [\n",
    "    {\"id\": \"U0\", \"trust_score\": int, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U1\", \"trust_score\": int, \"category\": \"regular\"},\n",
    "    {\"id\": \"U2\", \"trust_score\": int, \"category\": \"expert\"},\n",
    "    # ... all users (U3-U19)\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    {\"from\": \"U0\", \"to\": \"U1\"},\n",
    "    {\"from: \"U0\", \"to\": \"U2\"},\n",
    "    {\"from\": \"U2\", \"to\": \"U3\"},\n",
    "    # ... more edges\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fbd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict  \n",
    "\n",
    "def verify_social_network(users, edges):\n",
    "\n",
    "    validation_results = {\n",
    "        \"valid_no_self_loops\": True,\n",
    "        \"valid_celebrity_outgoing\": True,\n",
    "        \"valid_regular_to_expert\": True,\n",
    "        \"valid_acyclic\": True,\n",
    "        \"valid_user_attributes\": True,\n",
    "        \"valid_edge_structure\": True,\n",
    "        \"valid_total_users\": True,\n",
    "        \"valid_categories\": True,\n",
    "        \"valid_trust_scores\": True,\n",
    "        \"errors\": []\n",
    "    }\n",
    "\n",
    "    if not isinstance(users, list):\n",
    "        validation_results[\"valid_total_users\"] = False\n",
    "        validation_results[\"errors\"].append(\"'users' should be a list.\")\n",
    "    elif len(users) != 20:\n",
    "        validation_results[\"valid_total_users\"] = False\n",
    "        validation_results[\"errors\"].append(f\"Number of users is {len(users)}; expected 20.\")\n",
    "    \n",
    "    expected_user_ids = {f\"U{i}\" for i in range(20)}\n",
    "    actual_user_ids = set()\n",
    "    user_map = {}\n",
    "    for user in users:\n",
    "        if not isinstance(user, dict):\n",
    "            validation_results[\"valid_user_attributes\"] = False\n",
    "            validation_results[\"errors\"].append(\"Each user should be a dictionary.\")\n",
    "            continue\n",
    "        required_keys = {\"id\", \"trust_score\", \"category\"}\n",
    "        if not required_keys.issubset(user.keys()):\n",
    "            missing = required_keys - user.keys()\n",
    "            validation_results[\"valid_user_attributes\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User {user.get('id', 'Unknown')} is missing keys: {missing}.\")\n",
    "            continue\n",
    "        user_id = user[\"id\"]\n",
    "        if user_id not in expected_user_ids:\n",
    "            validation_results[\"valid_user_attributes\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User ID '{user_id}' is invalid. Expected IDs from U0 to U19.\")\n",
    "        actual_user_ids.add(user_id)\n",
    "        user_map[user_id] = user\n",
    "        trust_score = user[\"trust_score\"]\n",
    "        if not isinstance(trust_score, int) or not (0 <= trust_score <= 100):\n",
    "            validation_results[\"valid_trust_scores\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User '{user_id}' has invalid 'trust_score': {trust_score}. Must be an integer between 0 and 100.\")\n",
    "        category = user[\"category\"]\n",
    "        if trust_score >= 80 and category != \"celebrity\":\n",
    "            validation_results[\"valid_categories\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User '{user_id}' has 'trust_score' {trust_score} but category '{category}'. Should be 'celebrity'.\")\n",
    "        elif 70 <= trust_score < 80 and category != \"expert\":\n",
    "            validation_results[\"valid_categories\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User '{user_id}' has 'trust_score' {trust_score} but category '{category}'. Should be 'expert'.\")\n",
    "        elif trust_score < 50 and category != \"regular\":\n",
    "            validation_results[\"valid_categories\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User '{user_id}' has 'trust_score' {trust_score} but category '{category}'. Should be 'regular'.\")\n",
    "        elif 50 <= trust_score < 70 and category not in [\"expert\", \"regular\"]:\n",
    "            validation_results[\"valid_categories\"] = False\n",
    "            validation_results[\"errors\"].append(f\"User '{user_id}' has 'trust_score' {trust_score} but category '{category}'. Should be 'expert' or 'regular'.\")\n",
    "\n",
    "    missing_users = expected_user_ids - actual_user_ids\n",
    "    if missing_users:\n",
    "        validation_results[\"valid_total_users\"] = False\n",
    "        validation_results[\"errors\"].append(f\"Missing user IDs: {missing_users}.\")\n",
    "\n",
    "    if not isinstance(edges, list):\n",
    "        validation_results[\"valid_edge_structure\"] = False\n",
    "        validation_results[\"errors\"].append(\"'edges' should be a list.\")\n",
    "    else:\n",
    "        adj = defaultdict(list)\n",
    "        for edge in edges:\n",
    "            if not isinstance(edge, dict):\n",
    "                validation_results[\"valid_edge_structure\"] = False\n",
    "                validation_results[\"errors\"].append(\"Each edge should be a dictionary.\")\n",
    "                continue\n",
    "            required_edge_keys = {\"from\", \"to\"}\n",
    "            if not required_edge_keys.issubset(edge.keys()):\n",
    "                missing = required_edge_keys - edge.keys()\n",
    "                validation_results[\"valid_edge_structure\"] = False\n",
    "                validation_results[\"errors\"].append(f\"Edge is missing keys: {missing}.\")\n",
    "                continue\n",
    "            from_id = edge[\"from\"]\n",
    "            to_id = edge[\"to\"]\n",
    "            if from_id not in expected_user_ids:\n",
    "                validation_results[\"valid_edge_structure\"] = False\n",
    "                validation_results[\"errors\"].append(f\"Edge 'from' user '{from_id}' is not a valid user ID.\")\n",
    "            if to_id not in expected_user_ids:\n",
    "                validation_results[\"valid_edge_structure\"] = False\n",
    "                validation_results[\"errors\"].append(f\"Edge 'to' user '{to_id}' is not a valid user ID.\")\n",
    "            adj[from_id].append(to_id)\n",
    "\n",
    "    for edge in edges:\n",
    "        if edge[\"from\"] == edge[\"to\"]:\n",
    "            validation_results[\"valid_no_self_loops\"] = False\n",
    "            validation_results[\"errors\"].append(f\"Self-loop detected: {edge['from']} → {edge['to']}.\")\n",
    "\n",
    "    for user in users:\n",
    "        if user[\"category\"] == \"celebrity\":\n",
    "            user_id = user[\"id\"]\n",
    "            outgoing = len(adj[user_id])\n",
    "            if outgoing < 5:\n",
    "                validation_results[\"valid_celebrity_outgoing\"] = False\n",
    "                validation_results[\"errors\"].append(f\"Celebrity '{user_id}' has {outgoing} outgoing edges; expected at least 5.\")\n",
    "\n",
    "    for edge in edges:\n",
    "        from_user = user_map.get(edge[\"from\"])\n",
    "        to_user = user_map.get(edge[\"to\"])\n",
    "        if from_user and to_user:\n",
    "            if from_user[\"category\"] == \"regular\" and to_user[\"trust_score\"] >= 70:\n",
    "                validation_results[\"valid_regular_to_expert\"] = False\n",
    "                validation_results[\"errors\"].append(f\"Regular user '{from_user['id']}' is influencing expert '{to_user['id']}'.\")\n",
    "\n",
    "    visited = set()\n",
    "    rec_stack = set()\n",
    "    def dfs(u):\n",
    "        visited.add(u)\n",
    "        rec_stack.add(u)\n",
    "        for v in adj[u]:\n",
    "            if v not in visited:\n",
    "                if dfs(v):\n",
    "                    return True\n",
    "            elif v in rec_stack:\n",
    "                return True\n",
    "        rec_stack.remove(u)\n",
    "        return False\n",
    "\n",
    "    has_cycle = False\n",
    "    for user_id in expected_user_ids:\n",
    "        if user_id not in visited:\n",
    "            if dfs(user_id):\n",
    "                has_cycle = True\n",
    "                break\n",
    "    if has_cycle:\n",
    "        validation_results[\"valid_acyclic\"] = False\n",
    "        validation_results[\"errors\"].append(\"Cycle detected in the network; the graph must be acyclic.\")\n",
    "    return(validation_results['valid_no_self_loops'] and\n",
    "    validation_results['valid_celebrity_outgoing'] and \n",
    "    validation_results['valid_regular_to_expert'] and\n",
    "     validation_results['valid_acyclic'] and\n",
    "     validation_results['valid_user_attributes'] and\n",
    "     validation_results['valid_edge_structure'] and\n",
    "     validation_results['valid_total_users'] and\n",
    "      validation_results['valid_categories'] and\n",
    "      validation_results['valid_trust_scores']\n",
    "      , validation_results)\n",
    "\n",
    "\n",
    "#PASTE HERE!\n",
    "users = [\n",
    "    {\"id\": \"U0\", \"trust_score\": 85, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U1\", \"trust_score\": 40, \"category\": \"regular\"},\n",
    "    {\"id\": \"U2\", \"trust_score\": 75, \"category\": \"expert\"},\n",
    "    {\"id\": \"U3\", \"trust_score\": 90, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U4\", \"trust_score\": 35, \"category\": \"regular\"},\n",
    "    {\"id\": \"U5\", \"trust_score\": 73, \"category\": \"expert\"},\n",
    "    {\"id\": \"U6\", \"trust_score\": 20, \"category\": \"regular\"},\n",
    "    {\"id\": \"U7\", \"trust_score\": 82, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U8\", \"trust_score\": 45, \"category\": \"regular\"},\n",
    "    {\"id\": \"U9\", \"trust_score\": 77, \"category\": \"expert\"},\n",
    "    {\"id\": \"U10\", \"trust_score\": 30, \"category\": \"regular\"},\n",
    "    {\"id\": \"U11\", \"trust_score\": 88, \"category\": \"celebrity\"},\n",
    "    {\"id\": \"U12\", \"trust_score\": 78, \"category\": \"expert\"},\n",
    "    {\"id\": \"U13\", \"trust_score\": 25, \"category\": \"regular\"},\n",
    "    {\"id\": \"U14\", \"trust_score\": 15, \"category\": \"regular\"},\n",
    "    {\"id\": \"U15\", \"trust_score\": 70, \"category\": \"expert\"},\n",
    "    {\"id\": \"U16\", \"trust_score\": 10, \"category\": \"regular\"},\n",
    "    {\"id\": \"U17\", \"trust_score\": 5, \"category\": \"regular\"},\n",
    "    {\"id\": \"U18\", \"trust_score\": 0, \"category\": \"regular\"},\n",
    "    {\"id\": \"U19\", \"trust_score\": 49, \"category\": \"regular\"}\n",
    "]\n",
    "\n",
    "edges = [\n",
    "    # Outgoing edges from celebrity U0 (index 0) – at least 5 edges\n",
    "    {\"from\": \"U0\", \"to\": \"U1\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U2\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U3\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U4\"},\n",
    "    {\"from\": \"U0\", \"to\": \"U5\"},\n",
    "    \n",
    "    # Additional edges from expert U2 (index 2)\n",
    "    {\"from\": \"U2\", \"to\": \"U3\"},\n",
    "    {\"from\": \"U2\", \"to\": \"U4\"},\n",
    "    \n",
    "    # Outgoing edges from celebrity U3 (index 3) – at least 5 edges\n",
    "    {\"from\": \"U3\", \"to\": \"U4\"},\n",
    "    {\"from\": \"U3\", \"to\": \"U5\"},\n",
    "    {\"from\": \"U3\", \"to\": \"U6\"},\n",
    "    {\"from\": \"U3\", \"to\": \"U7\"},\n",
    "    {\"from\": \"U3\", \"to\": \"U8\"},\n",
    "    \n",
    "    # Additional edges from expert U5 (index 5)\n",
    "    {\"from\": \"U5\", \"to\": \"U6\"},\n",
    "    {\"from\": \"U5\", \"to\": \"U7\"},\n",
    "    \n",
    "    # Outgoing edges from celebrity U7 (index 7) – at least 5 edges\n",
    "    {\"from\": \"U7\", \"to\": \"U8\"},\n",
    "    {\"from\": \"U7\", \"to\": \"U9\"},\n",
    "    {\"from\": \"U7\", \"to\": \"U10\"},\n",
    "    {\"from\": \"U7\", \"to\": \"U11\"},\n",
    "    {\"from\": \"U7\", \"to\": \"U12\"},\n",
    "    \n",
    "    # An edge from regular U8 (index 8) that respects category constraints\n",
    "    {\"from\": \"U8\", \"to\": \"U10\"},\n",
    "    \n",
    "    # Additional edges from expert U9 (index 9)\n",
    "    {\"from\": \"U9\", \"to\": \"U10\"},\n",
    "    {\"from\": \"U9\", \"to\": \"U13\"},\n",
    "    \n",
    "    # Outgoing edges from celebrity U11 (index 11) – at least 5 edges\n",
    "    {\"from\": \"U11\", \"to\": \"U12\"},\n",
    "    {\"from\": \"U11\", \"to\": \"U13\"},\n",
    "    {\"from\": \"U11\", \"to\": \"U14\"},\n",
    "    {\"from\": \"U11\", \"to\": \"U15\"},\n",
    "    {\"from\": \"U11\", \"to\": \"U16\"},\n",
    "    \n",
    "    # Additional edge from expert U12 (index 12)\n",
    "    {\"from\": \"U12\", \"to\": \"U13\"},\n",
    "    \n",
    "    # Additional edge from expert U15 (index 15)\n",
    "    {\"from\": \"U15\", \"to\": \"U16\"},\n",
    "    \n",
    "    # Edges among regular users to extend acyclicity\n",
    "    {\"from\": \"U16\", \"to\": \"U17\"},\n",
    "    {\"from\": \"U17\", \"to\": \"U18\"},\n",
    "    {\"from\": \"U18\", \"to\": \"U19\"}\n",
    "]\n",
    "\n",
    "\n",
    "verification_output = verify_social_network(users,edges)\n",
    "print(\"Verification Output:\", verification_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65364642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama3370B\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini15Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\"\n",
    "]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"directedSocialNetwork\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"users\":users,\n",
    "    \"edges\":edges,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a40de4",
   "metadata": {},
   "source": [
    "# Quantum Circuit Design  \n",
    "\n",
    "## Problem Description:\n",
    "Design a quantum circuit consisting of multiple qubits and quantum gates. The circuit must adhere to specific constraints to ensure proper gate operations, circuit efficiency, and overall functionality. The design should incorporate structural elements like depth and a Directed Acyclic Graph (DAG) while simplifying some of the gate-related rules to enhance accessibility.\n",
    "\n",
    "## Constraints:\n",
    "1. **Qubits:**\n",
    "   - **Total Qubits:** 10, labeled from `Q0` to `Q9`.\n",
    "   - **Initialization:** All qubits must start in the |0⟩ state.\n",
    "\n",
    "2. **Gates:**\n",
    "   - **Types of Gates to Include:**\n",
    "     - **Single-Qubit Gates:** Hadamard (H), Pauli-X (X), Pauli-Z (Z)\n",
    "     - **Multi-Qubit Gates:** Controlled NOT (CNOT), SWAP\n",
    "     - **Measurement:** Measure (Measure)\n",
    "   - **Gate Operations:**\n",
    "     - Each gate operates on specific qubits at designated times.\n",
    "     - **CNOT Gates:** Must operate on qubits that are not adjacent (e.g., Q0 and Q2 are valid; Q0 and Q1 are invalid).\n",
    "     - **SWAP Gates:** Must operate between pairs of qubits that have identical gate sequences up to that point.\n",
    "     - **Measurements:** Each qubit can be measured only once and must be the last operation on that qubit.\n",
    "   - **Gate Restrictions:**\n",
    "     - **Gate Frequency:** No single-qubit gate can be applied more than twice consecutively on the same qubit.\n",
    "\n",
    "3. **Circuit Structure:**\n",
    "   - The circuit must be a Directed Acyclic Graph (DAG); no repeated times for the same qubit.\n",
    "   - **Layered Operations:** Gates at the same time step must operate on disjoint sets of qubits (i.e., no two gates at the same time can act on the same qubit).\n",
    "   - **Depth Constraint:** The total number of time steps (layers) must not exceed 30.\n",
    "\n",
    "4. **Operational Constraints:**\n",
    "   - **Circuit Reversibility:** Measurements must be the final operations on their respective qubits to maintain circuit reversibility.\n",
    "   - **Gate Optimization:** The circuit should minimize the total number of gates while satisfying all other constraints.\n",
    "   - **Final State:** After all operations, all qubits must either be measured or returned to the |0⟩ state.\n",
    "\n",
    "## Required Output Format:\n",
    "\n",
    "Provide the circuit details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "circuit = [\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q0\"], \"time\": 1},\n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q0\", \"Q2\"], \"time\": 2},\n",
    "    {\"gate\": \"X\", \"qubits\": [\"Q2\"], \"time\": 3},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q0\"], \"time\": 4},\n",
    "    # ... more gates\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8270de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "def verify_quantum_circuit(circuit):\n",
    "    \"\"\"\n",
    "    Verifies the Quantum Circuit Design against the specified constraints.\n",
    "\n",
    "    Args:\n",
    "        circuit (list): List of gate operation dictionaries.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (bool indicating overall validity, detailed validation results dictionary)\n",
    "    \"\"\"\n",
    "    # Initialize the results dictionary\n",
    "    verification_results = {\n",
    "        \"valid_output_structure\": True,\n",
    "        \"valid_gate_types\": True,\n",
    "        \"valid_qubits\": True,\n",
    "        \"valid_dag\": True,\n",
    "        \"valid_gate_precedences\": True,\n",
    "        \"valid_cnot_adjacency\": True,\n",
    "        \"valid_swap_constraints\": True,\n",
    "        \"valid_measurements\": True,\n",
    "        \"valid_gate_restrictions\": True,\n",
    "        \"layered_operations\": True,\n",
    "        \"depth_constraint\": True,\n",
    "        \"gate_optimization\": True,\n",
    "        \"final_state_compliance\": True,\n",
    "        \"errors\": []\n",
    "    }\n",
    "\n",
    "    valid_qubits = {f\"Q{i}\" for i in range(10)}\n",
    "\n",
    "    # Define allowed gates\n",
    "    single_qubit_gates = {\"H\", \"X\", \"Z\"}\n",
    "    multi_qubit_gates = {\"CNOT\", \"SWAP\"}\n",
    "    measurement_gate = \"Measure\"\n",
    "    allowed_gates = single_qubit_gates.union(multi_qubit_gates).union({measurement_gate})\n",
    "\n",
    "    # Initialize data structures\n",
    "    qubit_operations = defaultdict(list)  \n",
    "    measurement_counts = defaultdict(int) \n",
    "    gate_sequences = defaultdict(list)\n",
    "    time_layers = defaultdict(set)\n",
    "    max_time_step = 0\n",
    "\n",
    "\n",
    "    def add_error(message):\n",
    "        verification_results[\"errors\"].append(message)\n",
    "\n",
    "    if not isinstance(circuit, list):\n",
    "        verification_results[\"valid_output_structure\"] = False\n",
    "        add_error(\"'circuit' should be a list.\")\n",
    "        return False, verification_results \n",
    "\n",
    "    for idx, gate_op in enumerate(circuit):\n",
    "        if not isinstance(gate_op, dict):\n",
    "            verification_results[\"valid_output_structure\"] = False\n",
    "            add_error(f\"Gate operation at index {idx} is not a dictionary.\")\n",
    "            continue\n",
    "\n",
    "        required_keys = {\"gate\", \"qubits\", \"time\"}\n",
    "        if not required_keys.issubset(gate_op.keys()):\n",
    "            missing = required_keys - gate_op.keys()\n",
    "            verification_results[\"valid_output_structure\"] = False\n",
    "            add_error(f\"Gate operation at index {idx} is missing keys: {missing}.\")\n",
    "            continue\n",
    "\n",
    "        gate = gate_op[\"gate\"]\n",
    "        qubits = gate_op[\"qubits\"]\n",
    "        time = gate_op[\"time\"]\n",
    "\n",
    "\n",
    "        if gate not in allowed_gates:\n",
    "            verification_results[\"valid_gate_types\"] = False\n",
    "            add_error(f\"Invalid gate type '{gate}' at index {idx}. Allowed gates: {allowed_gates}.\")\n",
    "\n",
    "\n",
    "        if not isinstance(qubits, list) or not all(isinstance(q, str) for q in qubits):\n",
    "            verification_results[\"valid_output_structure\"] = False\n",
    "            add_error(f\"'qubits' for gate at index {idx} must be a list of strings.\")\n",
    "            continue\n",
    "\n",
    "        for q in qubits:\n",
    "            if q not in valid_qubits:\n",
    "                verification_results[\"valid_qubits\"] = False\n",
    "                add_error(f\"Invalid qubit ID '{q}' in gate at index {idx}. Expected IDs from Q0 to Q9.\")\n",
    "\n",
    "\n",
    "        if not isinstance(time, int) or time < 0:\n",
    "            verification_results[\"valid_output_structure\"] = False\n",
    "            add_error(f\"Invalid 'time' value '{time}' in gate at index {idx}. Must be a non-negative integer.\")\n",
    "            continue\n",
    "\n",
    "        if time > max_time_step:\n",
    "            max_time_step = time\n",
    "\n",
    "\n",
    "        for q in qubits:\n",
    "            qubit_operations[q].append((time, gate))\n",
    "            gate_sequences[q].append(gate)\n",
    "\n",
    "\n",
    "        for q in qubits:\n",
    "            if q in time_layers[time]:\n",
    "                verification_results[\"layered_operations\"] = False\n",
    "                add_error(f\"Multiple gates operate on qubit '{q}' at time {time}. Gates must operate on disjoint qubit sets per time step.\")\n",
    "            time_layers[time].add(q)\n",
    "\n",
    "        if gate == \"CNOT\":\n",
    "            if len(qubits) != 2:\n",
    "                verification_results[\"valid_output_structure\"] = False\n",
    "                add_error(f\"CNOT gate at index {idx} must operate on exactly two qubits.\")\n",
    "        elif gate == \"SWAP\":\n",
    "            if len(qubits) != 2:\n",
    "                verification_results[\"valid_output_structure\"] = False\n",
    "                add_error(f\"SWAP gate at index {idx} must operate on exactly two qubits.\")\n",
    "        elif gate in single_qubit_gates and gate != \"Measure\":\n",
    "            if len(qubits) != 1:\n",
    "                verification_results[\"valid_output_structure\"] = False\n",
    "                add_error(f\"{gate} gate at index {idx} must operate on exactly one qubit.\")\n",
    "        elif gate == \"Measure\":\n",
    "            if len(qubits) != 1:\n",
    "                verification_results[\"valid_output_structure\"] = False\n",
    "                add_error(f\"Measure gate at index {idx} must operate on exactly one qubit.\")\n",
    "\n",
    "\n",
    "    if not verification_results[\"valid_output_structure\"]:\n",
    "        return False, verification_results\n",
    "\n",
    "    for q, ops in qubit_operations.items():\n",
    "        times = [t for (t, _) in ops]\n",
    "        if len(times) != len(set(times)):\n",
    "            verification_results[\"valid_dag\"] = False\n",
    "            add_error(f\"Qubit '{q}' has overlapping operations at the same time.\")\n",
    "\n",
    "    for q, gates in gate_sequences.items():\n",
    "        previous_gate = None\n",
    "        consecutive_gate_count = 0\n",
    "        for idx, gate in enumerate(gates):\n",
    "            if gate in single_qubit_gates:\n",
    "                if previous_gate == gate:\n",
    "                    consecutive_gate_count += 1\n",
    "                    if consecutive_gate_count > 2:\n",
    "                        verification_results[\"valid_gate_restrictions\"] = False\n",
    "                        add_error(f\"Qubit '{q}' has more than two consecutive '{gate}' gates.\")\n",
    "                else:\n",
    "                    consecutive_gate_count = 1\n",
    "            else:\n",
    "                consecutive_gate_count = 0\n",
    "            previous_gate = gate\n",
    "\n",
    "    for idx, gate_op in enumerate(circuit):\n",
    "        gate = gate_op[\"gate\"]\n",
    "        qubits = gate_op[\"qubits\"]\n",
    "        if gate == \"CNOT\":\n",
    "            q1, q2 = qubits\n",
    "            q1_num = int(q1[1:])\n",
    "            q2_num = int(q2[1:])\n",
    "            if abs(q1_num - q2_num) < 2:\n",
    "                verification_results[\"valid_cnot_adjacency\"] = False\n",
    "                add_error(f\"CNOT gate at index {idx} operates on adjacent qubits '{q1}' and '{q2}'. Must have at least one qubit gap.\")\n",
    "\n",
    "    for idx, gate_op in enumerate(circuit):\n",
    "        gate = gate_op[\"gate\"]\n",
    "        qubits = gate_op[\"qubits\"]\n",
    "        if gate == \"SWAP\":\n",
    "            q1, q2 = qubits\n",
    "            seq_q1 = gate_sequences[q1][:gate_sequences[q1].index(gate)+1]\n",
    "            seq_q2 = gate_sequences[q2][:gate_sequences[q2].index(gate)+1]\n",
    "            if seq_q1[:-1] != seq_q2[:-1]:  # Exclude the current SWAP gate\n",
    "                verification_results[\"valid_swap_constraints\"] = False\n",
    "                add_error(f\"SWAP gate at index {idx} operates on qubits '{q1}' and '{q2}' with differing gate sequences up to this point.\")\n",
    "\n",
    "    for gate_op in circuit:\n",
    "        gate = gate_op[\"gate\"]\n",
    "        qubits = gate_op[\"qubits\"]\n",
    "        if gate == \"Measure\":\n",
    "            q = qubits[0]\n",
    "            measurement_counts[q] += 1\n",
    "\n",
    "    for q, count in measurement_counts.items():\n",
    "        if count > 1:\n",
    "            verification_results[\"valid_measurements\"] = False\n",
    "            add_error(f\"Qubit '{q}' has been measured {count} times; only one measurement allowed.\")\n",
    "\n",
    "    for time, qubits_in_time in time_layers.items():\n",
    "        qubits_set = set(qubits_in_time)\n",
    "        if len(qubits_set) != len(qubits_in_time):\n",
    "            verification_results[\"layered_operations\"] = False\n",
    "            add_error(f\"Multiple gates operate on the same qubit(s) at time {time}.\")\n",
    "\n",
    "    if max_time_step > 30:\n",
    "        verification_results[\"depth_constraint\"] = False\n",
    "        add_error(f\"Circuit depth is {max_time_step} time steps; exceeds the maximum allowed depth of 30.\")\n",
    "\n",
    "    for q, gates in gate_sequences.items():\n",
    "        for i in range(1, len(gates)):\n",
    "            if gates[i] == gates[i-1] and gates[i] in single_qubit_gates:\n",
    "                verification_results[\"gate_optimization\"] = False\n",
    "                add_error(f\"Redundant consecutive '{gates[i]}' gates on qubit '{q}' at positions {i-1} and {i}.\")\n",
    "\n",
    "    for q, gates in gate_sequences.items():\n",
    "        if gates:\n",
    "            last_gate = gates[-1]\n",
    "            if last_gate != \"Measure\" and last_gate != \"X\" and last_gate != \"Z\" and last_gate != \"H\":\n",
    "                verification_results[\"final_state_compliance\"] = False\n",
    "                add_error(f\"Qubit '{q}' does not end with a Measurement or a gate to reset to |0⟩.\")\n",
    "        else:\n",
    "            # If no gates were applied, qubit remains in |0⟩\n",
    "            pass\n",
    "\n",
    "    # Final Validation\n",
    "    overall_passed = all([\n",
    "        verification_results[\"valid_output_structure\"],\n",
    "        verification_results[\"valid_gate_types\"],\n",
    "        verification_results[\"valid_qubits\"],\n",
    "        verification_results[\"valid_dag\"],\n",
    "        verification_results[\"valid_gate_precedences\"],\n",
    "        verification_results[\"valid_cnot_adjacency\"],\n",
    "        verification_results[\"valid_swap_constraints\"],\n",
    "        verification_results[\"valid_measurements\"],\n",
    "        verification_results[\"valid_gate_restrictions\"],\n",
    "        verification_results[\"layered_operations\"],\n",
    "        verification_results[\"depth_constraint\"],\n",
    "        verification_results[\"gate_optimization\"],\n",
    "        verification_results[\"final_state_compliance\"]\n",
    "    ])\n",
    "    verification_results[\"overall_passed\"] = overall_passed\n",
    "\n",
    "    return (verification_results[\"overall_passed\"], verification_results)\n",
    "\n",
    "circuit = [\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q0\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q2\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q4\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q6\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q8\"], \"time\": 1},\n",
    "    {\"gate\": \"H\", \"qubits\": [\"Q5\"], \"time\": 1},\n",
    "    \n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q0\", \"Q2\"], \"time\": 2},\n",
    "    {\"gate\": \"CNOT\", \"qubits\": [\"Q6\", \"Q8\"], \"time\": 2},\n",
    "    \n",
    "    {\"gate\": \"X\", \"qubits\": [\"Q2\"], \"time\": 3},\n",
    "    {\"gate\": \"Z\", \"qubits\": [\"Q8\"], \"time\": 3},\n",
    "    \n",
    "    {\"gate\": \"SWAP\", \"qubits\": [\"Q4\", \"Q5\"], \"time\": 4},\n",
    "    \n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q0\"], \"time\": 5},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q2\"], \"time\": 5},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q4\"], \"time\": 5},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q5\"], \"time\": 5},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q6\"], \"time\": 5},\n",
    "    {\"gate\": \"Measure\", \"qubits\": [\"Q8\"], \"time\": 5},\n",
    "]\n",
    "\n",
    "\n",
    "# Execute verification\n",
    "verification_output = verify_quantum_circuit(circuit)\n",
    "print(\"Verification Output:\", verification_output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d427139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama3370B\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini15Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\"\n",
    "]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"quantum\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\" Asks the user for model, prompt type, run number, and problem type \"\"\"\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"circuit\": circuit,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74198f1f",
   "metadata": {},
   "source": [
    "# Gene-Disease Association Network\n",
    "\n",
    "Design a gene-disease association network based on the specifications below.\n",
    "\n",
    "## Problem Description:\n",
    "Create a bipartite network that models the associations between genes and diseases. This network will represent which genes are associated with which diseases, capturing the strength of each association. The network should adhere to defined constraints to ensure biological relevance and structural integrity.\n",
    "\n",
    "## Constraints:\n",
    "1. **Nodes:**\n",
    "   - **Genes:**\n",
    "     - Total of 20 genes labeled from G0 to G19.\n",
    "     - Each gene has a \"name\" and a \"function\".\n",
    "   - **Diseases:**\n",
    "     - Total of 20 diseases labeled from D0 to D19.\n",
    "     - Each disease has a \"name\" and a \"severity_level\" (e.g., \"Low\", \"Medium\", \"High\").\n",
    "   \n",
    "2. **Edges (Associations):**\n",
    "   - Represents the association between a gene and a disease.\n",
    "   - **Bipartite Constraint:** Associations can only exist between genes and diseases, not within the same set.\n",
    "   - **Association Strength:** Each association has a \"strength\" value ranging from 0.0 to 1.0, indicating the confidence of the association.\n",
    "   \n",
    "3. **Degree Constraints:**\n",
    "   - **Genes:**\n",
    "     - Each gene must be associated with at least 2 and at most 5 diseases.\n",
    "   - **Diseases:**\n",
    "     - Each disease must be associated with at least 3 and at most 10 genes.\n",
    "   \n",
    "4. **Structural Constraints:**\n",
    "   - The network must be bipartite; no edges should connect nodes within the same set (i.e., no gene-gene or disease-disease associations).\n",
    "   - There should be no duplicate edges (i.e., each gene-disease pair is unique).\n",
    "\n",
    "## Required Output Format:\n",
    "\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "genes = [\n",
    "    {\"id\": \"G0\", \"name\": \"BRCA1\", \"function\": \"DNA repair\"},\n",
    "    {\"id\": \"G1\", \"name\": \"TP53\", \"function\": \"Tumor suppression\"},\n",
    "    # ... all genes (G2-G19)\n",
    "]\n",
    "\n",
    "diseases = [\n",
    "    {\"id\": \"D0\", \"name\": \"Breast Cancer\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D1\", \"name\": \"Lung Cancer\", \"severity_level\": \"High\"},\n",
    "    # ... all diseases (D2-D19)\n",
    "]\n",
    "\n",
    "associations = [\n",
    "    {\"from\": \"G0\", \"to\": \"D0\", \"strength\": 0.85},\n",
    "    {\"from\": \"G0\", \"to\": \"D2\", \"strength\": 0.60},\n",
    "    {\"from\": \"G1\", \"to\": \"D0\", \"strength\": 0.90},\n",
    "    # ... more associations\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e348cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def verify_gene_disease_association_network(genes, diseases, associations):\n",
    "    verification_results = {\n",
    "        \"defined_counts\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"valid_associations\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"degree_constraints\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"duplicate_associations\": {\"passed\": False, \"message\": \"\"},\n",
    "    }\n",
    "\n",
    "    error_messages = []\n",
    "\n",
    "    if len(genes) == 20 and len(diseases) == 20:\n",
    "        verification_results[\"defined_counts\"][\"passed\"] = True\n",
    "    else:\n",
    "        missing = []\n",
    "        if len(genes) != 20:\n",
    "            missing.append(f\"genes count is {len(genes)}; expected 20.\")\n",
    "        if len(diseases) != 20:\n",
    "            missing.append(f\"diseases count is {len(diseases)}; expected 20.\")\n",
    "        verification_results[\"defined_counts\"][\"message\"] = \" \".join(missing)\n",
    "        error_messages.append(\"Defined Counts Check Failed.\")\n",
    "\n",
    "    gene_map = {gene[\"id\"]: gene for gene in genes}\n",
    "    disease_map = {disease[\"id\"]: disease for disease in diseases}\n",
    "\n",
    "    invalid_associations = []\n",
    "    for assoc in associations:\n",
    "        from_id = assoc.get(\"from\")\n",
    "        to_id = assoc.get(\"to\")\n",
    "        strength = assoc.get(\"strength\")\n",
    "\n",
    "        if from_id not in gene_map:\n",
    "            invalid_associations.append(f\"Association from undefined gene '{from_id}' to '{to_id}'.\")\n",
    "        \n",
    "        if to_id not in disease_map:\n",
    "            invalid_associations.append(f\"Association from '{from_id}' to undefined disease '{to_id}'.\")\n",
    "        \n",
    "        if not isinstance(strength, (int, float)) or not (0.0 <= strength <= 1.0):\n",
    "            invalid_associations.append(f\"Association strength {strength} for '{from_id}' -> '{to_id}' is out of bounds (0.0 - 1.0).\")\n",
    "    \n",
    "    if not invalid_associations:\n",
    "        verification_results[\"valid_associations\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"valid_associations\"][\"message\"] = \" \".join(invalid_associations)\n",
    "        error_messages.append(\"Valid Associations Check Failed.\")\n",
    "\n",
    "    gene_degrees = defaultdict(int)\n",
    "    disease_degrees = defaultdict(int)\n",
    "    for assoc in associations:\n",
    "        gene_id = assoc.get(\"from\")\n",
    "        disease_id = assoc.get(\"to\")\n",
    "        gene_degrees[gene_id] += 1\n",
    "        disease_degrees[disease_id] += 1\n",
    "\n",
    "    degree_errors = []\n",
    "\n",
    "    for gene in genes:\n",
    "        gene_id = gene[\"id\"]\n",
    "        degree = gene_degrees.get(gene_id, 0)\n",
    "        if degree < 2 or degree > 5:\n",
    "            degree_errors.append(f\"Gene '{gene_id}' has {degree} associations; expected between 2 and 5.\")\n",
    "\n",
    "    for disease in diseases:\n",
    "        disease_id = disease[\"id\"]\n",
    "        degree = disease_degrees.get(disease_id, 0)\n",
    "        if degree < 3 or degree > 10:\n",
    "            degree_errors.append(f\"Disease '{disease_id}' has {degree} associations; expected between 3 and 10.\")\n",
    "\n",
    "    if not degree_errors:\n",
    "        verification_results[\"degree_constraints\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"degree_constraints\"][\"message\"] = \" \".join(degree_errors)\n",
    "        error_messages.append(\"Degree Constraints Check Failed.\")\n",
    "\n",
    "    seen_pairs = set()\n",
    "    duplicates = []\n",
    "    for assoc in associations:\n",
    "        pair = (assoc.get(\"from\"), assoc.get(\"to\"))\n",
    "        if pair in seen_pairs:\n",
    "            duplicates.append(f\"Duplicate association found between '{pair[0]}' and '{pair[1]}'.\")\n",
    "        else:\n",
    "            seen_pairs.add(pair)\n",
    "    \n",
    "    if not duplicates:\n",
    "        verification_results[\"duplicate_associations\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"duplicate_associations\"][\"message\"] = \" \".join(duplicates)\n",
    "        error_messages.append(\"Duplicate Associations Check Failed.\")\n",
    "\n",
    "    final_results = {\n",
    "        \"constraints\": verification_results,\n",
    "        \"overall_passed\": not error_messages,\n",
    "        \"errors\": error_messages\n",
    "    }\n",
    "\n",
    "    return (not error_messages, final_results)\n",
    "\n",
    "# PASTE HERE!\n",
    " \n",
    "genes = [\n",
    "    {\"id\": \"G0\", \"name\": \"BRCA1\", \"function\": \"DNA repair\"},\n",
    "    {\"id\": \"G1\", \"name\": \"TP53\", \"function\": \"Tumor suppression\"},\n",
    "    {\"id\": \"G2\", \"name\": \"CFTR\", \"function\": \"Chloride channel\"},\n",
    "    {\"id\": \"G3\", \"name\": \"HTT\", \"function\": \"Huntingtin protein\"},\n",
    "    {\"id\": \"G4\", \"name\": \"FBN1\", \"function\": \"Fibrillin-1\"},\n",
    "    {\"id\": \"G5\", \"name\": \"APOE\", \"function\": \"Lipid transport\"},\n",
    "    {\"id\": \"G6\", \"name\": \"EGFR\", \"function\": \"Cell growth regulation\"},\n",
    "    {\"id\": \"G7\", \"name\": \"VHL\", \"function\": \"Hypoxia response\"},\n",
    "    {\"id\": \"G8\", \"name\": \"SOD1\", \"function\": \"Superoxide dismutase\"},\n",
    "    {\"id\": \"G9\", \"name\": \"PARK7\", \"function\": \"Protein deglycase\"},\n",
    "    {\"id\": \"G10\", \"name\": \"DMD\", \"function\": \"Dystrophin production\"},\n",
    "    {\"id\": \"G11\", \"name\": \"HFE\", \"function\": \"Iron homeostasis\"},\n",
    "    {\"id\": \"G12\", \"name\": \"COL1A1\", \"function\": \"Collagen formation\"},\n",
    "    {\"id\": \"G13\", \"name\": \"MYH7\", \"function\": \"Cardiac muscle contraction\"},\n",
    "    {\"id\": \"G14\", \"name\": \"FMR1\", \"function\": \"RNA binding\"},\n",
    "    {\"id\": \"G15\", \"name\": \"PAH\", \"function\": \"Phenylalanine hydroxylase\"},\n",
    "    {\"id\": \"G16\", \"name\": \"GBA\", \"function\": \"Glucosylceramidase\"},\n",
    "    {\"id\": \"G17\", \"name\": \"HBB\", \"function\": \"Hemoglobin subunit\"},\n",
    "    {\"id\": \"G18\", \"name\": \"PRNP\", \"function\": \"Prion protein\"},\n",
    "    {\"id\": \"G19\", \"name\": \"RYR1\", \"function\": \"Calcium release channel\"},\n",
    "]\n",
    "\n",
    "diseases = [\n",
    "    {\"id\": \"D0\", \"name\": \"Breast Cancer\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D1\", \"name\": \"Lung Cancer\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D2\", \"name\": \"Cystic Fibrosis\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D3\", \"name\": \"Huntington's Disease\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D4\", \"name\": \"Marfan Syndrome\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D5\", \"name\": \"Alzheimer's Disease\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D6\", \"name\": \"Parkinson's Disease\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D7\", \"name\": \"Von Hippel-Lindau Syndrome\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D8\", \"name\": \"Amyotrophic Lateral Sclerosis\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D9\", \"name\": \"Duchenne Muscular Dystrophy\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D10\", \"name\": \"Hemochromatosis\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D11\", \"name\": \"Osteogenesis Imperfecta\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D12\", \"name\": \"Hypertrophic Cardiomyopathy\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D13\", \"name\": \"Fragile X Syndrome\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D14\", \"name\": \"Phenylketonuria\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D15\", \"name\": \"Gaucher Disease\", \"severity_level\": \"Medium\"},\n",
    "    {\"id\": \"D16\", \"name\": \"Sickle Cell Anemia\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D17\", \"name\": \"Creutzfeldt-Jakob Disease\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D18\", \"name\": \"Malignant Hyperthermia\", \"severity_level\": \"High\"},\n",
    "    {\"id\": \"D19\", \"name\": \"Retinoblastoma\", \"severity_level\": \"High\"},\n",
    "]\n",
    "\n",
    "associations = [\n",
    "    {\"from\": \"G0\", \"to\": \"D0\", \"strength\": 0.85},\n",
    "    {\"from\": \"G0\", \"to\": \"D1\", \"strength\": 0.75},\n",
    "    {\"from\": \"G0\", \"to\": \"D2\", \"strength\": 0.65},\n",
    "    {\"from\": \"G1\", \"to\": \"D1\", \"strength\": 0.85},\n",
    "    {\"from\": \"G1\", \"to\": \"D2\", \"strength\": 0.75},\n",
    "    {\"from\": \"G1\", \"to\": \"D3\", \"strength\": 0.65},\n",
    "    {\"from\": \"G2\", \"to\": \"D2\", \"strength\": 0.85},\n",
    "    {\"from\": \"G2\", \"to\": \"D3\", \"strength\": 0.75},\n",
    "    {\"from\": \"G2\", \"to\": \"D4\", \"strength\": 0.65},\n",
    "    {\"from\": \"G3\", \"to\": \"D3\", \"strength\": 0.85},\n",
    "    {\"from\": \"G3\", \"to\": \"D4\", \"strength\": 0.75},\n",
    "    {\"from\": \"G3\", \"to\": \"D5\", \"strength\": 0.65},\n",
    "    {\"from\": \"G4\", \"to\": \"D4\", \"strength\": 0.85},\n",
    "    {\"from\": \"G4\", \"to\": \"D5\", \"strength\": 0.75},\n",
    "    {\"from\": \"G4\", \"to\": \"D6\", \"strength\": 0.65},\n",
    "    {\"from\": \"G5\", \"to\": \"D5\", \"strength\": 0.85},\n",
    "    {\"from\": \"G5\", \"to\": \"D6\", \"strength\": 0.75},\n",
    "    {\"from\": \"G5\", \"to\": \"D7\", \"strength\": 0.65},\n",
    "    {\"from\": \"G6\", \"to\": \"D6\", \"strength\": 0.85},\n",
    "    {\"from\": \"G6\", \"to\": \"D7\", \"strength\": 0.75},\n",
    "    {\"from\": \"G6\", \"to\": \"D8\", \"strength\": 0.65},\n",
    "    {\"from\": \"G7\", \"to\": \"D7\", \"strength\": 0.85},\n",
    "    {\"from\": \"G7\", \"to\": \"D8\", \"strength\": 0.75},\n",
    "    {\"from\": \"G7\", \"to\": \"D9\", \"strength\": 0.65},\n",
    "    {\"from\": \"G8\", \"to\": \"D8\", \"strength\": 0.85},\n",
    "    {\"from\": \"G8\", \"to\": \"D9\", \"strength\": 0.75},\n",
    "    {\"from\": \"G8\", \"to\": \"D10\", \"strength\": 0.65},\n",
    "    {\"from\": \"G9\", \"to\": \"D9\", \"strength\": 0.85},\n",
    "    {\"from\": \"G9\", \"to\": \"D10\", \"strength\": 0.75},\n",
    "    {\"from\": \"G9\", \"to\": \"D11\", \"strength\": 0.65},\n",
    "    {\"from\": \"G10\", \"to\": \"D10\", \"strength\": 0.85},\n",
    "    {\"from\": \"G10\", \"to\": \"D11\", \"strength\": 0.75},\n",
    "    {\"from\": \"G10\", \"to\": \"D12\", \"strength\": 0.65},\n",
    "    {\"from\": \"G11\", \"to\": \"D11\", \"strength\": 0.85},\n",
    "    {\"from\": \"G11\", \"to\": \"D12\", \"strength\": 0.75},\n",
    "    {\"from\": \"G11\", \"to\": \"D13\", \"strength\": 0.65},\n",
    "    {\"from\": \"G12\", \"to\": \"D12\", \"strength\": 0.85},\n",
    "    {\"from\": \"G12\", \"to\": \"D13\", \"strength\": 0.75},\n",
    "    {\"from\": \"G12\", \"to\": \"D14\", \"strength\": 0.65},\n",
    "    {\"from\": \"G13\", \"to\": \"D13\", \"strength\": 0.85},\n",
    "    {\"from\": \"G13\", \"to\": \"D14\", \"strength\": 0.75},\n",
    "    {\"from\": \"G13\", \"to\": \"D15\", \"strength\": 0.65},\n",
    "    {\"from\": \"G14\", \"to\": \"D14\", \"strength\": 0.85},\n",
    "    {\"from\": \"G14\", \"to\": \"D15\", \"strength\": 0.75},\n",
    "    {\"from\": \"G14\", \"to\": \"D16\", \"strength\": 0.65},\n",
    "    {\"from\": \"G15\", \"to\": \"D15\", \"strength\": 0.85},\n",
    "    {\"from\": \"G15\", \"to\": \"D16\", \"strength\": 0.75},\n",
    "    {\"from\": \"G15\", \"to\": \"D17\", \"strength\": 0.65},\n",
    "    {\"from\": \"G16\", \"to\": \"D16\", \"strength\": 0.85},\n",
    "    {\"from\": \"G16\", \"to\": \"D17\", \"strength\": 0.75},\n",
    "    {\"from\": \"G16\", \"to\": \"D18\", \"strength\": 0.65},\n",
    "    {\"from\": \"G17\", \"to\": \"D17\", \"strength\": 0.85},\n",
    "    {\"from\": \"G17\", \"to\": \"D18\", \"strength\": 0.75},\n",
    "    {\"from\": \"G17\", \"to\": \"D19\", \"strength\": 0.65},\n",
    "    {\"from\": \"G18\", \"to\": \"D18\", \"strength\": 0.85},\n",
    "    {\"from\": \"G18\", \"to\": \"D19\", \"strength\": 0.75},\n",
    "    {\"from\": \"G18\", \"to\": \"D0\", \"strength\": 0.65},\n",
    "    {\"from\": \"G19\", \"to\": \"D19\", \"strength\": 0.85},\n",
    "    {\"from\": \"G19\", \"to\": \"D0\", \"strength\": 0.75},\n",
    "    {\"from\": \"G19\", \"to\": \"D1\", \"strength\": 0.65},\n",
    "]\n",
    "\n",
    "verification_output = verify_gene_disease_association_network(genes, diseases, associations)\n",
    "print(\"Gene-Disease Association Network is valid:\", verification_output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d7c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama3370B\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini15Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\"\n",
    "]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"geneAssociation\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\" Asks the user for model, prompt type, run number, and problem type \"\"\"\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "verification_json = {\n",
    "    \"genes\": genes,\n",
    "    \"diseases\": diseases,\n",
    "    \"associations\": associations,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45e101",
   "metadata": {},
   "source": [
    "## Optimal Network Design Challenge (Enhanced Version)\n",
    "\n",
    "### Problem Description\n",
    "\n",
    "Design an optimal transportation network represented as a **directed graph** where nodes represent cities and edges represent one-way roads. The network must satisfy the following constraints to ensure efficiency, connectivity, robustness, and cost-effectiveness:\n",
    "\n",
    "#### 1. Nodes (Cities):\n",
    "- **Total:** 8, labeled from `C0` to `C7`.\n",
    "- **Attributes:**\n",
    "  - **Population:** Number of inhabitants in each city.\n",
    "    - `C0`: 1,000\n",
    "    - `C1`: 500\n",
    "    - `C2`: 750\n",
    "    - `C3`: 600\n",
    "    - `C4`: 900\n",
    "    - `C5`: 400\n",
    "    - `C6`: 800\n",
    "    - `C7`: 650\n",
    "\n",
    "#### 2. Edges (Roads):\n",
    "- **Definition:** Represents a one-way road from one city to another.\n",
    "- **Attributes:**\n",
    "  - **Distance:** Length of the road in kilometers (km). *(Each road must be ≤ 300 km.)*\n",
    "  - **Construction Cost:** Cost to build the road in thousand dollars ($K).\n",
    "\n",
    "#### 3. Constraints:\n",
    "1. **Connectivity:**\n",
    "   - The network must be **strongly connected**, meaning there is a directed path from any city to every other city.\n",
    "\n",
    "2. **Road Capacity:**\n",
    "   - No single road should be longer than **300 km**.\n",
    "\n",
    "3. **Cost Optimization:**\n",
    "   - The **total construction cost** of all roads should not exceed **$10,000K**.\n",
    "\n",
    "4. **Population Accessibility:**\n",
    "   - Each city must have **at least two incoming roads** to ensure redundancy and accessibility.\n",
    "\n",
    "5. **Strategic Road Placement:**\n",
    "   - Cities `C0` and `C7` are major hubs and **must have at least three outgoing roads** each to distribute traffic efficiently.\n",
    "\n",
    "6. **Avoiding Redundancy:**\n",
    "   - **No two cities** should have more than **one direct road** connecting them in the same direction.\n",
    "\n",
    "7. **Minimizing Total Distance:**\n",
    "   - The **sum of all road distances** should be minimized to ensure efficient transportation.\n",
    "\n",
    "8. **2-Edge Robustness:**\n",
    "   - The network must remain strongly connected if **any single road is removed** (i.e. there must be two edge‑disjoint paths between every ordered pair of cities).\n",
    "\n",
    "9. **Edge-Disjoint Paths Guarantee:**\n",
    "   - For every pair of distinct cities, there must exist **at least two completely independent (edge‑disjoint) paths** connecting them.\n",
    "\n",
    "10. **Balanced Outgoing Degree:**\n",
    "    - Except for the designated hubs (`C0` and `C7`), the difference between the maximum and minimum number of outgoing roads among all cities must not exceed **2**. This prevents “overloaded” junctions.\n",
    "\n",
    "11. **Path Efficiency Constraint:**\n",
    "    - For every pair of cities, the shortest route (by total distance) should be less than **500 km** to ensure quick intercity transit.\n",
    "\n",
    "12. **Cost–Distance Consistency:**\n",
    "    - For every road, the construction cost (in $K) must be **between 1.0 and 1.5 times its distance (in km)**.  \n",
    "      *Example:* A road that is 90 km long must have a cost between **90K** and **135K**.\n",
    "\n",
    "---\n",
    "\n",
    "### Required Output Format\n",
    "\n",
    "Provide the network details in the following Python format. **Strictly adhere to this structure without deviations!**\n",
    "\n",
    "```python\n",
    "cities = [\n",
    "    {\"id\": \"C0\", \"population\": 1000},\n",
    "    {\"id\": \"C1\", \"population\": 500},\n",
    "    # ... all cities (C2-C7)\n",
    "]\n",
    "\n",
    "roads = [\n",
    "    {\"from\": \"C0\", \"to\": \"C1\", \"distance\": float, \"cost\": float},\n",
    "    {\"from\": \"C1\", \"to\": \"C2\", \"distance\": float, \"cost\": float},\n",
    "    # ... all roads\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "973d81c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verification Output: (True, {'output_structure': {'passed': True, 'message': ''}, 'connectivity': {'passed': True, 'message': ''}, 'road_capacity': {'passed': True, 'message': ''}, 'cost_optimization': {'passed': True, 'message': ''}, 'population_accessibility': {'passed': True, 'message': ''}, 'strategic_road_placement': {'passed': True, 'message': ''}, 'redundancy': {'passed': True, 'message': ''}, 'overall_passed': True, 'errors': []})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "def verify_optimal_network_design(cities, roads):\n",
    "    verification_results = {\n",
    "        \"output_structure\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"connectivity\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"road_capacity\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"cost_optimization\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"population_accessibility\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"strategic_road_placement\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"redundancy\": {\"passed\": False, \"message\": \"\"},\n",
    "        \"overall_passed\": False,\n",
    "        \"errors\": []\n",
    "    }\n",
    "    \n",
    "    # 1. Verify cities\n",
    "    if not isinstance(cities, list):\n",
    "        verification_results[\"output_structure\"][\"message\"] = \"'cities' should be a list.\"\n",
    "        return False, verification_results\n",
    "\n",
    "    city_ids = set()\n",
    "    city_population = {}\n",
    "    for city in cities:\n",
    "        if not isinstance(city, dict):\n",
    "            verification_results[\"errors\"].append(\"Each city should be a dictionary.\")\n",
    "            continue\n",
    "        if \"id\" not in city or \"population\" not in city:\n",
    "            verification_results[\"errors\"].append(f\"City {city.get('id', 'Unknown')} is missing 'id' or 'population'.\")\n",
    "            continue\n",
    "        city_id = city[\"id\"]\n",
    "        population = city[\"population\"]\n",
    "        if city_id in city_ids:\n",
    "            verification_results[\"errors\"].append(f\"Duplicate city ID detected: {city_id}.\")\n",
    "            continue\n",
    "        city_ids.add(city_id)\n",
    "        city_population[city_id] = population\n",
    "\n",
    "    # 2. Verify roads\n",
    "    if not isinstance(roads, list):\n",
    "        verification_results[\"output_structure\"][\"message\"] = \"'roads' should be a list.\"\n",
    "        return False, verification_results\n",
    "    \n",
    "    adjacency = defaultdict(list)\n",
    "    road_set = set()\n",
    "    total_cost = 0.0\n",
    "    road_unique = True\n",
    "    road_capacity_passed = True\n",
    "    road_capacity_errors = []\n",
    "    for road in roads:\n",
    "        if not isinstance(road, dict):\n",
    "            verification_results[\"errors\"].append(\"Each road should be a dictionary.\")\n",
    "            continue\n",
    "        if \"from\" not in road or \"to\" not in road or \"distance\" not in road or \"cost\" not in road:\n",
    "            verification_results[\"errors\"].append(f\"Road from {road.get('from', 'Unknown')} to {road.get('to', 'Unknown')} is missing required attributes.\")\n",
    "            continue\n",
    "        from_city = road[\"from\"]\n",
    "        to_city = road[\"to\"]\n",
    "        distance = road[\"distance\"]\n",
    "        cost = road[\"cost\"]\n",
    "        \n",
    "        if from_city not in city_ids:\n",
    "            verification_results[\"errors\"].append(f\"Road 'from' city '{from_city}' is not defined.\")\n",
    "        if to_city not in city_ids:\n",
    "            verification_results[\"errors\"].append(f\"Road 'to' city '{to_city}' is not defined.\")\n",
    "        if not isinstance(distance, (int, float)) or distance > 300:\n",
    "            verification_results[\"errors\"].append(f\"Road from '{from_city}' to '{to_city}' has invalid distance {distance} km (must be <= 300 km).\")\n",
    "            road_capacity_passed = False\n",
    "            road_capacity_errors.append(f\"Road from '{from_city}' to '{to_city}' exceeds the maximum allowed distance of 300 km.\")\n",
    "        if not isinstance(cost, (int, float)) or cost <=0:\n",
    "            verification_results[\"errors\"].append(f\"Road from '{from_city}' to '{to_city}' has invalid cost ${cost}K (must be positive).\")\n",
    "        \n",
    "        road_key = (from_city, to_city)\n",
    "        if road_key in road_set:\n",
    "            verification_results[\"errors\"].append(f\"Duplicate road detected from '{from_city}' to '{to_city}'.\")\n",
    "            road_unique = False\n",
    "        else:\n",
    "            road_set.add(road_key)\n",
    "        \n",
    "        adjacency[from_city].append(to_city)\n",
    "        total_cost += cost\n",
    "\n",
    "    # Road Capacity Compliance\n",
    "    if road_capacity_passed:\n",
    "        verification_results[\"road_capacity\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"road_capacity\"][\"passed\"] = False\n",
    "        verification_results[\"road_capacity\"][\"message\"] = \"; \".join(road_capacity_errors)\n",
    "        verification_results[\"errors\"].extend(road_capacity_errors)\n",
    "    \n",
    "    # 3. Check total construction cost\n",
    "    if total_cost <= 10000:\n",
    "        verification_results[\"cost_optimization\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"cost_optimization\"][\"passed\"] = False\n",
    "        verification_results[\"cost_optimization\"][\"message\"] = f\"Total construction cost is ${total_cost}K, exceeding the limit of $10,000K.\"\n",
    "        verification_results[\"errors\"].append(verification_results[\"cost_optimization\"][\"message\"])\n",
    "\n",
    "    # 4. Check connectivity (Strongly Connected)\n",
    "    # Using Kosaraju's algorithm\n",
    "    def kosaraju_scc(adjacency, nodes):\n",
    "        visited = set()\n",
    "        stack = []\n",
    "        \n",
    "        def dfs(u):\n",
    "            visited.add(u)\n",
    "            for v in adjacency[u]:\n",
    "                if v not in visited:\n",
    "                    dfs(v)\n",
    "            stack.append(u)\n",
    "        \n",
    "        for u in nodes:\n",
    "            if u not in visited:\n",
    "                dfs(u)\n",
    "        \n",
    "        # Transpose graph\n",
    "        transposed = defaultdict(list)\n",
    "        for u in adjacency:\n",
    "            for v in adjacency[u]:\n",
    "                transposed[v].append(u)\n",
    "        \n",
    "        # Second pass\n",
    "        visited.clear()\n",
    "        scc = []\n",
    "        \n",
    "        def dfs_transposed(u, component):\n",
    "            visited.add(u)\n",
    "            component.append(u)\n",
    "            for v in transposed[u]:\n",
    "                if v not in visited:\n",
    "                    dfs_transposed(v, component)\n",
    "        \n",
    "        while stack:\n",
    "            u = stack.pop()\n",
    "            if u not in visited:\n",
    "                component = []\n",
    "                dfs_transposed(u, component)\n",
    "                scc.append(component)\n",
    "        \n",
    "        return scc\n",
    "    \n",
    "    scc = kosaraju_scc(adjacency, city_ids)\n",
    "    if len(scc) == 1:\n",
    "        verification_results[\"connectivity\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"connectivity\"][\"passed\"] = False\n",
    "        verification_results[\"connectivity\"][\"message\"] = \"The network is not strongly connected.\"\n",
    "        verification_results[\"errors\"].append(verification_results[\"connectivity\"][\"message\"])\n",
    "\n",
    "    # 5. Check population accessibility (at least two incoming roads per city)\n",
    "    incoming_roads = defaultdict(int)\n",
    "    for road in roads:\n",
    "        incoming_roads[road[\"to\"]] += 1\n",
    "    population_accessible = True\n",
    "    for city in city_ids:\n",
    "        if incoming_roads[city] < 2:\n",
    "            verification_results[\"errors\"].append(f\"City '{city}' has only {incoming_roads[city]} incoming road(s); requires at least two.\")\n",
    "            population_accessible = False\n",
    "    if population_accessible:\n",
    "        verification_results[\"population_accessibility\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"population_accessibility\"][\"passed\"] = False\n",
    "\n",
    "    # 6. Check strategic road placement (C0 and C7 have at least three outgoing roads)\n",
    "    strategic_passed = True\n",
    "    for critical_city in [\"C0\", \"C7\"]:\n",
    "        outgoing = len(adjacency[critical_city])\n",
    "        if outgoing < 3:\n",
    "            verification_results[\"errors\"].append(f\"Critical city '{critical_city}' has only {outgoing} outgoing road(s); requires at least three.\")\n",
    "            strategic_passed = False\n",
    "    if strategic_passed:\n",
    "        verification_results[\"strategic_road_placement\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"strategic_road_placement\"][\"passed\"] = False\n",
    "\n",
    "    # 7. Check redundancy (implied by strong connectivity and multiple incoming roads)\n",
    "    if verification_results[\"connectivity\"][\"passed\"] and verification_results[\"population_accessibility\"][\"passed\"]:\n",
    "        verification_results[\"redundancy\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"redundancy\"][\"passed\"] = False\n",
    "        verification_results[\"redundancy\"][\"message\"] = \"Insufficient redundancy due to connectivity or population accessibility issues.\"\n",
    "        verification_results[\"errors\"].append(verification_results[\"redundancy\"][\"message\"])\n",
    "\n",
    "    # 8. Check road uniqueness\n",
    "    if road_unique:\n",
    "        verification_results[\"output_structure\"][\"passed\"] = True\n",
    "    else:\n",
    "        verification_results[\"output_structure\"][\"passed\"] = False\n",
    "        verification_results[\"output_structure\"][\"message\"] = \"Duplicate roads detected.\"\n",
    "    \n",
    "    # 9. Overall Pass\n",
    "    overall_passed = all([\n",
    "        verification_results[\"output_structure\"][\"passed\"],\n",
    "        verification_results[\"connectivity\"][\"passed\"],\n",
    "        verification_results[\"road_capacity\"][\"passed\"],\n",
    "        verification_results[\"cost_optimization\"][\"passed\"],\n",
    "        verification_results[\"population_accessibility\"][\"passed\"],\n",
    "        verification_results[\"strategic_road_placement\"][\"passed\"],\n",
    "        verification_results[\"redundancy\"][\"passed\"],\n",
    "    ])\n",
    "    verification_results[\"overall_passed\"] = overall_passed\n",
    "    \n",
    "    return overall_passed, verification_results\n",
    "\n",
    "\n",
    "cities = [\n",
    "    {\"id\": \"C0\", \"population\": 1000},\n",
    "    {\"id\": \"C1\", \"population\": 500},\n",
    "    {\"id\": \"C2\", \"population\": 750},\n",
    "    {\"id\": \"C3\", \"population\": 600},\n",
    "    {\"id\": \"C4\", \"population\": 900},\n",
    "    {\"id\": \"C5\", \"population\": 400},\n",
    "    {\"id\": \"C6\", \"population\": 800},\n",
    "    {\"id\": \"C7\", \"population\": 650},\n",
    "]\n",
    "\n",
    "# Design rationale:\n",
    "# We construct two complete cycles – a “forward cycle” and its reverse – so that every city\n",
    "# has exactly 2 incoming edges and every ordered pair of cities is connected by two edge‑disjoint paths.\n",
    "# This ensures strong connectivity and 2‑edge robustness.\n",
    "#\n",
    "# The forward cycle is:\n",
    "#   C0 → C1 → C2 → C3 → C4 → C5 → C6 → C7 → C0\n",
    "#\n",
    "# The reverse cycle (each edge going in the opposite direction) is:\n",
    "#   C1 → C0, C2 → C1, C3 → C2, C4 → C3, C5 → C4, C6 → C5, C7 → C6, C0 → C7\n",
    "#\n",
    "# To meet the strategic requirement that the major hubs C0 and C7 have at least three outgoing roads,\n",
    "# we add one extra outgoing edge from each:\n",
    "#   - From C0: an extra edge to C3.\n",
    "#   - From C7: an extra edge to C4.\n",
    "#\n",
    "# All roads are assigned a distance of 50 km and a construction cost of 50K dollars.\n",
    "# This choice satisfies:\n",
    "#   - Each road is ≤ 300 km.\n",
    "#   - Cost–distance consistency (50K is exactly 1.0 times 50 km, within the allowed [1.0, 1.5] range).\n",
    "#   - The overall total cost (18 × 50K = 900K) is far below the 10,000K budget.\n",
    "#\n",
    "# Moreover, with each edge being 50 km, any shortest route between two cities (using at most 4 edges\n",
    "# along the “shorter” direction around the dual cycles) remains well under the 500 km limit.\n",
    "#\n",
    "# Finally, non‐hub cities (C1–C6) have exactly 2 outgoing roads (one from the forward cycle and one from the reverse cycle),\n",
    "# so the difference between the maximum and minimum outgoing roads (excluding hubs C0 and C7) is 0, satisfying the balanced degree constraint.\n",
    "\n",
    "roads = [\n",
    "    # Forward cycle edges\n",
    "    {\"from\": \"C0\", \"to\": \"C1\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C1\", \"to\": \"C2\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C2\", \"to\": \"C3\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C3\", \"to\": \"C4\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C4\", \"to\": \"C5\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C5\", \"to\": \"C6\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C6\", \"to\": \"C7\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C7\", \"to\": \"C0\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "\n",
    "    # Reverse cycle edges\n",
    "    {\"from\": \"C1\", \"to\": \"C0\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C2\", \"to\": \"C1\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C3\", \"to\": \"C2\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C4\", \"to\": \"C3\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C5\", \"to\": \"C4\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C6\", \"to\": \"C5\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C7\", \"to\": \"C6\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C0\", \"to\": \"C7\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "\n",
    "    # Extra edges to satisfy hub outbound degree requirements\n",
    "    {\"from\": \"C0\", \"to\": \"C3\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "    {\"from\": \"C7\", \"to\": \"C4\", \"distance\": 50.0, \"cost\": 50.0},\n",
    "]\n",
    "\n",
    "\n",
    "# Execute verification\n",
    "verification_output = verify_optimal_network_design(\n",
    "    cities,\n",
    "    roads\n",
    ")\n",
    "print(\"Verification Output:\", verification_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aab3b1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Models:\n",
      "1. GPT4omini\n",
      "2. Claude35Haiku\n",
      "3. Gemini20Flash\n",
      "4. DeepSeekV3\n",
      "5. Llama3370B\n",
      "6. GPT4o\n",
      "7. Claude35Sonnet\n",
      "8. Gemini15Pro\n",
      "9. Llama31405B\n",
      "10. DeepSeekR1\n",
      "11. o3mini\n",
      "12. o1\n",
      "Select a model by number: 11\n",
      "\n",
      "Available Prompt Types:\n",
      "1. directprompt\n",
      "2. iterativefeedback\n",
      "3. programaugmented\n",
      "Select a prompt type by number: 2\n",
      "\n",
      "Enter the run number (1-5): 4\n",
      "Save is succesful! results/cities_o3mini_iterativefeedback_run4_output.json\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "\n",
    "models = [\n",
    "    \"GPT4omini\", \"Claude35Haiku\", \"Gemini20Flash\", \"DeepSeekV3\", \"Llama3370B\", \n",
    "    \"GPT4o\", \"Claude35Sonnet\", \"Gemini15Pro\", \"Llama31405B\", \"DeepSeekR1\", \"o3mini\", \"o1\"\n",
    "]\n",
    "\n",
    "prompt_types = [\"directprompt\", \"iterativefeedback\", \"programaugmented\"]\n",
    "\n",
    "problem_type = \"cities\"\n",
    "\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\" Asks the user for model, prompt type, run number, and problem type \"\"\"\n",
    "    print(\"\\nAvailable Models:\")\n",
    "    for i, model in enumerate(models):\n",
    "        print(f\"{i+1}. {model}\")\n",
    "    model_choice = int(input(\"Select a model by number: \")) - 1\n",
    "    model_selected = models[model_choice]\n",
    "\n",
    "    print(\"\\nAvailable Prompt Types:\")\n",
    "    for i, prompt in enumerate(prompt_types):\n",
    "        print(f\"{i+1}. {prompt}\")\n",
    "    prompt_choice = int(input(\"Select a prompt type by number: \")) - 1\n",
    "    prompt_selected = prompt_types[prompt_choice]\n",
    "\n",
    "    run_number = int(input(\"\\nEnter the run number (1-5): \"))\n",
    "\n",
    "    return run_number, model_selected, prompt_selected\n",
    "\n",
    "run_number, model_selected, prompt_selected = get_user_input()\n",
    "\n",
    "results_dir = \"results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "json_file_path = os.path.join(results_dir, f\"{problem_type}_{model_selected}_{prompt_selected}_run{run_number}_output.json\")\n",
    "\n",
    "\n",
    "verification_json = {\n",
    "    \"cities\":cities,\n",
    "    \"result\": verification_output[0],\n",
    "    \"fullOutput\": verification_output[1]\n",
    "}\n",
    "\n",
    "with open(json_file_path, mode='w', newline='') as json_file:\n",
    "    json.dump(verification_json, json_file, indent=4)\n",
    "\n",
    "print(\"Save is succesful!\",json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecd0c47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
